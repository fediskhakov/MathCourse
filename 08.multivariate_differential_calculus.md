---
jupytext:
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

````{admonition} Announcements & Reminders
:class: note
:class: dropdown

1. This week and the next week we have a guest lecturer

    Dr **Esben Skriver Andersen**

    - Office: 1018 HW Arndt Building
    - Email: esbenscriver.andersen@anu.edu.au

2. Online Test 4 on **Monday May 6**

    - will cover last two lectures:
      - linear systems of equations
      - multivariate differential calculus (part 1)

3. The final exam is scheduled! 

    - **Friday May 31, 2pm**
    - 3 hours exam + 15 minutes reading time
    - closed book, no materials allowed
    - Manning Clark Hall, room 1.04, Cultural Centre Kambri

````


# üìñ Multivariate differential calculus (part 1)

<small>‚è± <span class="eta"></span> | <span class="words"></span> words</small>


````{dropdown} Sources and reading guide

```{figure} _static/img/bibliography/shsc2016.png
:width: 100px
:align: left
```
{cite:ps}`sydsaeter2016`

Chapters 11 and 12 (pp. 407-494).

<div style="clear: both"></div>

Introductory level references:
- {cite:ps}`bradley2008`: Chapter 7, Sections 1 to 3 (pp. 360-408).
- {cite:ps}`haeussler1987`: Chapter 17, Sections 1 to 7 and Sections 9 to 10 (pp. 668-706 and 714-723).
- {cite:ps}`shannon1995`: Chapter 10, Sections 1 to 6 (pp. 450-489).

Intermediate mathematical economics textbooks:
- {cite:ps}`chiang1984`: Chapters 6-8 and Chapter 10 (pp. 127-227 and 268-306).
- {cite:ps}`chiang2005`: Chapters 6 to 10 (pp. 124-290).
- {cite:ps}`simon1994`: Chapters 2 to 5 (pp. 10-103).

Mathematics textbooks:
- {cite:ps}`spiegel1981a`: Chapters 4, 6, 7 and 8; pp. 57-79 and 101-179.
- {cite:ps}`spiegel1981b`: Chapters 3 and 4; pp. 35-81.
````

> We want to extend our discussion of differential calculus from single-real-valued univariate functions, $f(x_1)$, to single-real-valued multivariate functions, $f(x_1,x_2,\dots,x_n)$.
> 
> We will be focussing on two concepts. These are **partial derivatives** and **total  derivatives**.

## Notation

To simplify notation we will sometimes denote vectors with bold letters, e.g. $\mathbf{x}=(x_1,x_2,\dots,x_n)$. Hence, we can write our multivariate function as a function of a vector input, $f(\mathbf{x})=f(x_1,x_2,\dots,x_n)$.

## Single-real-valued multivariate functions

```{admonition} Definition
:class: caution

A single-real-valued multivariate function takes as input $n$ real numbers and outputs a single real number, 

$$
f: X \subseteq \mathbb{R}^{n} \rightarrow Y \subseteq \mathbb{R}.
$$
```

Recall that:
- $X$ is the domain of $f$.
- $Y$ is the target space of $f$.

Often we simply write a single-real-valued multivariate functions as

$$
y = f(x_1,x_2,\dots,x_n),
$$

where $y$ is refered to as the dependent variable, and $x_i$ is referred to as an independent variable. Alternatively, $y$ and $x_i$ can be referred to as the endogenous and exogenous variables, or the output and input variables.

```{admonition} Example
:class: tip

Consider the single-real-valued multivariate function $f(x_1,x_2) = \sqrt{x_1 - 1} + \sqrt{x_2 - 2}$.
- the domain of $f$ is $\left\{ (x_1,x_2) \in \mathbb{R}^{2} | x_1 \geq 1, x_2 \geq 2 \right\}$.
- the target of $f$ is $\left\{ y \in \mathbb{R} | y \geq 0 \right\}$.

```

```{figure} _static/img/lecture_08/domain_and_target.png
:name: domain_and_target
:width: 100%

Illustrations of domain and target of $f$.
```

In economic analysis we will often use single-real-valued multivariate functions to represent
- production functions
- cost functions
- profit functions
- utility functions
- demand functions

```{admonition} Example
:class: tip
Important single-real-valued bivariate functions used in economic analysis:
- Linear function

$$f(\mathbf{x}) = a_{1} x_{1} + a_{2} x_{2}.$$

- Input-output function

$$f(\mathbf{x}) = \text{min}(a_1 x_1, a_2 x_2).$$

- Cobb-Douglas function

$$f(\mathbf{x}) = k x_{1}^{b_1} x_{2}^{b_2}.$$

- Constant elasticity of substitution (CES) function, 

$$f(\mathbf{x}) = k (c_1 x_1^{-a} + c_2 x_2^{-a})^{b/a}.$$

```

These functions are straight forward to extent to more than two inputs.

## Partial derivatives
Our primary goal in economic analysis is to understand how a change in one independent variable affect the dependent variable. By using partial derivatives we take the simplest approach by changing one variable at a time, keeping all other constant.

<!-- Suppose that we hold the values that are taken by $(n-1)$ of the independent variables constant and only allow the k'th independent variable to take on different values, $x_k$.

- To simplify notation, let $\mathbf{x}_{-k}$ denote the $(n-1)$ independent variables we keep fixed

$$
\mathbf{x}_{-k}=\left(x_{1}, x_{2}, \dots, x_{k-1}, x_{k+1}, \dots, x_{n}\right)
$$

- Further, let $\bar{\mathbf{x}}_{-k}$ denote the fixed values of these $(n-1)$ independent variables

$$
\bar{\mathbf{x}}_{-k}=\left(\bar{x}_{1}, \bar{x}_{2}, \dots, \bar{x}_{k-1}, \bar{x}_{k+1}, \dots, \bar{x}_{n}\right) .
$$

We can now think about the multivariate function as a univariate function, with $x_{k}$ being the sole independent variable. To be precise, we have

$$
g\left(x_{k}\right)=f\left(x_{k}; \bar{\mathbf{x}}_{-k}\right) .
$$

Suppose that the univariate function $g\left(x_{k}\right)$ is differentiable and that its derivative is given by

$$
g^{\prime}\left(x_{k}\right)=\frac{d g\left(x_{k}\right)}{d x_{k}}
$$ -->

```{admonition} Definition
:class: caution

The partial derivative of the single-real-valued multivariate function $f$ with respect to the variable $x_{k}$ is defined as

$$
\begin{aligned}
\frac{\partial f\left(\mathbf{x}\right)}{\partial x_{k}} = \lim _{h \rightarrow 0}\left\{\frac{f\left(x_{1}, \dots, x_{k} + h, x_{k+1}, \dots, x_n\right) - f\left(x_{1}, \dots, x_{k}, x_{k+1}, \dots, x_n\right)}{h}\right\} .
\end{aligned}
$$

```

```{figure} _static/img/lecture_08/partial_derivative.png
:name: Simplified illustration of partial derivative.
:width: 100%

Illustration of the partial derivative with respect to $x_k$.
```

Note that the partial derivative, $\partial f\left(\mathbf{x}\right)/\partial x_k$, is a single-real-valued multivariate function itself, as it in general depend on all the independent variables.

As a matter of convenience partial derivatives are often denoted by $f_{k}\left(\mathbf{x}\right)$ or $f'_{k}\left(\mathbf{x}\right)$.

```{admonition} Definition
:class: caution

The gradient is defined as the vector of first-order partial derivatives of $f$

$$
\nabla f(\mathbf{x}) = \bigg(\tfrac{\partial f(\mathbf{x})}{\partial x_1}, \tfrac{\partial f(\mathbf{x})}{\partial x_1}, \dots, \tfrac{\partial f(\mathbf{x})}{\partial x_n} \bigg)^T
$$
```

The gradient is commonly denoted by one of $\nabla f(\mathbf{x}), D_{x} f(\mathbf{x})$, or $\operatorname{grad} f(\mathbf{x})$.

Note that when calculating the partial derivative with respect $x_k$ we treat the remaining independent variables as constants. Hence, we can use the same rules for partial differentiation as for differentiation of univariate functions. 

```{admonition} Fact: Rules for partial differentiation
:class: important

- $f(\mathbf{x}) = c g(\mathbf{x}) \Rightarrow f_k\left( \mathbf{x} \right) = c g_k\left( \mathbf{x} \right)$.
- $f(\mathbf{x}) = g(\mathbf{x}) + h(\mathbf{x}) \Rightarrow f_k\left( \mathbf{x} \right) = g_k\left( \mathbf{x} \right) + h_k\left( \mathbf{x} \right)$.
- $f(\mathbf{x}) = g(\mathbf{x})h(\mathbf{x}) \Rightarrow f_k\left( \mathbf{x} \right) = g_k(\mathbf{x})h(\mathbf{x}) + g(\mathbf{x})h_k(\mathbf{x})$.
- $f(\mathbf{x}) = g\left(h\left(\mathbf{x}\right)\right) \Rightarrow f_k\left( \mathbf{x} \right) = g_h\left(h\left(\mathbf{x}\right)\right)h_k\left(\mathbf{x}\right)$.

```

```{admonition} Example I
:class: tip

Consider the bivariate function $y=f(x_1,x_2)=a x_1 + b x_2$. The partial derivative with respect to $x_1$ is then

The partial derivative with respect to $x_1$ is then

$$
f_1(x_1,x_2)=a.
$$

The partial derivative with respect to $x_2$ is then

$$
f_1(x_1,x_2)=b.
$$

```

```{admonition} Example II
:class: tip

Consider the bivariate function $y=f(x_1,x_2)=x_1 x_2$.

The partial derivative with respect to $x_1$ is then

$$
f_1(x_1,x_2)=x_2.
$$

The partial derivative with respect to $x_2$ is then

$$
f_2(x_1,x_2)=x_1.
$$

```

```{admonition} Definition
:class: caution

Some terminologi:
- If $\partial f\left(\mathbf{x}\right)/\partial x_k$ exist for each $k$, we say that $f$ is differentiable at $\mathbf{x}$.
- If these $n$ partial derivative functions are continuous, we say that $f$ is continously differentiable at $\mathbf{x}$. This is denoted by $f \in C^{1}$ on $X$.

```

### Some economic applications

Often in economic analysis the partial derivative has a straight forward interpretation
- production function: marginal product
- cost function: marginal cost
- profit function: marginal profit
- utility function: marginal utility
- demand function: marginal change in demand

```{admonition} Marginal products of production inputs
:class: tip

Suppose a firm's production is described by a Cobb-Douglas production function, where labor (L) and capital (K) are the inputs:

$$
Q = f(L, K)=A L^{\alpha} K^{\beta} .
$$

The marginal product of labour is simply the partial derivative with respect to labor. Thus we have

$$
\begin{aligned}
M P_{L}(L, K) & =\frac{\partial f(L, K)}{\partial L} \\
& =\frac{\partial\left(A L^{\alpha} K^{\beta}\right)}{\partial L} \\
& =\alpha A L^{\alpha-1} K^{\beta}
\end{aligned}
$$

The marginal product of capital is simply the first-order derivative with respect to capital. Thus we have

$$
\begin{aligned}
M P_{K}(L, K) & =\frac{\partial f(L, K)}{\partial K} \\
& =\frac{\partial\left(A L^{\alpha} K^{\beta}\right)}{\partial K} \\
& =\beta A L^{\alpha} K^{\beta-1}
\end{aligned}
$$

```

### Elasticities
An elasticity measure the fractional response of the dependent variable, $y=f(x_1,x_2,\dots,x_n)$, to a fractional change in an independent variable, e.g. $x_k$, which can be written as

$$
\varepsilon_{x_{k}} 
&= \left(\frac{f(x_1,\dots,x_k + h, x_{k+1},\dots,x_n) - f(x_1,\dots,x_k, x_{k+1},\dots,x_n)}{f(x_1,\dots,x_k, x_{k+1},\dots,x_n)} \right) / \left( \frac{h}{x_k} \right), \\
&= \frac{f(x_1,\dots,x_k + h, x_{k+1},\dots,x_n) - f(x_1,\dots,x_k, x_{k+1},\dots,x_n)}{h}\frac{x_k}{f(x_1,\dots,x_k, x_{k+1},\dots,x_n)},
$$

where $h$ is the change in $x_k$. As $h \rightarrow 0$, we can write this in terms of the partial derivative

$$
\varepsilon_{x_{k}} = \frac{\partial f(\mathbf{x})}{\partial x_k} \frac{x_k}{f(\mathbf{x})}.
$$

Similar to partial derivatives, elasticities measure how sensitive the dependent variable is to changes in the independent variables. Unlike partial derivatives elasticities are unit-free.

```{admonition} Elasticities of production with respect to inputs
:class: tip

Suppose a firm production is described by a Cobb-Douglas production function:

$$
f(L, K)=A L^{\alpha} K^{\beta} .
$$

We know from earlier that the partial derivatives of the Cobb-Douglas production function are

$$
\frac{\partial f(L, K)}{\partial L} = \alpha A L^{\alpha-1} K^{\beta}. \\
\frac{\partial f(L, K)}{\partial K} = \beta A L^{\alpha} K^{\beta-1}. \\
$$

Insert the partial derivate with respect to labor into the definition of elasticities

$$
\varepsilon_{L} 
&= \tfrac{\partial f(L,K)}{\partial L}\tfrac{L}{f(L,K)}, \\
&= \alpha A L^{\alpha-1} K^{\beta}\frac{L}{A L^{\alpha} K^{\beta}}, \\
&= \alpha.
$$

Insert the partial derivate with respect to capital into the definition of elasticities

$$
\varepsilon_{K} 
&= \tfrac{\partial f(L,K)}{\partial L}\tfrac{L}{f(L,K)}, \\
&= \beta A L^{\alpha} K^{\beta-1}\frac{K}{A L^{\alpha} K^{\beta}}, \\
&= \beta.
$$
```

### Elasticities of demand

Suppose that an individual's demand function for commodity $k$ is given by

$$
D_{k}\left(\mathbf{p},y\right) = D_{k}\left(p_{1}, p_{2}, \dots, p_{n}, y\right),
$$

where $p_{i}$ is the price of commodity $i$ and $y$ is the consumer's income.

- The own-price elasticity of demand for commodity $k$ for this consumer is

$$
\begin{aligned}
\varepsilon_{k}^{k}\left(\mathbf{p},y\right)
& =\left(\frac{p_{k}}{D_{k}\left(\mathbf{p},y\right)}\right)\left(\frac{\partial D_{k}\left(\mathbf{p},y\right)}{\partial p_{k}}\right) .
\end{aligned}
$$

- The cross-price elasticity of demand for commodity $k$ with respect to the price of commodity $l$ for this consumer is

$$
\begin{aligned}
\varepsilon_{l}^{k}\left(\mathbf{p},y\right)
& =\left(\frac{p_{l}}{D_{k}\left(\mathbf{p},y\right)}\right)\left(\frac{\partial D_{k}\left(\mathbf{p},y\right)}{\partial p_{l}}\right).
\end{aligned}
$$

- The income elasticity of demand for commodity $k$ for this consumer is

$$
\begin{aligned}
\varepsilon_{y}^{k}\left(\mathbf{p},y\right)
& =\left(\frac{y}{D_{k}\left(\mathbf{p},y\right)}\right)\left(\frac{\partial D_{k}\left(\mathbf{p},y\right)}{\partial y}\right) .
\end{aligned}
$$

We can use these elasticities to classify the types of commodities that are being considered:
- If $\varepsilon_{y}^{k}>0$, then commodity $k$ is a normal good. 
- If $\varepsilon_{y}^{k}<0$, then commodity $k$ is an inferior good.
- If $\varepsilon_{l}^{k}>0$, then commodities $k$ and $l$ are substitutes. 
- If $\varepsilon_{l}^{k}<0$, then commodities $k$ and $l$ are complements.
- The demand curve for most commodities will usually slope down. As such, we would usually expect $\varepsilon_{k}^{k}<0$.
- However, there are circumstances in which the demand curve for a commodity can slope up over some range of prices (at least in theory). Such commodities are known as Giffen goods. In such circumstances, we would have $\varepsilon_{k}^{k}>0$ over the relevant range of prices. Note that a necessary, but not sufficient, condition for a commodity to be a Giffen good is that it be an inferior good.

<!-- ### Cournot aggregation

Suppose that a consumer's preferences over bundles of $L$ commodities. Assume that the budget constrain holds exactly

$$
\sum_{l=1}^{L} p_{l} x_{l}(p, y)=y,
$$

where $p=\left(p_{1}, p_{2}, \dots, p_{n}\right)=\left(p_{k}, p_{-k}\right)$ is the price vector, $y$ is the consumer's income and $x_{l}(p, y)$ is the consumer's Marshallian demand for good $l$.

Note that this can be rewritten as

$$
p_{k} x_{k}\left(p_{k}, p_{-k}, y\right)+\sum_{l \neq k} p_{l} x_{l}(p, y)=y
$$


Partially differentiating both sides of this equation with respect to the price of commodity $k$, we obtain

$$
\left\{(1) x_{k}(p, y)+p_{k}\left(\frac{\partial x_{k}(p, y)}{\partial p_{k}}\right)\right\}+\sum_{l \neq k} p_{l}\left(\frac{\partial x_{l}(p, y)}{\partial p_{k}}\right)=0 .
$$

This can be simplified to obtain

$$
x_{k}(p, y)+\sum_{l=1}^{L} p_{l} \frac{\partial x_{l}(p, y)}{\partial p_{k}}=0
$$

This can be rearranged to obtain

$$
\sum_{l=1}^{L} p_{l} \frac{\partial x_{l}(p, y)}{\partial p_{k}}=-x_{k}(p, y)
$$

This can be rewritten as

$$
\sum_{l=1}^{L}\left(\frac{p_{k}}{p_{k}}\right)\left(\frac{x_{l}(p, y)}{x_{l}(p, y)}\right)\left(\frac{y}{y}\right) p_{l} \frac{\partial x_{l}(p, y)}{\partial p_{k}}=-x_{k}(p, y) .
$$

This can be rearranged to obtain

$$
\sum_{l=1}^{L}\left(\frac{p_{l} x_{l}(p, y)}{y}\right)\left(\frac{p_{k}}{x_{l}(p, y)}\right)\left(\frac{\partial x_{l}(p, y)}{\partial p_{k}}\right)=-\left(\frac{p_{k} x_{k}(p, y)}{y}\right) .
$$

This can be rewritten as

$$
\sum_{l=1}^{L} s_{l} \varepsilon_{k}^{l}=-s_{k}
$$

where

$$
s_{l}=\frac{p_{l} x_{l}(p, y)}{y}
$$

is the budget share of commodity $l$ and

$$
\varepsilon_{k}^{\prime}=\left(\frac{p_{k}}{x_{l}(p, y)}\right)\left(\frac{\partial x_{l}(p, y)}{\partial p_{k}}\right)
$$

is the $k$ th commodity-price elasticity of demand for commodity $l$.

The above formula is a result known as Cournot aggregation. It provides a relationship between the $k$ th price elasticities of demand for the various commodities.


### Engel aggregation

Suppose that a consumer's preferences over bundles of $L$ commodities are locally non-satiated in the neighbourhood of any potentially feasible commodity bundle. Then we know that budget exhaustion (which is sometimes called Walras' law for the individual) must hold for the consumer. This ensures that

$$
\sum_{l=1}^{L} p_{l} x_{l}(p, y)=y
$$

where $p=\left(p_{1}, p_{2}, \cdots, p_{n}\right)$ is the price vector, $y$ is the consumer's income and $x_{l}(p, y)$ is the consumer's Marshallian demand for good $I$.

Partially differentiating both sides of this equation with respect to income, we obtain

$$
\sum_{l=1}^{L} p_{l}\left(\frac{\partial x_{l}(p, y)}{\partial y}\right)=1
$$

This can be rewritten as

$$
\sum_{l=1}^{L}\left(\frac{y}{y}\right)\left(\frac{x_{l}(p, y)}{x_{l}(p, y)}\right) p_{l}\left(\frac{\partial x_{l}(p, y)}{\partial y}\right)=1
$$

This can be simplified to obtain

$$
\sum_{l=1}^{L}\left(\frac{p_{l} x_{l}(p, y)}{y}\right)\left(\frac{y}{x_{l}(p, y)}\right)\left(\frac{\partial x_{l}(p, y)}{\partial y}\right)=1
$$

This can be rewritten as

$$
\sum_{l=1}^{L} s_{l} \varepsilon_{y}^{l}=1
$$

where

$$
s_{l}=\frac{p_{l} x_{l}(p, y)}{y}
$$

is the budget share of commodity $l$ and

$$
\varepsilon_{y}^{l}=\left(\frac{y}{x_{l}(p, y)}\right)\left(\frac{\partial x_{l}(p, y)}{\partial y}\right)
$$

is the income elasticity of demand for commodity $l$.

The above formula is a result known as Engel aggregation. It provides a relationship between the income elasticities of demand for the various commodities. -->

## Second-order partial derivatives

Consider the function single-real-valued multivariate function $f\left(x_1,x_2,\dots,x_n \right)$. Recall that if the first-order partial derivative exist it is also a single-real-valued multivariate function. The second-order partial derivative is given as the partial derivate of the first-order partial derivate

$$
\frac{\partial^{2} f\left(x_{1}, x_{2}, \dots, x_{n}\right)}{\partial x_{j} \partial x_{i}}=\frac{\partial}{\partial x_{j}}\left(\frac{\partial f\left(x_{1}, x_{2}, \dots, x_{n}\right)}{\partial x_{i}}\right),
$$

where $x_i$ is the input $f$ is differentiated with respect to, and $x_j$ is the input the first-order partial derivative is differentiated with respect to.

The second-order partial derivative is commonly denoted

$$
\frac{\partial^{2} f\left(x_{1}, x_{2}, \dots, x_{n}\right)}{\partial x_{j} \partial x_{i}}=f_{i j}\left(x_{1}, x_{2}, \dots, x_{n}\right)
$$

Note again that if the second-order partial derivative exist it is also a single-real-valued multivariate function.

```{admonition} Definition
:class: caution

The Hessian is defined as the matrix of second-order partial derivatives of $f$

$$
\nabla^2 f(\mathbf{x}) = \left(\begin{array}{cccc}
\frac{\partial^{2} f(\mathbf{x})}{\partial x_{1}^{2}} & \frac{\partial^{2} f(\mathbf{x})}{\partial x_{2} \partial x_{1}} & \cdots & \frac{\partial^{2} f(\mathbf{x})}{\partial x_{n} \partial x_{1}} \\
\frac{\partial^{2} f(\mathbf{x})}{\partial x_{1} \partial x_{2}} & \frac{\partial^{2} f(\mathbf{x})}{\partial x_{2}^{2}} & \cdots & \frac{\partial^{2} f(\mathbf{x})}{\partial x_{n} \partial x_{2}} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial^{2} f(\mathbf{x})}{\partial x_{1} \partial x_{n}} & \frac{\partial^{2} f(\mathbf{x})}{\partial x_{2} \partial x_{n}} & \cdots & \frac{\partial^{2} f(\mathbf{x})}{\partial x_{n}^{2}}
\end{array}\right)
$$
```

The Hessian is commonly denoted as $H(\mathbf{x})$, $\nabla^2 f(\mathbf{x})$, $D_{xx^T}f(\mathbf{x})$, or $\operatorname{hess} f(\mathbf{x})$.

The elements on the diagonal of the Hessian are referred to as second-order own partial derivatives, and the elements off the diagonal are referred to as second-order cross partial derivatives.

```{admonition} Definition
:class: caution

Some terminologi:
- If $f$ is twice-differentiable at every point $x \in X$, then $f$ is said to be twice-differentiable on $X$.
- If $f$ is twice-differentiable on $X$ and $\frac{\partial^{2} f}{\partial x_{k} \partial x_{i}}$ is a continuous function on $X$ for all combinations of $i$ and $j$ then $f$ is said to be twice continuously differentiable on $X$. This is denoted by $f \in C^{2}$ on $X$.

```

It is possible to extend the process of differentiation for multivariate functions to even higher orders than second-order derivatives. Doing so for partial derivatives is relatively straight-forward. However, this will not be done in this course.

```{admonition} Hessian of the Cobb-Douglas production function
:class: tip

Suppose that we have a Cobb-Douglas production function:

$$
f(L, K)=A L^{\alpha} K^{\beta} .
$$

From earlier we know the partial derivatives of the Cobb-Douglas production function that constitute the gradient

$$
\nabla f(\mathbf{x}) 
= \left(\begin{array}{c}
\tfrac{\partial f(L,K)}{\partial L} \\
\tfrac{\partial f(L,K)}{\partial K}
\end{array}\right)
= \left(\begin{array}{c}
\alpha A L^{\alpha-1} K^{\beta} \\
\beta A L^{\alpha} K^{\beta-1} 
\end{array}\right).  
$$

Take the partial derivatives of the marginal product of labor

$$
\tfrac{\partial^2 f(L,K)}{\partial L \partial L} 
&= \tfrac{\partial}{\partial L} \left( \tfrac{\partial f(L,K)}{\partial L} \right) \\
&= \tfrac{\partial}{\partial L} \left( \alpha A L^{\alpha-1} K^{\beta}\right) \\
&= \alpha (\alpha-1) A L^{\alpha-2} K^{\beta} \\
\tfrac{\partial^2 f(L,K)}{\partial L \partial K} 
&= \tfrac{\partial}{\partial K} \left( \tfrac{\partial f(L,K)}{\partial L} \right) \\
&= \tfrac{\partial}{\partial K} \left( \alpha A L^{\alpha-1} K^{\beta}\right) \\
&= \alpha \beta A L^{\alpha-1} K^{\beta-1}
$$

Take the partial derivatives of the marginal product of capital

$$
\tfrac{\partial^2 f(L,K)}{\partial K \partial L} 
&= \tfrac{\partial}{\partial L} \left( \tfrac{\partial f(L,K)}{\partial K} \right) \\
&= \tfrac{\partial}{\partial L} \left( \beta A L^{\alpha} K^{\beta-1}\right) \\
&= \alpha \beta A L^{\alpha-1} K^{\beta-1} \\
\tfrac{\partial^2 f(L,K)}{\partial K \partial K} 
&= \tfrac{\partial}{\partial K} \left( \tfrac{\partial f(L,K)}{\partial K} \right) \\
&= \tfrac{\partial}{\partial K} \left( \beta A L^{\alpha} K^{\beta-1}\right) \\
&= \beta (\beta - 1) A L^{\alpha} K^{\beta-2}
$$

We can now set up the Hessian of the Cobb-Douglas production function

$$
\nabla^2 f(\mathbf{x}) 
= \left(\begin{array}{cc}
\tfrac{\partial^2 f(L,K)}{\partial L \partial L} & \tfrac{\partial^2 f(L,K)}{\partial L \partial K} \\
\tfrac{\partial^2 f(L,K)}{\partial K \partial L} & \tfrac{\partial^2 f(L,K)}{\partial K \partial K} 
\end{array} \right) 
= \left(\begin{array}{cc}
\alpha (\alpha-1) A L^{\alpha-2} K^{\beta} & \alpha \beta A L^{\alpha-1} K^{\beta-1} \\
\alpha \beta A L^{\alpha-1} K^{\beta-1} & \beta (\beta-1) A L^{\alpha} K^{\beta-2} 
\end{array} \right).
$$

Note that the Hessian is symmetric.
```

It turns out that the second-order cross partial derivatives are equal in general. This is known as **Young's theorem**.

```{admonition} Fact (Young's theorem)
:class: important

Suppose that $f(x_1,x_2,\dots,x_n)$ is a $C^2$ on its domain, X. Then, for each pair of indices $i$, $j$,

$$
\frac{\partial^2 f (\mathbf{x})}{\partial x_i \partial x_j} = \frac{\partial^2 f (\mathbf{x})}{\partial x_j \partial x_i}. 
$$

```

**Young's theorem** states that the order of differentiation does not matter for a $C^2$ function. The result is trivially true when $i=j$. This is the case of second-order own partial derivatives.


## Total differentiation

When calculating the partial derivative of a function $f$ with respect to $x_i$, we only allow $x_i$ to vary and keep all other variables constant. In contrast, when calculating the total derivative we allow all independent variables to vary

$$
df = \sum_{i=1}^n \frac{\partial f(\mathbf{x})}{\partial x_i}dx_i.
$$

$df$ is the total derivative of $f$ with respect to the change $\mathbf{dx}=(dx_1,dx_2,\dots,dx_n)$. Unlike the partial derivate the total derivate does not restrict the analysis to be local, i.e. $dx_i \rightarrow 0$. 

```{admonition} Example I
:class: tip

Consider the bivariate function $y=f(x_1,x_2)=a x_1 + b x_2$. The total derivative with respect to $x_1$ is then

$$
df=a dx_1 + b dx_2.
$$

```

```{admonition} Example II
:class: tip

Consider the bivariate function $y=f(x_1,x_2)=x_1 x_2$. The partial derivative with respect to $x_1$ is then

$$
df=x_2 dx_1 + x_1 dx_2.
$$
```

The total derivative, $df$, can be thought of as a linear approximation of the change in $f$ due to the change $\mathbf{dx}$.

$$
df \approx f(\mathbf{x} + \mathbf{dx}) - f(\mathbf{x}).
$$

Hence, we can use total differentiation to approximate $f$ around the point $\mathbf{x}^0$

$$
f(\mathbf{x}^0 + \mathbf{dx}) \approx f(\mathbf{x}^0) + \sum_{i=1}^n \frac{\partial f(\mathbf{x}^0)}{\partial x_i}dx_i.
$$

This is an example of a first order Taylor approximation.

## The chain rule

Many economic models involve composition functions. These are functions of one or serveral variables in wich the variables are themselves functions of other basic variables.

E.g. many models of economic growth regard production as a function of capital and labor, both which are functions of time. For these models, we can apply the **chain rule** to analyze how production changes over time due to changes in labor and capital.

```{admonition} Fact (chain rule I)
:class: important

When $z=f(x_1,x_2,\dots,x_n)$ with $x_i=g_i(t)$ for every $i$, then

$$
\frac{dz}{dt} = \sum_{i=1}^n \frac{\partial z}{\partial x_i} \frac{dx_i}{dt}
$$

```

As every variable, $x_i$, depends on the basic variable, $t$, a small change in $t$ sets off a chain reaction. The sum of the individual contributions is called the **total derivative** and is denoted $dz/dt$.

```{admonition} Calculating the growth rate of the production
:class: tip

The production of the economy is given by the Cobb-Douglas production function $y=f(L(t),K(t))$ where the labor and capital inputs are both functions of time.

Labor and capital is accumulated at constant growth rates

$$
\dot{L} \equiv \frac{dL}{dt} &= g_L L(t). \\
\dot{K} \equiv \frac{dK}{dt} &= g_K K(t). \\
$$

Use chain rule to calculate how production changes over time

$$
\frac{dy}{dt} 
&= \frac{\partial f(L,K)}{\partial L} \frac{dL}{dt} + \frac{\partial f(L,K)}{\partial K} \frac{dK}{dt} \\
&= \alpha A L^{\alpha-1} K^{\beta} g_L L + \beta A L^{\alpha} K^{\beta-1}  g_K K \\
&= \alpha A L^{\alpha} K^{\beta} g_L + \beta A L^{\alpha} K^{\beta}  g_K \\
&= (\alpha g_L + \beta  g_K) y.
$$

Divide both sides with the production, $y$

$$
\frac{\dot{y}}{y} = \alpha g_L + \beta  g_K.
$$

The growth rate of the economy is constant, and is given by dot product of the elasticities and growth rates with respect to each of the production inputs.

```

The chain rule can be generalized by allowing the variables, $x_i$, to be a function of more than one basic variable.

```{admonition} Fact (chain rule II)
:class: important

When $z=f(x_1,x_2,\dots,x_n)$ with $x_i=g_i(t_1,t_2,...,t_m)$ for every $i$, then

$$
\frac{\partial z}{\partial t_j} = \sum_{i=1}^n \frac{\partial z}{\partial x_i} \frac{\partial x_i}{\partial t_j}
$$

for each $j=1,2,\dots,m$

```

<!-- ## Implicit functions

Until now we have been working with explicit functions where the dependet variable, $y$, is on the left side of the equation and the independet variables, $x_i$, are on the right side

$$
y = f(x_1,x_2,\dots,x_n).
$$

Frequently, we have to work with implicit functions where the dependent variable cannot be separated from the independent variables

$$
G(x_1,x_2,\dots,x_n,y) = c.
$$

We still want to analyze how changes in the independet variables affect the dependent variable.

```{admonition} Fact (Implicit function theorem)
:class: important

Suppose that $G\left(x_{1}, x_{2}, \cdots, x_{n}, y\right)$ is a function that is at least once continuously differentiable around the point $\left(x_{1}^{*}, x_{2}^{*}, \cdots, x_{n}^{*}, y^{*}\right)$. Suppose also that

$$
G\left(x_{1}^{*}, x_{2}^{*}, \cdots, x_{n}^{*}, y^{*}\right)=c \text { for some constant } c
$$

and that

$$
\frac{\partial G}{\partial y}\left(x_{1}^{*}, x_{2}^{*}, \cdots, x_{n}^{*}, y^{*}\right) \neq 0
$$


Under these conditions, there is a function $y\left(x_{1}, x_{2}, \cdots, x_{n}\right)$ defined on some open ball $B$ around the point $\left(x_{1}^{*}, x_{2}^{*}, \cdots, x_{n}^{*}\right)$ that is at least once continuously differentiable such that:

$$
G\left(x_{1}, x_{2}, \cdots, x_{n}, y\left(x_{1}, x_{2}, \cdots, x_{n}\right)\right)=c \\
\text { for all }\left(x_{1}, x_{2}, \cdots, x_{n}\right) \in B
$$

$$
y^{*}=y\left(x_{1}^{*}, x_{2}^{*}, \cdots, x_{n}^{*}\right)
$$

$$
\frac{\partial y}{\partial x_{i}}\left(x_{1}^{*}, x_{2}^{*}, \cdots, x_{n}^{*}\right)=-\left(\frac{\frac{\partial G}{\partial x_{i}}\left(x_{1}^{*}, x_{2}^{*}, \cdots, x_{n}^{*}, y^{*}\right)}{\frac{\partial G}{\partial y}\left(x_{1}^{*}, x_{2}^{*}, \cdots, x_{n}^{*}, y^{*}\right)}\right) \\
\text { for each } i \in\{1,2, \cdots, n\}
$$

```

### Derivatives of implicit functions

Suppose that we know that some variable $y$ is a function of $n$ other variables $\left(x_{1}, x_{2}, \cdots, x_{n}\right)$. Sometimes it is not easy to explicitly characterise this function in the form

$$
y=f\left(x_{1}, x_{2}, \cdots, x_{n}\right) .
$$

In some cases, we might only be able to characterise the function implicitly, along the lines of a relationship of the form

$$
g\left(y, x_{1}, x_{2}, \cdots, x_{n}\right)=b
$$

where $b \in \mathbb{R}$ is some fixed constant.


Suppose that we want to obtain the partial derivative of $y$ with respect to $x_{k}$ in such a case. How would we do this?
Since $b \in \mathbb{R}$ is some fixed constant, we must have $d g=0$.
Note that the total differential for $g$ is

$$
d g=\left(\frac{\partial g}{\partial y}\right) d y+\sum_{i=1}^{n}\left(\frac{\partial g}{\partial x_{i}}\right) d x_{i}
$$

Thus we must have

$$
\left(\frac{\partial g}{\partial y}\right) d y+\sum_{i=1}^{n}\left(\frac{\partial g}{\partial x_{i}}\right) d x_{i}=0
$$


Suppose that the only variables that are allowed to change are $x_{k}$ and $y$. This means that $d x_{k} \neq 0$ and $d y \neq 0$. It also means that $d x_{i}=0$ for all $i \neq k$. Substituting these values into the above equation yields

$$
\left(\frac{\partial g}{\partial y}\right) d y+\left(\frac{\partial g}{\partial x_{k}}\right) d x_{k}=0
$$

This can be rearranged to obtain

$$
\left.\frac{d y}{d x_{k}}\right|_{d x_{i}=0 \text { for all } i \neq k}=\frac{-\left(\frac{\partial g}{\partial x_{k}}\right)}{\left(\frac{\partial g}{\partial y}\right)}
$$

Since we are holding $d x_{i}=0$ for all $i \neq k$, this is really a partial derivative. Thus we have

$$
\frac{\partial y}{\partial x_{k}}=\frac{-\left(\frac{\partial g}{\partial x_{k}}\right)}{\left(\frac{\partial g}{\partial y}\right)}
$$


### Some applications of implicit functions

Some potential applications of the implicit function theorem include the following:
- The slope of an indifference curve
- The slope of an iso-expenditure ("budget") line
- The slope of an isoquant
- The slope of an isocost

Before discussing these examples, we will consider the related concepts of level sets, upper contour sets and lower contour sets.


## Level sets and contour sets

Consider a function $f: X \rightarrow Y$, where $X \subseteq \mathbb{R}^{L}$ and $Y \subseteq \mathbb{R}$.

- A **level set** for the function $f$ defined with respect to a point in the domain $\widehat{x} \in X$ is defined to be

$$
f_{\widehat{x}}^{0}=\{x \in X: f(x)=f(\widehat{x})\} .
$$

- A **weak upper contour** set for the function $f$ defined with respect to a point in the domain $\widehat{x} \in X$ is defined to be

$$
f_{\widehat{x}}^{+}=\{x \in X: f(x) \geq f(\widehat{x})\} .
$$

- A **strong upper contour set** for the function $f$ defined with respect to a point in the domain $\widehat{X} \in X$ is defined to be

$$
f_{\widehat{x}}^{++}=\{x \in X: f(x)>f(\widehat{x})\} .
$$

- A **weak lower contour set** for the function $f$ defined with respect to a point in the domain $\widehat{X} \in X$ is defined to be

$$
f_{\widehat{x}}^{-}=\{x \in X: f(x) \leq f(\widehat{x})\} .
$$

- A **strong lower contour set** for the function $f$ defined with respect to a point in the domain $\widehat{X} \in X$ is defined to be

$$
f_{\widehat{x}}^{--}=\{x \in X: f(x)<f(\widehat{x})\} .
$$


### The slope of an indifference curve

Suppose that $U: \mathbb{R}_{+}^{L} \rightarrow \mathbb{R}$ is a utility function.

The level sets for a utility function are known as indifference curves. The indifference curve that passes through consumption bundle $\widehat{x} \in \mathbb{R}_{+}^{L}$ is defined to be

$$
U_{\widehat{x}}^{0}=\left\{x \in \mathbb{R}_{+}^{L}: U(x)=U(\widehat{x})\right\} .
$$

The (weak) upper contour sets for a utility function could be called consumption requirement sets. The consumption requirement set that is associated with the reference consumption bundle $\widehat{x} \in \mathbb{R}_{+}^{L}$ is defined to be

$$
U_{\widehat{x}}^{+}=\left\{x \in \mathbb{R}_{+}^{L}: U(x) \geq U(\widehat{x})\right\}
$$


Note that we could also define the level set and the (weak) upper contour set for a utility function in terms of a reference utility level, $\bar{U}$. I will leave the modification of the definitions for the case in which a reference utility level is employed as an exercise for you to attempt.
Note that any point $x \in \mathbb{R}_{+}^{L}$ that belongs to an indifference curve must yield the same level of utility.
This means that the change in utility around any indifference curve is zero.
In other words, $d U=0$ along an indifference curve.


Suppose that $L=2$. We have

$$
d U=\left(\frac{\partial U}{\partial x_{1}}\right) d x_{1}+\left(\frac{\partial U}{\partial x_{2}}\right) d x_{2}
$$

Along any indifference curve, we must have

$$
d U=\left(\frac{\partial U}{\partial x_{1}}\right) d x_{1}+\left(\frac{\partial U}{\partial x_{2}}\right) d x_{2}=0
$$

This can be rearranged to obtain

$$
\left.\frac{d x_{2}}{d x_{1}}\right|_{d U=0}=\frac{-\left(\frac{\partial U}{\partial x_{1}}\right)}{\left(\frac{\partial U}{\partial x_{2}}\right)}= -MRS_{12}(x)
$$

which is the formula for the slope of an indifference curve when $U: \mathbb{R}_{+}^{2} \rightarrow \mathbb{R}$.


### The slope of a budget line

A consumer's expenditure is given by the linear function $E: \mathbb{R}_{+}^{L} \rightarrow \mathbb{R}$ that is defined by

$$
E(x)=p^{T} x=\sum_{l=1}^{L} p_{l} x_{l}
$$

where $p \in \mathbb{R}_{++}^{L}$, so that $p_{l}>0$ for all $l \in\{1,2, \cdots, L\}$.

We will refer to this as the budget function, because the term "expenditure function" has a specific meaning in microeconomics that differs somewhat from this function.


The level sets for a budget function are known budget lines (or, if you prefer, budget hyper-planes).

The budget line that passes through consumption bundle $\omega \in \mathbb{R}_{+}^{L}$ is defined to be

$$
B_{\omega}^{0}(p, \boldsymbol{\omega})=\left\{x \in \mathbb{R}_{+}^{L}: E(x)=E(\boldsymbol{\omega})\right\} .
$$

In this case, we might think of $\omega \in \mathbb{R}_{+}^{L}$ as an endowment bundle.

The budget line that is consistent with an exogenous money income equal to $M \in \mathbb{R}_{+}$ is defined to be

$$
B_{M}^{0}(p, M)=\left\{x \in \mathbb{R}_{+}^{L}: E(x)=M\right\}
$$


The (weak) lower contour sets for a budget function are known budget sets. The budget set that is associated with the endowment bundle $\omega \in \mathbb{R}_{+}^{L}$ is defined to be

$$
B_{\omega}^{-}(p, \mathfrak{\omega})=\left\{x \in \mathbb{R}_{+}^{L}: E(x) \leq E(\mathfrak{\omega})\right\}
$$

The (weak) lower contour sets for a budget function are known budget sets. The budget set that is associated with an exogenous money income equal to $M \in \mathbb{R}_{+}$ is defined to be

$$
B_{M}^{-}(p, M)=\left\{x \in \mathbb{R}_{+}^{L}: E(x) \leq M\right\}
$$


Note that any point $x \in \mathbb{R}_{+}^{L}$ that belongs to a budget line must require the same level of expenditure. This means that the change in expenditure along any budget line is zero. In other words, $d E=0$ along a budget line.

Suppose that $L=2$. We have

$$
\begin{aligned}
d E &= \left(\frac{\partial E}{\partial x_{1}}\right) d x_{1}+\left(\frac{\partial E}{\partial x_{2}}\right) d x_{2} \\
&= \left(\frac{\partial\left(p_{1} x_{1}+p_{2} x_{2}\right)}{\partial x_{1}}\right) d x_{1} 
 +\left(\frac{\partial\left(p_{1} x_{1}+p_{2} x_{2}\right)}{\partial x_{2}}\right) d x_{2} \\
&= p_{1} d x_{1}+p_{2} d x_{2}
\end{aligned}
$$



Along any budget line, we must have

$$
d E=p_{1} d x_{1}+p_{2} d x_{2}=0
$$


This can be rearranged to obtain

$$
\left.\frac{d x_{2}}{d x_{1}}\right|_{d E=0}=\frac{-p_{1}}{p_{2}}
$$

which is the formula for the slope of a budget line when the consumption set is given by $\mathbb{R}_{+}^{2}$.

### The slope of an isoquant

Suppose that $F: \mathbb{R}_{+}^{K} \rightarrow \mathbb{R}_{+}$ is a single-product production function.

The level sets for a production function are known as isoquants. The isoquant that is consistent with $y \in \mathbb{R}_{+}$ units of output being produced is defined to be

$$
F_{y}^{0}=\left\{x \in \mathbb{R}_{+}^{K}: F(x)=y\right\}
$$

The (weak) upper contour sets for a production function are known as input requirement sets. The input requirement set that is associated with $y \in \mathbb{R}_{+}$ units of output being produced is defined to be

$$
F_{y}^{+}=\left\{x \in \mathbb{R}_{+}^{K}: F(x) \geq y\right\}
$$


Note that we could also define the level set and the (weak) upper contour set for a production function in terms of a reference input bundle, $\widehat{x}$. I will leave the modification of the definitions for the case in which a reference input bundle is employed as an exercise for you to attempt.
Note that any point $x \in \mathbb{R}_{+}^{K}$ that belongs to an isoquant must yield the same level of output.
This means that the change in output around any isoquant is zero.
In other words, $d F=0$ along an isoquant.


Suppose that $K=2$. We have

$$
d F=\left(\frac{\partial F}{\partial x_{1}}\right) d x_{1}+\left(\frac{\partial F}{\partial x_{2}}\right) d x_{2}
$$

Along any isoquant, we must have

$$
d F=\left(\frac{\partial F}{\partial x_{1}}\right) d x_{1}+\left(\frac{\partial F}{\partial x_{2}}\right) d x_{2}=0
$$

This can be rearranged to obtain

$$
\left.\frac{d x_{2}}{d x_{1}}\right|_{d F=0}=\frac{-\left(\frac{\partial F}{\partial x_{1}}\right)}{\left(\frac{\partial F}{\partial x_{2}}\right)}=-\operatorname{MRTS}_{12}(x)
$$

which is the formula for the slope of an isoquant when $F: \mathbb{R}_{+}^{2} \rightarrow \mathbb{R}_{+}$.



### The slope of an isocost

A firm's expenditure on inputs is given by the linear function $E: \mathbb{R}_{+}^{K} \rightarrow \mathbb{R}$ that is defined by

$$
E(x)=w^{T} x=\sum_{k=1}^{K} w_{k} x_{k}
$$

where $w \in \mathbb{R}_{++}^{K}$ is the input price vector.

Note that $w \in \mathbb{R}_{++}^{K}$ means that $w_{k}>0$ for all $k \in\{1,2, \cdots, K\}$.

We will refer to this as the budget function, because the term "cost function" has a specific meaning in microeconomics that differs somewhat from this function.



The level sets for a firm's budget function are known as isocosts.

The isocost line that passes through input bundle $\widehat{x} \in \mathbb{R}_{+}^{K}$ is defined to be

$$
B_{\widehat{x}}^{0}(w, \widehat{x})=\left\{x \in \mathbb{R}_{+}^{K}: E(x)=E(\widehat{x})\right\} .
$$

In this case, we might think of $\omega \in \mathbb{R}_{+}^{L}$ as an endowment bundle.

The isocost line that is consistent with a particular level of expenditure on inputs equal to $C \in \mathbb{R}_{+}$ is defined to be

$$
B_{C}^{0}(p, M)=\left\{x \in \mathbb{R}_{+}^{K}: E(x)=C\right\} .
$$


Note that any point $x \in \mathbb{R}_{+}^{K}$ that belongs to an isocost line must involve the same level of expenditure on inputs.
This means that the change in expenditure on inputs along any isocost line is zero.
In other words, $d E=0$ along an isocost line.

Suppose that $K=2$. We have

$$
\begin{aligned}
d E &= \left(\frac{\partial E}{\partial x_{1}}\right) d x_{1}+\left(\frac{\partial E}{\partial x_{2}}\right) d x_{2} \\
&= \left(\frac{\partial\left(w_{1} x_{1}+w_{2} x_{2}\right)}{\partial x_{1}}\right) d x_{1} 
 +\left(\frac{\partial\left(w_{1} x_{1}+w_{2} x_{2}\right)}{\partial x_{2}}\right) d x_{2} \\
&= w_{1} d x_{1}+w_{2} d x_{2}
\end{aligned}
$$


Along any isocost line, we must have

$$
d E=w_{1} d x_{1}+w_{2} d x_{2}=0
$$

This can be rearranged to obtain

$$
\left.\frac{d x_{2}}{d x_{1}}\right|_{d E=0}=\frac{-w_{1}}{w_{2}}
$$

which is the formula for the slope of an isocost line for a firm with a production technology that involves two inputs.


## Total differentials

Consider a function $f: S \longrightarrow \mathbb{R}$, where $S \subseteq \mathbb{R}^{n}$ is an open set. This function can be written as $f\left(x_{1}, x_{2}, \cdots, x_{n}\right)$. Suppose that this function is at least twice continuously differentiable with respect to all of its arguments.

Suppose that we want to consider the impact of a small change in each of the independent variables on the value of the function.

Imagine that the initial values of the independent variables are

$$
x=\left(x_{1}, x_{2}, \cdots, x_{n}\right)
$$

Following the change, the new values of the independent variables are

$$
x+d x=\left(x_{1}+d x_{1}, x_{2}+d x_{2}, \cdots, x_{n}+d x_{n}\right)
$$

Note that the vector of changes in the independent variables is

$$
\begin{aligned}
d x &= x+d x-x \\
&= \left(x_{1}+d x_{1}, x_{2}+d x_{2}, \cdots, x_{n}+d x_{n}\right)
-\left(x_{1}, x_{2}, \cdots, x_{n}\right) \\
&=  \left(d x_{1}, d x_{2}, \cdots, d x_{n}\right) .
\end{aligned}
$$

The actual change in the value of the function that is induced by these changes in the independent variables is

$$
d f=f(x+d x)-f(x)
$$

When the function is non-linear, this actual change can be rather complicated to calculate explicitly.


As such, we will often employ a first-order (or linear) differential approximation for $d f$. This approximation is known as the **(first-order) total differential** of the function. It is given by

$$
d f \approx \sum_{i=1}^{n}\left(\frac{\partial f}{\partial x_{i}}\right) d x_{i}
$$

If the function is twice continuously differentiable in all of its arguments and the change in each of the independent variables is sufficiently small, then this approximation for $d f$ will be reasonably accurate.

## The inverse function theorem

This is Theorem 15.9 in {cite:ps}`simon1994` (p. 367).

```{admonition} Fact
:class: important

Consider a function of the form $f: \mathbb{R}^{n} \longrightarrow \mathbb{R}^{n}$.

Suppose that:
- (a) $f: \mathbb{R}^{n} \longrightarrow \mathbb{R}^{n}$ is at least once continuously differentiable;
- (b) $f\left(x^{*}\right)=y^{*}$; and
- (c) The Jacobian matrix $D_{x} f$ is non-singular at the point $x^{*}$.

If this is the case, then:
- (i) There exists an open ball $B_{r}\left(x^{*}\right)$ around the point $x^{*}$, and an open set $V$ around the point $y^{*}$, such that $f: B_{r}\left(x^{*}\right) \longrightarrow V$ is both one-to-one and onto;
- (ii) The inverse map $f^{-1}: V \longrightarrow B_{r}\left(x^{*}\right)$ is at least once continuously differentiable; and
- (iii) The derivative of the inverse function at the point $x^{*}$ is equal to the inverse of the derivative function at the point $x^{*}$ (that is $\left(D_{x} f^{-1}\right)\left(f\left(x^{*}\right)=\left(D_{x} f\left(x^{*}\right)\right)^{-1}\right)$.

```

### An elasticity application of the inverse function theorem

Consider a function of the form $f: S \longrightarrow \mathbb{R}$, where $S \subseteq \mathbb{R}^{n}$ is an open set.
Suppose that this function is at least once continuously differentiable in all of its arguments.

The elasticity of $f$ with respect to the variable $x_{i}$ at the point $(x, f(x))$ is given by the formula

$$
\varepsilon_{i}^{f}=\left(\frac{x_{i}}{f(x)}\right)\left(\frac{\partial f}{\partial x_{i}}\right)
$$

Another formula for the elasticity of $f$ with respect to the variable $x_{i}$ at the point $(x, f(x))$ that is sometimes useful is

$$
\varepsilon_{i}^{f}=\frac{\partial \ln (f(x))}{\partial \ln \left(x_{i}\right)}
$$

We will use the chain rule of differentiation and the inverse function theorem to show that these two formulas are equivalent. Note that

$$
\frac{\partial \ln (f(x))}{\partial \ln \left(x_{i}\right)}=\left(\frac{\partial \ln (f(x))}{\partial f(x)}\right)\left(\frac{\partial f(x)}{\partial x_{i}}\right)\left(\frac{\partial x_{i}}{\partial \ln \left(x_{i}\right)}\right)
$$

from the chain rule of differentiation.

We know from the inverse function theorem that

$$
\left(\frac{\partial x_{i}}{\partial \ln \left(x_{i}\right)}\right)=\frac{1}{\left(\frac{\partial \ln \left(x_{i}\right)}{\partial x_{i}}\right)}
$$

Thus we have

$$
\frac{\partial \ln (f(x))}{\partial \ln \left(x_{i}\right)}=\left(\frac{\partial \ln (f(x))}{\partial f(x)}\right)\left(\frac{\partial f(x)}{\partial x_{i}}\right)\left(\frac{1}{\left(\frac{\partial \ln \left(x_{i}\right)}{\partial x_{i}}\right)}\right)
$$

Note that $\frac{\partial \ln (f(x))}{\partial f(x)}=\frac{1}{f(x)}$ and $\frac{\partial \ln \left(x_{i}\right)}{\partial x_{i}}=\frac{1}{x_{i}}$. This means that

$$
\frac{\partial \ln (f(x))}{\partial \ln \left(x_{i}\right)}=\left(\frac{1}{f(x)}\right)\left(\frac{\partial f(x)}{\partial x_{i}}\right)\left(\frac{1}{\frac{1}{x_{i}}}\right)=\left(\frac{1}{f(x)}\right)\left(\frac{\partial f(x)}{\partial x_{i}}\right)\left(x_{i}\right)
$$

This can be rearranged to obtain

$$
\frac{\partial \ln (f(x))}{\partial \ln \left(x_{i}\right)}=\left(\frac{x_{i}}{f(x)}\right)\left(\frac{\partial f}{\partial x_{i}}\right) .
$$


## Homogeneous functions

Consider a function $f: S \longrightarrow \mathbb{R}$, where $S \subseteq \mathbb{R}^{n}$.

This function can be written as $f\left(x_{1}, x_{2}, \cdots, x_{n}\right)$.

Let $\lambda>0$ be a positive real number.

```{admonition} Definition
:class: caution

The function $f\left(x_{1}, x_{2}, \cdots, x_{n}\right)$ is said to be **homogeneous of degree $r$** if

$$
f\left(\lambda x_{1}, \lambda x_{2}, \cdots, \lambda x_{n}\right)=\lambda^{r} f\left(x_{1}, x_{2}, \cdots, x_{n}\right)
$$

for all $\left(x_{1}, x_{2}, \cdots, x_{n}\right) \in S$ and all $\lambda>0$.

```

```{admonition} Definition
:class: caution

A function that is homogeneous of degree one is said to be **linearly homogeneous**.

```


Homogeneity is a cardinal property, not an ordinal one.
This means that homogeneity will not necessarily be preserved under a strictly increasing transformation.
An ordinal property that is somewhat similar to homogeneity is that of homotheticity.
A discussion of homotheticity can be found in {cite:ps}`simon1994` (pp. 483 and 500-504).


## Euler's theorem

```{admonition} Fact
:class: important

Suppose that the function $f\left(x_{1}, x_{2}, \cdots, x_{n}\right)$ is homogeneous of degree $r$. In this case we have

$$
\sum_{i=1}^{n} x_{i}\left(\frac{\partial f}{\partial x_{i}}\right)=r f\left(x_{1}, x_{2}, \cdots, x_{n}\right) .
$$

```

This result is known as **Euler's theorem**.

It is straightforward to explicitly derive this result from the definition of homogeneity of degree $r$. The following proof is based on the one in {cite:ps}`haeussler1987` (p. 723).

Since the function $f\left(x_{1}, x_{2}, \cdots, x_{n}\right)$ is homogeneous of degree $r$, we know that

$$
f\left(\lambda x_{1}, \lambda x_{2}, \cdots, \lambda x_{n}\right)=\lambda^{r} f\left(x_{1}, x_{2}, \cdots, x_{n}\right)
$$

for any choice of $\lambda>0$.

Consider the left-hand side of this definition first. Let $z_{i}=\lambda x_{i}$ for all $i \in\{1,2, \cdots, n\}$. Totally differentiating

$$
f\left(\lambda x_{1}, \lambda x_{2}, \cdots, \lambda x_{n}\right)=f\left(z_{1}, z_{2}, \cdots, z_{n}\right)
$$

yields

$$
d f=\sum_{i=1}^{n}\left(\frac{\partial f}{\partial z_{i}}\right) d z_{i}
$$

Dividing both sides of this total differential by $d \lambda \neq 0$ yields

$$
\frac{d f}{d \lambda}=\sum_{i=1}^{n}\left(\frac{\partial f}{\partial z_{i}}\right)\left(\frac{d z_{i}}{d \lambda}\right)
$$


Suppose that we hold all of the $x_{i}$ variables constant and only allow $\lambda$ to vary. This means that $d x_{i}=0$ for all $i \in\{1,2, \cdots, n\}$ and $d \lambda \neq 0$. This yields

$$
\left.\frac{d f}{d \lambda}\right|_{d x_{i}=0 \text { for all } i}=\sum_{i=1}^{n}\left(\frac{\partial f}{\partial z_{i}}\right)\left(\left.\frac{d z_{i}}{d \lambda}\right|_{d x_{i}=0 \text { for all } i}\right) .
$$

Note that

$$
\left.\frac{d f}{d \lambda}\right|_{d x_{i}=0 \text { for all } i}=\frac{\partial f}{\partial \lambda}
$$

and

$$
\left.\frac{d z_{i}}{d \lambda}\right|_{d x_{i}=0 \text { for all } i}=\frac{\partial z_{i}}{\partial \lambda}
$$


Thus we have

$$
\frac{\partial f}{\partial \lambda}=\sum_{i=1}^{n}\left(\frac{\partial f}{\partial z_{i}}\right)\left(\frac{\partial z_{i}}{\partial \lambda}\right)
$$

Note that

$$
\frac{\partial z_{i}}{\partial \lambda}=\frac{\partial\left(\lambda x_{i}\right)}{\partial \lambda}=x_{i}
$$

for all $i \in\{1,2, \cdots, n\}$.

Thus we know that the partial derivative of

$$
f\left(\lambda x_{1}, \lambda x_{2}, \cdots, \lambda x_{n}\right)
$$

with respect to $\lambda$ is

$$
\frac{\partial f\left(\lambda x_{1}, \lambda x_{2}, \cdots, \lambda x_{n}\right)}{\partial \lambda}=\sum_{i=1}^{n}\left(\frac{\partial f}{\partial z_{i}}\right) x_{i}
$$

where $z_{i}=\lambda x_{i}$ for all $i \in\{1,2, \cdots, n\}$.


Now consider the right hand-side of the following definition for a function that is homogeneous of degree $r$ :

$$
f\left(\lambda x_{1}, \lambda x_{2}, \cdots, \lambda x_{n}\right)=\lambda^{r} f\left(x_{1}, x_{2}, \cdots, x_{n}\right)
$$

for any choice of $\lambda>0$.

Note that $\lambda$ does not appear in the term $\left(x_{1}, x_{2}, \cdots, x_{n}\right)$. As such, the partial derivative of $\lambda^{r} f\left(x_{1}, x_{2}, \cdots, x_{n}\right)$ with respect to $\lambda$ is

$$
\frac{\partial \lambda^{r} f\left(x_{1}, x_{2}, \cdots, x_{n}\right)}{\partial \lambda}=r \lambda^{r-1} f\left(x_{1}, x_{2}, \cdots, x_{n}\right) .
$$


Thus we have

$$
\begin{aligned}
f\left(\lambda x_{1}, \lambda x_{2}, \cdots, \lambda x_{n}\right) &= \lambda^{r} f\left(x_{1}, x_{2}, \cdots, x_{n}\right) \\[5pt]
\Longleftrightarrow \\[5pt]
\frac{\partial f\left(\lambda x_{1}, \lambda x_{2}, \cdots, \lambda x_{n}\right)}{\partial \lambda} &=\frac{\partial \lambda^{r} f\left(x_{1}, x_{2}, \cdots, x_{n}\right)}{\partial \lambda} \\[5pt]
\Longleftrightarrow \\[5pt]
\sum_{i=1}^{n}\left(\frac{\partial f}{\partial z_{i}}\right) x_{i} &= r \lambda^{r-1} f\left(x_{1}, x_{2}, \cdots, x_{n}\right) .
\end{aligned}
$$


Note that when $\lambda=1$ we have $z_{i}=1 x_{i}=x_{i}$ for all $i \in\{1,2, \cdots, n\}$. This means that

$$
\left(\frac{\partial f}{\partial z_{i}}\right)=\left(\frac{\partial f}{\partial x_{i}}\right)
$$

for all $i \in\{1,2, \cdots, n\}$ when $\lambda=1$.

Note also that when $\lambda=1$ we have

$$
\lambda^{r-1}=1^{r-1}=1
$$

Now suppose that we evaluate both sides of this last equation at the point $\lambda=1$. This yields

$$
\sum_{i=1}^{n}\left(\frac{\partial f}{\partial x_{i}}\right) x_{i}=r f\left(x_{1}, x_{2}, \cdots, x_{n}\right)
$$

which is the result from Euler's theorem.


### Applications of homogeneity

Some applications of homogeneity include the following:
- Returns to scale for production technologies in general.
- Returns to scale for Cobb-Douglas production technologies.
- Euler aggregation for a Marshallian demand function.
- Product exhaustion under perfect competition and constant returns to scale.


### Returns to scale

Suppose that an $n$ input and one output production technology can be represented by a production function of the form

$$
Q=f\left(L_{1}, L_{2}, \cdots, L_{n}\right) .
$$

What happens if we increase all of the inputs by the same proportion?

Specifically, suppose that we move to an input bundle of the form $\left(\lambda L_{1}, \lambda L_{2}, \cdots, \lambda L_{n}\right)$, where $\lambda>0$.


#### Decreasing returns to scale

The production technology is said to display **decreasing returns to scale** if this increase in all of the inputs induces a less than proportionate change in the amount of output that can be produced.

In other words, production technology is said to display decreasing returns to scale if

$$
f\left(\lambda L_{1}, \lambda L_{2}, \cdots, \lambda L_{n}\right)<\lambda Q
$$

which is equivalent to

$$
f\left(\lambda L_{1}, \lambda L_{2}, \cdots, \lambda L_{n}\right)<\lambda f\left(L_{1}, L_{2}, \cdots, L_{n}\right) .
$$

Thus the production function for a production technology that displays decreasing returns to scale is either homogeneous of degree less than one or it is not homogeneous.

```{admonition} Note

A simple replication argument would suggest that decreasing returns to scale do not make any sense.

Studies that find decreasing returns to scale are probably really finding diminishing marginal products.

There is probably some unobserved (or imprecisely observed) input that is implicitly being held fixed or, at least, not varying in the same proportion as all of the other inputs.
```


#### Constant returns to scale
The production technology is said to display **constant returns to scale** if this increase in all of the inputs induces a proportionate change in the amount of output that can be produced.

In other words, production technology is said to display constant returns to scale if

$$
f\left(\lambda L_{1}, \lambda L_{2}, \cdots, \lambda L_{n}\right)=\lambda Q
$$

which is equivalent to

$$
f\left(\lambda L_{1}, \lambda L_{2}, \cdots, \lambda L_{n}\right)=\lambda f\left(L_{1}, L_{2}, \cdots, L_{n}\right) .
$$

Thus the production function for a production technology that displays constant returns to scale will be homogeneous of degree one. (Homogeneity of degree one is sometimes referred to as linear homogeneity.)

```{admonition} Note

Constant returns to scale production technologies are employed in the standard versions of the neoclassical model of economic growth. This model is often referred to as the Solow-Swan model of economic growth, because one of the seminal papers on this model was written by Robert Solow and the other was written by Trevor Swan. Note that the late Trevor Swan was an Australian economist who worked at the Australian National University.

The relevant references are:
- Solow, RM (1956), "A contribution to the theory of economic growth", The Quarterly Journal of Economics 70(1), February, pp. 65-94; and
- Swan, TW (1956), "Economic growth and capital accumulation", The Economic Record 32, November, pp. 334-361.
```

#### Increasing returns to scale
The production technology is said to display **increasing returns to scale** if this increase in all of the inputs induces a more than proportionate change in the amount of output that can be produced.

In other words, production technology is said to display increasing returns to scale if

$$
f\left(\lambda L_{1}, \lambda L_{2}, \cdots, \lambda L_{n}\right)>\lambda Q
$$

which is equivalent to

$$
f\left(\lambda L_{1}, \lambda L_{2}, \cdots, \lambda L_{n}\right)>\lambda f\left(L_{1}, L_{2}, \cdots, L_{n}\right) .
$$

Thus the production function for a production technology that displays increasing returns to scale is either homogeneous of degree more than one or it is not homogeneous.


```{admonition} Note

The returns to scale displayed by some production technologies might vary with input vector.  In such cases, the production technology will not necessarily display either constant returns to scale or increasing returns to scale over the entire set of possible values for the input vector.
```


### Cobb-Douglas production functions

Suppose that an two input and one output production technology can be represented by a production function of the form

$$
Q=f(L, K)=A L^{\alpha} K^{\beta} .
$$

This type of production function is known as a Cobb-Douglas production function.


Suppose that $\lambda>0$. Note that

$$
\begin{aligned}
f(\lambda L, \lambda K) & =A(\lambda L)^{\alpha}(\lambda K)^{\beta} \\
& =A \lambda^{\alpha} L^{\alpha} \lambda^{\beta} K^{\beta} \\
& =\lambda^{\alpha+\beta} A L^{\alpha} K^{\beta} \\
& =\lambda^{\alpha+\beta} f(L, K)
\end{aligned}
$$

Thus we know that the Cobb-Douglas production function is homogeneous of degree $(\alpha+\beta)$.

- If $(\alpha+\beta)<1$, then the Cobb-Douglas production function displays decreasing returns to scale;
- If $(\alpha+\beta)=1$, then the Cobb-Douglas production function displays constant returns to scale; and
- If $(\alpha+\beta)>1$, then the Cobb-Douglas production function displays increasing returns to scale.


### Euler aggregation

Suppose that a consumer's Marshallian demand for commodity $k$ is given by the function

$$
\begin{aligned}
Q_{k} & =x_{k}\left(p_{1}, p_{2}, \cdots, p_{n}, y\right) \\
& =x_{k}(p, y) .
\end{aligned}
$$

It can be shown that under certain circumstance, Marshallian demand functions are homogeneous of degree zero.

We will not provide a formal proof of this proposition here. However, the result is fairly intuitive. If all prices and income increase by the same proportion, then the budget constraint for the consumer does not change. If his or her preferences remain the same, then the fact that the budget constraint has not changed would suggest that the choice problem that faces the consumer has not changed in any real sense. As such, the consumer's optimal consumption bundle should not have changed either.

If Marshallian demand functions are homogeneous of degree zero, then the Marshallian demand for commodity $k$ will be homogeneous of degree zero.
In such circumstances, we know from Euler's theorem that

$$
\begin{aligned}
& y\left(\frac{\partial x_{k}(p, y)}{\partial y}\right)+\sum_{i=1}^{n} p_{i}\left(\frac{\partial x_{k}(p, y)}{\partial p_{i}}\right) \\
= & (0) x_{k}\left(p_{1}, p_{2}, \cdots, p_{n}, y\right) .
\end{aligned}
$$

This can be simplified to obtain

$$
y\left(\frac{\partial x_{k}(p, y)}{\partial y}\right)+\sum_{i=1}^{n} p_{i}\left(\frac{\partial x_{k}(p, y)}{\partial p_{i}}\right)=0
$$


This can be rearranged to obtain

$$
\sum_{i=1}^{n} p_{i}\left(\frac{\partial x_{k}(p, y)}{\partial p_{i}}\right)=-y\left(\frac{\partial x_{k}(p, y)}{\partial y}\right)
$$

Upon dividing both sides of this equation by $x_{k}(p, y)$, we obtain

$$
\begin{aligned}
& \sum_{i=1}^{n}\left(\frac{p_{i}}{x_{k}(p, y)}\right)\left(\frac{\partial x_{k}(p, y)}{\partial p_{i}}\right) \\
= & -\left(\frac{y}{x_{k}(p, y)}\right)\left(\frac{\partial x_{k}(p, y)}{\partial y}\right) .
\end{aligned}
$$

Thus we have

$$
\sum_{i=1}^{n} \varepsilon_{i}^{k}=-\varepsilon_{y}^{k}
$$

where

$$
\varepsilon_{i}^{k}=\left(\frac{p_{i}}{x_{k}(p, y)}\right)\left(\frac{\partial x_{k}(p, y)}{\partial p_{i}}\right)
$$

is the elasticity of demand for commodity $k$ with respect to the price of good $l$ and

$$
\varepsilon_{y}^{k}=\left(\frac{y}{x_{k}(p, y)}\right)\left(\frac{\partial x_{k}(p, y)}{\partial y}\right)
$$

is the income elasticity of demand for commodity $k$.

As far as I am aware, this well known result does not have a name. But it could be referred to as Euler aggregation, because it makes use of Euler's theorem.


### Product exhaustion

Consider a profit-maximising firm that has a single output $(Q)$ and two inputs $(L$ and $K$ ) production technology that displayys constant returns to scale. This production technology can be represented by a production function of the form

$$
Q=f(L, K)
$$

Suppose that this firm is a price-taker in both the ouput market and all input markets.
Constant returns to scale imply that the production function is homogeneous of degree one. Thus we know from Euler's theorem that

$$
\left(\frac{\partial f}{\partial L}\right) L+\left(\frac{\partial f}{\partial K}\right) K=f(L, K)
$$


Recall that the first-order conditions for profit maximisation by a firm with these characteristics are

$$
\left(\frac{\partial f}{\partial L}\right)=\frac{w}{p}
$$

and

$$
\left(\frac{\partial f}{\partial K}\right)=\frac{r}{p}
$$

where $p$ is the output price, $w$ is the input price for labour $(L)$ and $r$ is the input price for capital $(K)$.

Upon substituting these FOCs into Equation (1), we obtain

$$
\left(\frac{w}{p}\right) L+\left(\frac{r}{p}\right) K=f(L, K) .
$$

This can be rearranged to obtain

$$
w L+r K=p f(L, K) .
$$

In other words, the firm's revenue from sales of its output will be exactly equal to the firm's expenditure on inputs. This result, which implies zero profits for a perfectly competitive firm with a constant returns to scale production technology, is known as product exhaustion.

(Note that profit here means economic profit, not accounting profit.)
 -->
