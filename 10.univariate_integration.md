---
jupytext:
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

```{admonition} DRAFT
:class: danger

This lecture notes are INCOMPLETE!
```


# üìñ Univariate integration 

<small>‚è± <span class="eta"></span> | <span class="words"></span> words</small>

````{dropdown} Sources and reading guide

```{figure} _static/img/bibliography/shsc2016.png
:width: 100px
:align: left
```
{cite:ps}`sydsaeter2016`

Chapter 9 (pp. 319-373)

<div style="clear: both"></div>

**Univariate integration section**

These are references that are suitable for an elementary course on mathematical economics:
- {cite:ps}`bradley2013`: Chapter 8 (pp. 427-476)
- {cite:ps}`haeussler1987`: Chapters 14 and 15 (pp. 533-645)
- {cite:ps}`shannon1995`: Chapter 9 (pp. 408-449)

These are references that are suitable for a first-year undergraduate course for mathematics majors on calculus:
- {cite:ps}`kline1967`: Chapters 3, 5, 6, 9, 10, 11, 12, 14, 15, and 16
- {cite:ps}`silverman1969`: Chapters 7 and 14
- {cite:ps}`spivak2006`: Chapters 13, 14, 18, and 19

These references are suitable for an intermediate course on mathematical economics:
- {cite:ps}`chiang2005`: Chapter 14
- {cite:ps}`leonard1992`: The Appendix to Chapter 2 (pp. 111-113)
- {cite:ps}`simon1994`: Appendix A4


**Consumer demand and consumer welfare section**

These are references that are suitable for a first-year undergraduate economics course:
- {cite:ps}`alchian1983`: Chapter 2 (pp. 13-44)
- {cite:ps}`case1989`: Chapters 4-6 (pp. 77-162)
- {cite:ps}`gans2009`: Chapters 4, 5, 7 and 22 (pp. 62-112, 134-154 and 486-515)
- {cite:ps}`hamermesh2006`: Chapters 2, 5 and 6 (pp. 15-24 and 49-77)
- {cite:ps}`heyne1991`: Chapter 2 (pp. 15-45)

These are references that are suitable for a second-year undergraduate economics course:
- {cite:ps}`hirshleifer1988`: Chapters 2 and 7E (pp. 23-54 and 204-212)
- {cite:ps}`hirshleifer2005`: Chapters 2 and 7.3
- {cite:ps}`nicholson1987`: Chapters 1 and 12 (Consumers Surplus) (pp. 5-21 and 334)
- {cite:ps}`varian1987`: Chapters 1 and 15 (pp. 1-19 and 242-266)


These are references that are suitable for a third-year undergraduate economics course:
- {cite:ps}`gravelle1981`: Section C of Chapter 4 (pp. 103-111)
- {cite:ps}`nicholson1998`: Chapters 1, 5 (Consumer Surplus), and 15 (pp. 3-22, 152-157, and 438-458)
- {cite:ps}`takayama1993`: Appendix C (pp. 621-647)
- {cite:ps}`varian1992`: Chapter 10 (pp. 160-171)

**Producer supply and producer welfare section**

- {cite:ps}`alchian1983`: pp. 63-64
- {cite:ps}`hamermesh2006`: Chapters 1, 2, and 7 (pp. 3-24 and 81-90)

````


## Anti-derivatives and indefinite integrals


```{admonition} Definition
:class: caution

Let $I \in \mathbb{R}$ be a non-empty open interval of real numbers that contains more than a single point. In otherwords,
$I=(a, b)=\{x \in \mathbb{R}: a<x<b\}$
wherea $\in \mathbb{R}, b \in \mathbb{R}$, and $a<b$

Let $f: I \longrightarrow \mathbb{R}$ be some given univariate real-valued function. Suppose that there exists some function $F: I \longrightarrow \mathbb{R}$ such that

$$
F^{\prime}(x)=\frac{d F(x)}{d x}=f(x) \text { for all } x \in I
$$

In this case, the function $F(x)$ is said to be an **anti-derivative** of the function $f(x)$ on the interval $I$

```

```{admonition} Example
:class: tip

$$
f(x) = 3x^2 + 4x + 1 \quad \iff \quad F(x) = x^3 + 2x^2 + x + 5 $\text{ is anti-derivative}$
$$

$$
f(x) = \exp(x) \quad \iff \quad F(x) = exp(x)-1 $\text{ is anti-derivative}$
$$

```

### Anti-derivatives are NOT unique

If the function $F(x)$ is an anti-derivative of the function $f(x)$ on the interval $I$, then so is the function $G(x)=F(x)+C$, where $C \in \mathbb{R}$ is some fixed real number. 

This can be seen by differentiating $G(x)$ with respect to $x$. Upon doing this, we obtain

$$
\frac{d}{d x}(F(x)+C)=\frac{d F(x)}{d x}+\frac{d C}{d x}=f(x)+0=f(x)
$$

The constant $C \in \mathbb{R}$ is known as an *arbitrary constant* because it can take the form of any given real number. In effect, if the function $F(x)$ is an anti-derivative of the function $f(x)$ on the interval $I$, then there is an entire family of such anti-derivatives of $f(x)$ on the interval $I$. This family is given by the set

$$
\{F(x)+C: C \in \mathbb{R}\}
$$


When the domain of a univariate real-valued function $f(x)$ takes the form of a connected open interval of real numbers $I=(a, b)$, and if $F(x)$ is an anti-derivative of $f(x)$, then every anti-derivative of $f(x)$ must belong to the set $\{F(x)+C: C \in \mathbb{R}\}$

However, this result is not true when the domain of the function $f(x)$ is not a connected open interval of real numbers. This is established by the following counter-example that involves a non-connected (that is, dis-joint) domain for the function $f(x)$


Suppose that

$$
\begin{array}{r}
f(x)=2 x \text { for all } x \in(0,1) \cup(2,3), \\
F(x)= \begin{cases}x^{2} & \text { if } x \in(0,1), \\
x^{2}+1 & \text { if } x \in(2,3),\end{cases}
\end{array}
$$

and

$$
G(x)= \begin{cases}x^{2}+1 & \text { if } x \in(0,1) \\ x^{2} & \text { if } x \in(2,3) .\end{cases}
$$

Note that $F^{\prime}(x)=G^{\prime}(x)=f(x)$ for all $x \in(0,1) \cup(2,3)$. Thus both $F(x)$ and $G(x)$ are anti-derivatives of $f(x)$
However, there is no single constant $C \in \mathbb{R}$ such that $G(x)=F(x)+C$ for all $x \in(0,1) \cup(2,3)$


The problem that occurs in this counter-example is as follows:
- The arbitrary constant that is required to ensure that $G(x)=F(x)+C$ for all $x \in(0,1)$ (namely $C_{1}=1$ ) is different to the arbitrary constant that is required to ensure that $G(x)=F(x)+C$ for all $x \in(2,3)$ (namely $C_{2}=-1$ )
- While the result that the entire set of anti-derivatives of $f(x)$ can be found by adding different single arbitrary constants to a particular anti-derivative of $f(x)$ does not apply in this counter-example as a whole, it does apply to any case where we restrict the domain of the function to a subset of the entire domain that is a connected open interval
- In particular, the result applies if we restrict the domain in the counter-example to be either $(0,1)$ or $(2,3)$


```{admonition} Example(quick exercise)
:class: tip

Shout out the anti-derivative

$$
f(x) = 0
$$

$$
f(x)=5
$$

$$
f(x)=x
$$

$$
f(x)=6 x^2
$$

$$
f(x)=\frac{1}{x}
$$

```

## Indefinite integral

```{admonition} Definition
:class: caution

Suppose that the function $F(x)$ is an anti-derivative of the function $f(x)$ on the connected open interval $I$. 

The **indefinite integral** of $f(x)$, denoted by $\int f(x) d x$, is the set of all anti-derivatives of fucntion $f(x)$

$$
\int f(x) d x = \{ F(x)+C: C \in \mathbb{R} \}
$$

```

Note, however, that it is common to drop the set notation and simply use the integral sign to denote a generic member of the set of all anti-derivatives of $f(x)$ on the interval $I$. 

In other words, the indefinite integral of $f(x)$ on the interval $I$ is

$$
\int f(x) d x = F(x)+C: C \in \mathbb{R}
$$

where $C \in \mathbb{R}$ is an arbitrary constant. Note that here, the arbitrary constant $C$ is interpreted as being truly arbitrary, rather than taking on a particular value


### Some terminology

Suppose that $f: I \longrightarrow \mathbb{R}$, where $I \subseteq \mathbb{R}$ is a connected open interval, and $F^{\prime}(x)=f(x)$ for all $x \in I$

- $\int f(x) d x=F(x)+C$ is the **indefinite integral** of $f(x)$
- $f(x)$ is the **integrand**
- $d x$ means "with respect to $x$ ", $x$ is the variable of integration
- $F(x)$ is an **anti-derivative** of $f(x)$
- $C$ is an arbitrary constant


## Properties of indefinite integral

Suppose that $f: I \longrightarrow \mathbb{R}$ is at least once continuously differentiable on $I$, where $I \subseteq \mathbb{R}$ is a connected open interval, and $F^{\prime}(x)=f(x)$ for all $x \in I$. The following formulae apply to $f(x)$

1. $\frac{d}{d x} \int f(x) d x=f(x)$

2. $d \int f(x) d x=f(x) d x$

3. $\int f^{\prime}(x) d x=f(x)+C$

We will now provide an informal justification for each of these results


Claim: $\frac{d}{d x} \int f(x) d x=f(x)$
- Informal proof
- Suppose that $F(x)$ is an anti-derivative of $f(x)$
- This means that $\int f(x)=F(x)+C$
- Clearly, we must have $\frac{d}{d x} \int f(x)=\frac{d}{d x}(F(x)+C)$
- But $\frac{d}{d x}(F(x)+C)=\frac{d}{d x} F(x)+0=\frac{d}{d x} F(x)=f(x)$, because $F(x)$ is an anti-derivative of $f(x)$ and $C$ is an (albeit arbitrary) constant
- Thus we have $\frac{d}{d x} \int f(x) d x=f(x)$


Claim: $d \int f(x) d x=f(x) d x$
- Informal proof
- Suppose that $F(x)$ is an anti-derivative of $f(x)$
- This means that $\int f(x)=F(x)+C=G(x)$
- Recall that $d G(x) \approx \frac{d G(x)}{d x} d x=f(x) d x$
- This approximation is very accurate for really small values of $\delta x$ when $G(x)$ is well behaved. In such circumstances, we will have $\int d G(x)=\int f(x) d x$
- Differentiating both sides of this equation with respect to $x$ yields $d G(x)=f(x) d x$, so that we have $d \int f(x) d x=f(x) d x$


Claim: $\int f^{\prime}(x) d x=f(x)+C$
- Informal proof
- Suppose that $f(x)$ is at least once continuously differentiable, and denote its derivative by $f^{\prime}(x)$
- Let $F(x)=f(x)+C$, where $C$ is an arbitrary constant
- Clearly we must have $\frac{d}{d x} F(x)=\frac{d}{d x} f(x)+0=\frac{d}{d x} f(x)=f^{\prime}(x)$
- Furthermore, we have already shown that $\frac{d}{d x} \int g(x) d x=g(x)$. This means that we must have $\frac{d}{d x} \int f^{\prime}(x) d x=f^{\prime}(x)$
- Thus we have $\frac{d}{d x} \int f^{\prime}(x) d x=\frac{d}{d x} F(x)$,
- Upon integrating both sides of this equation, we obtain $\int f^{\prime}(x) d x=F(x)$, so that we have $\int f^{\prime}(x) d x=f(x)+C$



Suppose that $f: I \longrightarrow \mathbb{R}$ and $g: I \longrightarrow \mathbb{R}$ are both at least once continuously differentiable on $I$, where $I \subseteq \mathbb{R}$ is a connected open interval
Suppose also that $k \in \mathbb{R}$ is some given constant, $C \in \mathbb{R}$ is an arbitrary constant, $F^{\prime}(x)=f(x)$ for all $x \in I$, and $G^{\prime}(x)=g(x)$ for all $x \in I$

The following formulae apply to $f(x)$ and $g(x)$

1. $\int[f(x)+g(x)] d x=\int f(x) d x+\int g(x) d x=F(x)+G(X)+C$

2. $\int k f(x) d x=k \int f(x) d x=k F(x)+C$

We will provide an informal justification for each of these two results shortly
But first, note that the above two results can be used to establish the following result


Suppose that the functions $f_{i}: I \longrightarrow \mathbb{R}, i \in\{1,2, \cdots, n\}$, are all at least once continuously differentiable on $I$, where $I \subseteq \mathbb{R}$ is a connected open interval
Suppose also that $k_{i} \in \mathbb{R}, i \in\{1,2, \cdots, n\}$, are some given constants, and $C \in \mathbb{R}$ is an arbitrary constant
Suppose as well that $F_{i}^{\prime}(x)=f_{i}(x)$ for all $x \in I$ and for each $i \in\{1,2, \cdots, n\}$
The following formula applies to $\left\{f_{i}(x)\right\}_{i=1}^{n}$

$$
\begin{aligned}
& \int\left[\sum_{i=1}^{n} k_{i} f_{i}(x)\right] d x=\sum_{i=1}^{n}\left[\int k_{i} f_{i}(x) d x\right] \\
& =\sum_{i=1}^{n}\left[k_{i} \int f_{i}(x) d x\right]=\sum_{i=1}^{n} k_{i} F_{i}(x)+C 
\end{aligned}
$$


Claim:  $\int[f(x)+g(x)] d x=\int f(x) d x+\int g(x) d x=F(x)+G(x)+C$

- Informal proof
- Note that

$$
\begin{aligned}
\frac{d}{d x}(F(x)+G(x)+C) & =\frac{d}{d x} F(x)+\frac{d}{d x} G(x)+\frac{d}{d x} C \\
& =F^{\prime}(x)+G^{\prime}(x)+0 \\
& =f(x)+g(x) 
\end{aligned}
$$

- Note also that $\int f(x) d x=F(x)+C_{f}$ and $\int g(x) d x=G(x)+C_{g}$, so that

$$
\int f(x) d x+\int g(x) d x=F(x)+C_{f}+G(x)+C_{g}=F(x)+G(x)+C
$$

where $C_{f}, C_{g}$, and $C=C_{f}+C_{g}$ are arbitrary constants



Claim: $\int k f(x) d x=k \int f(x) d x=k F(x)+C$
- Informal proof
- Note that

$$
\begin{aligned}
 \frac{d}{d x}(k F(x)+C)&=\frac{d}{d x} k F(x)+\frac{d}{d x} C \\
& =k \frac{d}{d x} F(x)+0 \\
& =\quad k F^{\prime}(x) \\
& =\quad k f(x) 
\end{aligned}
$$

- Note also that

$$
k \int f(x) d x=k\left(F(x)+C_{f}\right)=k F(x)+k C_{f}=k F(x)+C
$$

where $C_{f}$ and $C=k C_{f}$ are arbitrary constants


## Integration techniques

There are a number of techniques that can be used to find the indefinite integral of a function. These include the following:

1. Direct integration. (This involves recognising that the integrand is the derivative of a particular function, or, rather, class of functions. It is most useful when the integrand is an elementary function.)

2. Integration by substitution. (This is the integration counterpart to the chain rule of differentiation.)

3. Integration by parts. (This is the integration counterpart to the product rule of differentiation.)

4. Integration by partial fractions. (This technique is sometimes useful when the integrand is the ratio of two polynomial functions.)


### Direct integration

**Direct integration** makes use of the fact that if $F^{\prime}(x)=f(x)$, then the indefinite integral of $f(x)$ is given by $\int f(x) d x=F(x)+C$

If we reconise the integrand $f(x)$ as being the derivative of some function $F(x)$ with respect to the variable $x$, then we automatically know that the indefinite integral of $f(x)$ is equal to $F(x)+C$

Some examples:
- Since $\frac{d}{d x} x^{\alpha}=\alpha x^{\alpha-1}$, we have $\int \alpha x^{\alpha-1} d x=x^{\alpha}+C$
- Since $\frac{d}{d x} e^{a x}=a e^{a x}$, we have $\int a e^{a x} d x=e^{a x}+C$
- Let $x \in(0, \infty)$. Since $\frac{d}{d x} \ln (x)=\frac{1}{x}$, we have $\int \frac{1}{x} d x=\ln (x)+C$


### Integration by substitution

Suppose that $G:(a, b) \longrightarrow \mathbb{R}$ be a function that is differentiable on the interval $(a, b) \subseteq \mathbb{R}$ and let $g(t)=G^{\prime}(t)=\frac{d G(t)}{d t}$ be its derivative when $t \in(a, b)$

Suppose that $t:(c, d) \longrightarrow(a, b)$ be a function that is differentiable on the interval $(c, d) \subseteq \mathbb{R}$ and let $t^{\prime}(x)=\frac{d t(x)}{d x}$ be its derivative when $x \in(c, d)$

Consider the composite function $F:(c, d) \longrightarrow \mathbb{R}$ defined by $F(x)=G(t(x))$

Since $G(t)$ is differentiable on $(a, b), t:(c, d) \longrightarrow(a, b)$, and $t(x)$ is differentiable on $(c, d)$, we know that $F(x)$ is differentiable on $(c, d)$. Denote its derivative by $f(x)=F^{\prime}(x)=\frac{d F(x)}{d t}$ when $x \in(c, d)$

We know from the chain rule of differentiation that $f(x)=F^{\prime}(x)=G^{\prime}(t(x)) t^{\prime}(x)=g(x) t^{\prime}(x)$

Recall that we have $F(x)=G(t(x))$ and $f(x)=F^{\prime}(x)=g(t(x)) t^{\prime}(x)$, where $g(t)=G^{\prime}(t)$
Thus we know that $F(x)+C=\int F(x) d x=\int g(t(x)) t^{\prime}(x) d x$, where $C \in \mathbb{R}$ is an arbitrary constant

Recall that $d t=\left(\frac{d t(x)}{d x}\right) d x=t^{\prime}(x) d x$. Thus we have

$$
\begin{gathered}
F(x)+C=\int F(x) d x=\int g(t(x)) t^{\prime}(x) d x \\
=\int g(t) d t=G(t)+C=G(t(x))+C
\end{gathered}
$$

when $G(t)$ is evaluated at the parameterised point $t=t(x)$

Note that we need to remember to substitute $t=t(x)$ into $G(t)$ to obtain the correct result here


We now have a framework for discussing the technique of **integration by substitution**
Clearly, this is the integral counterpart of the chain rule of differentiation
This techniques is useful in circumstances where each of the following properties is true

1. You do not know how to calculate the indefinite integral of $f(x)$ with respect to $x$

2. You can see a way to express $f(x)$ as $f(x)=g(t(x)) t^{\prime}(x)$ for which you know the functions $g(t)$ and $t(x)$

3. You do know how to calculate the indefinite integral of $g(t)$ with respect to $t$



```{dropdown} Example

Suppose that we want to find $\int f(x) d x=\int \frac{\ln (x)}{x} d x$
Let $g(t)=t$ and $t(x)=\ln (x)$
This means that $g(t(x))=t(x)=\ln (x)$ and $t^{\prime}(x)=\frac{1}{x}$
Note that $f(x)=\frac{\ln (x)}{x}=g(t(x)) t^{\prime}(x)$ and
$\int g(t) d t=\int t d t=\frac{t^{2}}{2}+C$

Thus we have

$$
F(x)+C=\frac{(t(x))^{2}}{2}+C=\frac{(\ln (x))^{2}}{2}+C=\frac{\ln ^{2}(x)}{2}+C 
$$

As a check on the accuracy of our proposed solution, note that

$$
\begin{gathered}
\frac{d}{d x}\left(\frac{\ln ^{2}(x)}{2}\right)=\left(\frac{1}{2}\right)(2) \ln (x)\left(\frac{d \ln (x)}{d x}\right) \\
\quad=(1) \ln (x)\left(\frac{1}{x}\right)=\frac{\ln (x)}{x}=f(x)
\end{gathered}
$$
```

```{dropdown} Example

Suppose that we want to find $\int f(x) d x=\int e^{x^{2}} x d x$
Let $g(t)=\left(\frac{1}{2}\right) e^{t}$ and $t(x)=x^{2}$
This means that $g(t(x))=\left(\frac{1}{2}\right) e^{t(x)}=e^{x^{2}}$ and $t^{\prime}(x)=2 x$
Note that $f(x)=e^{x^{2}} x=g(t(x)) t^{\prime}(x)$ and

$$
\int g(t) d t=\int\left(\frac{1}{2}\right) e^{t} d t=\left(\frac{1}{2}\right) \int e^{t} d t=\left(\frac{1}{2}\right) e^{t}+C
$$

Thus we have

$$
F(x)+C=\left(\frac{1}{2}\right) e^{t(x)}+C=\left(\frac{1}{2}\right) e^{x^{2}}+C 
$$

As a check on the accuracy of our proposed solution, note that

$$
\frac{d}{d x}\left(\left(\frac{1}{2}\right) e^{x^{2}}\right)=\left(\frac{1}{2}\right)(2 x) e^{x^{2}}=x e^{x^{2}}=e^{x^{2}} x
$$
```



### Integration by parts

Suppose that $u:(a, b) \longrightarrow \mathbb{R}$ and $v:(a, b) \longrightarrow \mathbb{R}$ are both functions that are differentiable on the interval $(a, b) \subseteq \mathbb{R}$
Suppose also that there exist two other functions that are both differentiable on the interval $(a, b) \subseteq \mathbb{R}, G:(a, b) \longrightarrow \mathbb{R}$ and $G:(a, b) \longrightarrow \mathbb{R}$, such that $G^{\prime}(x)=u^{\prime}(x) v(x)$ and $H^{\prime}(x)=v^{\prime}(x) u(x)$

Consider the function $J:(a, b) \longrightarrow \mathbb{R}$ defined by $J(x)=u(x) v(x)$
We know from the product rule of differentiation that

$$
\frac{d}{d x}(u(x) v(x))=\left(\frac{d u(x)}{d x}\right) v(x)+\left(\frac{d v(x)}{d x}\right) u(x)
$$

which can be rewritten as

$$
\frac{d}{d x}(u(x) v(x))=u^{\prime}(x) v(x)+v^{\prime}(x) u(x)
$$


We have obtained the expression

$$
\frac{d}{d x}(u(x) v(x))=u^{\prime}(x) v(x)+v^{\prime}(x) u(x)
$$

This expression can be rearranged to obtain

$$
u^{\prime}(x) v(x)=\frac{d}{d x}(u(x) v(x))-v^{\prime}(x) u(x)
$$

Thus we know that

$$
\begin{gathered}
\int u^{\prime}(x) v(x) d x=\int\left(\frac{d}{d x}(u(x) v(x))-v^{\prime}(x) u(x)\right) d x \\
=\int \frac{d}{d x}(u(x) v(x)) d x-\int v^{\prime}(x) u(x) d x
\end{gathered}
$$


Note that

$$
\int \frac{d}{d x}(u(x) v(x)) d x=u(x) v(x)+C
$$

where $C \in \mathbb{R}$ is an arbitrary constant

This gives us

$$
\int u^{\prime}(x) v(x) d x=u(x) v(x)-\int v^{\prime}(x) u(x) d x+C 
$$

Note also that $\int u^{\prime} v d x$ and $\int v^{\prime} u d x$ both implicitly incorporate arbitrary constants
If we absorb the explicit arbitrary constant $(C)$ in the above expression into the implicity arbitrary constants in the $\int u^{\prime} v d x$ and $\int v^{\prime} u d x$ terms in some appropriate fashion, then we can rewrite that expression as

$$
\int u^{\prime}(x) v(x) d x=u(x) v(x)-\int v^{\prime}(x) u(x) d x
$$


We have obtained the expression

$$
\int u^{\prime}(x) v(x) d x=u(x) v(x)-\int v^{\prime}(x) u(x) d x
$$

This expression forms the foundation for the integration technique known as **integration by parts**. Clearly, integration by parts is the integral counterpart to the product rule of differentiation

Integration by parts is particularly useful when you want to find $\int f(x) d x=\int u^{\prime} v d x$ and either of the following two situations occur

1. The indefinite integral $\int v^{\prime} u d x$ is easier to obtain than the indefinite integral $\int u^{\prime} v d x$

2. It turns out that $\int v^{\prime} u d x=\mathrm{k} \int u^{\prime} v d x$ for some constant $k \in \mathbb{R}$. (In this case, you get a functional equation in which the "variable" is the integrand $\int u^{\prime} v d x$. This equation can then be solved to obtain integrand $\int u^{\prime} v d x$

Sometimes, you might need to undertake multiple iterations of the technique of integration by parts


```{dropdown} Example
We want to find $\int \ln (x) d x$
Let $u(x)=x$ and $v(x)=\ln (x)$. This means that $u^{\prime}(x)=1$ and $v^{\prime}(x)=\frac{1}{x}$
This allows us to express the required integral as

$\int \ln (x) d x=\int(1) \ln (x) d x=\int u^{\prime}(x) v(x) d x$

Integrating by parts, and ignoring any arbitrary constants, we obtain

$$
\int \ln (x) d x=x \ln (x)-\int\left(\frac{1}{x}\right) x d x=x \ln (x)-\int d x=x \ln (x)-x 
$$

Thus we can conclude that

$$
\int \ln (x) d x=x \ln (x)-x+C=x(\ln (x)-1)+C
$$

where $C \in \mathbb{R}$ is an arbitrary constant
```

```{dropdown} Example
We want to find $\int \frac{\ln (x)}{x} d x$
Let $u(x)=\ln (x)$ and $v(x)=\ln (x)$. This means that $u^{\prime}(x)=\frac{1}{x}$ and $v^{\prime}(x)=\frac{1}{x}$
This allows us to express the required integral as $\int \frac{\ln (x)}{x} d x=\int u^{\prime}(x) v(x) d x$

Integrating by parts, and ignoring any arbitrary constants, we obtain

$$
\begin{gathered}
\int \frac{\ln (x)}{x} d x=\int u^{\prime}(x) v(x) d x=u(x) v(x)-\int v^{\prime}(x) u(x) d x \\
=(\ln (x))(\ln (x))-\int \frac{\ln (x)}{x} d x=(\ln (x))^{2}-\int \frac{\ln (x)}{x} d x \\
=\ln ^{2}(x)-\int \frac{\ln (x)}{x} d x
\end{gathered}
$$

Ignoring any arbitrary constants, we have shown that

$$
\int \frac{\ln (x)}{x} d x=\ln ^{2}(x)-\int \frac{\ln (x)}{x} d x
$$

This equation can be rearranged to obtain

$$
2 \int \frac{\ln (x)}{x} d x=\ln ^{2}(x)
$$

so that, ignoring any arbitrary constants, we have

$$
\int \frac{\ln (x)}{x} d x=\left(\frac{1}{2}\right) \ln ^{2}(x)
$$

Thus we know that

$$
\int \frac{\ln (x)}{x} d x=\left(\frac{1}{2}\right) \ln ^{2}(x)+C
$$

where $C \in \mathbb{R}$ is an arbitrary constant
```


% ### Integration of rational functions
% 
% If the the integrand $f(x)$ is a rational function, then decomposing that rational function into the sum of a number of more simple rational functions can sometimes help with finding the indefinite integral $\int f(x) d x$. This decomposition technique is known as the method of "partial fractions"
% 
% A rational function $R(x)$ is simply the ratio of two polynomial functions, $P(x)$ and $Q(x)$. It takes the form
% 
% $$
% R(x)=\frac{P(x)}{Q(x)}=\frac{a_{m} x^{m}+a_{m-1} x^{m-1}+\cdots+a_{1} x+a_{0}}{b_{n} x^{n}+b_{n-1} x^{n-1}+\cdots+b_{1} x+b_{0}}
% $$
% 
% where
% 
% $$
% P(x)=a_{m} x^{m}+a_{m-1} x^{m-1}+\cdots+a_{1} x+a_{0}
% $$
% 
% is an $m$ th order polynomial (so that $a_{m} \neq 0$ ), and
% 
% $$
% Q(x)=b_{m} x^{m}+b_{m-1} x^{m-1}+\cdots+b_{1} x+b_{0}
% $$
% 
% is an $n$th order polynomial (so that $b_{n} \neq 0$ )
% 
% 
% Note that there is no requirement that the polynomial functions $P(x)$ and $Q(x)$ be of the same order. (In other words, we do not require that $m=n$.)
% 
% The most interesting case is when $m<n$. In such cases, the rational function $R(x)$ is called a "proper" rational function
% 
% When $m \geqslant n$, then we can always use the process of long division to write the original rational function $R(x)$ as the sum of a polynomial function $Y(x)$ and another proper rational function $R^{*}(x)$
% 
% This is nicely illustrated by the following example from Chapter 14 of {cite:ps}`silverman1969`. Consider the rational function $R(x)=\frac{x^{2}+x-1}{x-1}$. Note the following
% 
% ```{image} _static/img/lecture_10/longdiv.png
% :align: center
% ```
% 
% Thus we have
% 
% $$
% R(x)=\frac{x^{2}+x-1}{x-1}=x+2+\left(\frac{1}{x-1}\right) 
% $$
% 
% 
% Since any non-proper rational function $R(x)$ can be written as the sum of a polynomial function $Y(x)$ and a proper rational function $R^{*}(x)$, we know that
% 
% $$
% \int R(x) d x=\int Y(x) d x+\int R^{*}(x) d x
% $$
% 
% where
% 
% $$
% \begin{aligned}
% \int Y(x) d x &= \int\left(c_{y} x^{y}+c_{y-1} x^{y-1}+\cdots+c_{1} x+c_{0}\right) d x \\
% &=\int\left(\sum_{i=0}^{y} c_{y-i} x^{y-i}\right) d x=\sum_{i=0}^{y}\left(\int c_{y-i} x^{y-i} d x\right) \\
% &=\sum_{i=0}^{y}\left(c_{y-i} \int x^{y-i} d x\right)=\sum_{i=0}^{y}\left(\frac{c_{y-i}}{(y-i+1)} \int(y-i+1) x^{y-i} d x\right)\\
% &=\int\left(c_{y} x^{y}+c_{y-1} x^{y-1}+\cdots+c_{1} x+c_{0}\right) d x \\
% &=\int\left(\sum_{i=0}^{y} c_{y-i} x^{y-i}\right) d x=\sum_{i=0}^{y}\left(\int c_{y-i} x^{y-i} d x\right) \\
% &=\sum_{i=0}^{y}\left(c_{y-i} \int x^{y-i} d x\right)=\sum_{i=0}^{y}\left(\frac{c_{y-i}}{(y-i+1)} \int(y-i+1) x^{y-i} d x\right) \\
% &=\sum_{i=0}^{y}\left(\frac{c_{y-i}}{y-i+1}\right) x^{y-i+1} \\
% &=\left(\frac{c_{y}}{y+1}\right) x^{y+1}+\left(\frac{c_{y-1}}{y}\right) x^{y}+\cdots+\left(\frac{c_{1}}{2}\right) x^{2}+c_{0} x 
% \end{aligned}
% $$
% 
% 
% Thus when $R(x)$ is a non-proper rational function, we can easily calculate the integral of the polynomial component of that function
% Doing so yields:
% 
% $$
% \begin{gathered}
% \int R(x) d x=\int Y(x) d x+\int R^{*}(x) d x \\
% =\left(\sum_{i=0}^{y}\left(\frac{c_{y-i}}{y-i+1}\right) x^{y-i+1}\right)+\int R^{*}(x) d x 
% \end{gathered}
% $$
% 
% This leaves us with the task of finding the integral of the proper rational function that constitutes the remainder term (in other words, the task of finding $\left.\int R^{*}(x) d x\right)$
% In cases where $R(x)$ is a proper rational function to begin with, then this last step is the only task that we face
% 
% 
% Sometimes you will be able to find $\int R^{*}(x) d x$ through direct integration, or integration by substitution, or integration by parts
% In other cases, the technique of partial fractions might help you to find $\int R^{*}(x) d x$
% You might like to review the material on partial fractions that we covered earlier in the semester at this point in time
% 

## Definite integral

Informally, a definite integral of a function tells us the area under the curve that represents the graph of that function between two points
- *Illustrate this on the white-board.*

Slightly more precisely, it tells us the aggregate signed area between the curve that represents the graph of that function and the axis for the independent variable between two points
- Some care is needed here. When the curve is above the axis, the area enters the aggregate sum positively. When the curve is below the axis, the area enters the aggregate sum negatively
- *Illustrate this on the white-board.*

This "aggregate signed area" is related to the indefinite integral of the function. This relationship is captured through the "Fundamental Theorem of Calculus". More on this later


### Area approximation by the sum of box areas

How might we try and measure the area under a curve?
One way might be to try and approximate it by adding up the area of boxes whose sum seems like it should be close to the area under the curve
The advantage of this approach is that calculating the area of boxes (or, rather rectangles) is easy. We know from high school (and perhaps even primary school) that it is just length times breadth (or height times width)

But how do we form these boxes?
- *Illustrate on the white-board.*
- Suppose that we want to calculate the area under the graph of the function $f(x)$ between the points $a$ and $b$, where $a<b$. To keep life simple, suppose also that $f(x)>0$ for all $x \in[a, b]$
- Choose a finite partition of the interval $[a, b]$. This will take the form $\left\{a, t_{1}, t_{2}, t_{3}, \cdots, t_{n-1}, t_{n}, b\right\}$
- Note that $\left[a, t_{1}\right] \cup\left(t_{1}, t_{2}\right] \cup\left(t_{2}, t_{3}\right] \cup \cdots \cup\left(t_{n-1}, t_{n}\right] \cup\left(t_{n}, b\right]=[a, b]$ and $\left[a, t_{1}\right] \cap\left(t_{1}, t_{2}\right] \cap\left(t_{2}, t_{3}\right] \cap \cdots \cap\left(t_{n-1}, t_{n}\right] \cap\left(t_{n}, b\right]=\varnothing$
- Let $B_{1}=\left[a, t_{1}\right], B_{n+1}=\left(t_{n}, b\right]$, and $B_{k}=\left(t_{k-1}, t_{k}\right]$ for $k \in\{2,3, \cdots, n\}$
- This allows us to express our partition as $\left\{B_{1}, B_{2}, \cdots, B_{n+1}\right\}$
- We can use this partition to form the bases of $(n+1)$ boxes
- The distances for each of these bases, moving from left to right along the $x$-axis between the points $x=a$ and $x=b$, are $\left(t_{1}-a\right)$, $\left(t_{2}-t_{1}\right),\left(t_{3}-t_{2}\right), \cdots,\left(t_{n}-t_{n-1}\right)$, and $\left(b-t_{n}\right)$
- Note that $B_{1}$ has a base distance of $\left(t_{1}-a\right)=w_{1}, B_{n+1}$ has a base distance of $\left(b-t_{n}\right)=w_{n+1}$, and $B_{k}$ has a base distance of $\left(t_{k}-t_{k-1}\right)=w_{k}$ for $k \in\{2,3, \cdots, n\}$
- But what about the height of these boxes?
- There are many possibilities. We will focus on two bounding possibilities. One of these will provide a lower bound for the area of each box. The other will provide an upper bound for the area of each box
- Let $h_{k}=\min \left\{f(x): x \in B_{k}\right\}$ and $H_{k}=\max \left\{f(x): x \in B_{k}\right\}$
- A lower bound for the area underneath the graph of the function on interval $B_{k}$ is given by $L_{k}=h_{k} w_{k}$
- An upper bound for the area underneath the graph of the function on interval $B_{k}$ is given by $U_{k}=H_{k} w_{k}$
- We can obtain a lower bound for the area underneath the graph of the function between the points $x=a$ and $x=b$ by summing all of the $L_{k}$ terms for our partition. This lower bound will be given by $L(a, b)=\sum_{k=1}^{n+1} L_{k}$
- We can obtain an upper bound for the area underneath the graph of the function between the points $x=a$ and $x=b$ by summing all of the $U_{k}$ terms for our partition. This upper bound will be given by $U(a, b)=\sum_{k=1}^{n+1} U_{k}$
- These types of upper bounds and lower bounds for the area underneath the graph of the function between the points $x=a$ and $x=b$ are known as upper Riemann sums and lower Riemann sums respectively


### The definite integral as a limit of Riemann sums

Let $\hat{w}=\max \left\{w_{k}: k \in\{1,2, \cdots, n+1\}\right\}$
If 
1. $\lim _{\hat{w} \rightarrow 0} L(a, b)$ exists, 
2. $\lim _{\hat{w} \rightarrow 0} U(a, b)$ exists, and 
3. $\lim _{\hat{w} \rightarrow 0} L(a, b)=\lim _{\hat{w} \rightarrow 0} U(a, b)$, 

then the **definite integral** exists and is defined to be

$$
\int_{a}^{b} f(x) d x=I(a, b)=\lim _{\hat{w} \rightarrow 0} L(a, b)=\lim _{\hat{w} \rightarrow 0} U(a, b) 
$$

This type of definite integral is sometimes known as a **Riemann integral**
When this definite integral exists, it is equal to the aggregate signed area "underneath" the graph of a function between two points


## The fundamental theorem of calculus

The fundamental theorem of calculus says that, if $F^{\prime}(x)=f(x)$ for all $x \in[a, b]$, then

$$
\int_{a}^{b} f(x) d x=F(b)-F(a)
$$


## Differentiating definite integrals

### Introduction

Let

$$
I(a, b)=\int_{a}^{b} f(x) d x
$$

Suppose that it is possible that $a, b$, and $f(x)$ all depend on some parameter $s$

We might be interested in calculating the impact of $s$ on $I(a, b)$

This is actually a topic from multivariate calculus. However, we will present it here because it is an important result that gets used in economics. The result is known as "Leibniz' rule"


### Leibniz' Rule

Let

$$
I(a, b)=\int_{a}^{b} f(x) d x
$$

Suppose that it is possible that $a, b$, and $f(x)$ all depend on some parameter $s$. The impact of a small change in $s$ on $I(a, b)$ is given by Leibniz' rule. Leibniz' rule says that

$$
\frac{d I(a, b, s)}{d s}=f(b, s) b^{\prime}(s)-f(a, s) a^{\prime}(s)+\int_{a}^{b} \frac{\partial f(x, s)}{\partial s} d x
$$


Here we will briefly consider four special sub-cases of Leibniz' rule
Note that these four sub-cases are not the only possible sub-cases

- Case 1: $a$ and $b$ are functions of $s$, but $f(x)$ is not a function of $s$. Here we have:

$$
\frac{d I(a, b ; s)}{d s}=f(b ; s) b^{\prime}(s)-f(a ; s) a^{\prime}(s)
$$

- Case 2: $a$ is a function of $s$, but $b$ and $f(x)$ are not functions of $s$. Here we have:

$$
\frac{d I(a, b ; s)}{d s}=-f(a ; s) a^{\prime}(s)
$$

- Case 3: $b$ is a function of $s$, but $a$ and $f(x)$ are not functions of $s$. Here we have:

$$
\frac{d I(a, b ; s)}{d s}=f(b ; s) b^{\prime}(s) 
$$

- Case 4: $f(x)$ is a function of $s$, but $a$ and $b$ are not functions of $s$. Here we have:

$$
\frac{d I(a, b ; s)}{d s}=\int_{a}^{b} \frac{\partial f(x, s)}{\partial s} d x
$$


## Improper integrals

The definite integral $\int_{a}^{b} f(x) d x$ is said to be **improper** if either the distance between the bounds of integration is infinite (that is, if $d(a, b)=|b-a|=\infty)$, or if the integrand $f(x)$ is discontinuous on the interval of integration $[a, b]$, or both of these possibilities occur
A definite integral that is improper because the distance between the bounds of integration is infinite will take one of the following three forms:

1. $\int_{a}^{\infty} f(x) d x$,

2. $\int_{-\infty}^{b} f(x) d x$, or

3. $\int_{-\infty}^{\infty} f(x) d x$


A discontinuity of the integrand can take place at one of three location categories. These are:

1. The lower bound of integration (that is, $f(x)$ is discontinuous at the point $x=a$ );

2. The upper bound of integration (that is, $f(x)$ is discontinuous at the point $x=b$ );

3. An interior point of the interval of integration (that is, $f(x)$ is discontinuous at the point $x=c \in(a, b))$

Of course, it is possible for the integrand to have muliple points of discontinuity on the interval of integration. Sometimes, improper integrals exist and sometimes they do not. Whether or not an improper integral exists will depend on whether or not a particular limit (or multiple particular limits) exist


- The improper integral $\int_{a}^{\infty} f(x) d x$ exists if the limit $\lim_ {b \uparrow \infty} \int_{a}^{b} f(x) d x$ exists, in which case we have

$$
\int_{a}^{\infty} f(x) d x=\lim _{b \uparrow \infty} \int_{a}^{b} f(x) d x
$$

- The improper integral $\int_{-\infty}^{b} f(x) d x$ exists if the limit $\lim _{a \downarrow-\infty} \int_{a}^{b} f(x) d x$ exists, in which case we have

$$
\int_{-\infty}^{b} f(x) d x=\lim _{a \downarrow-\infty} \int_{a}^{b} f(x) d x
$$

- The improper integral $\int_{\infty}^{\infty} f(x) d x$ exists if the limit $\lim _{a \downarrow-\infty, b \uparrow \infty} \int_{a}^{b} f(x) d x$ exists, in which case we have

$$
\int_{-\infty}^{\infty} f(x) d x=\lim _{a \downarrow-\infty, b \uparrow \infty} \int_{a}^{b} f(x) d x
$$


- If the integrand $f(x)$ is discontinuous at the point $x=a$, the improper integral $\int_{a}^{b} f(x) d x$ exists if the limit $\lim_{\theta \downarrow a} \int_{\theta}^{b} f(x) d x$ exists, in which case we have

$$
\int_{a}^{b} f(x) d x=\lim _{\theta \downarrow a} \int_{\theta}^{b} f(x) d x
$$

- If the integrand $f(x)$ is discontinuous at the point $x=b$, the improper integral $\int_{a}^{b} f(x) d x$ exists if the limit $\lim _{\psi \uparrow b} \int_{a}^{\psi} f(x) d x$ exists, in which case we have

$$
\int_{a}^{b} f(x) d x=\lim _{\psi \uparrow b} \int_{a}^{\psi} f(x) d x 
$$

- If the integrand $f(x)$ is discontinuous at the point $x=c \in(a, b)$, the improper integral $\int_{a}^{b} f(x) d x$ exists if both the limit from below $\lim _{\lambda \uparrow c} \int_{a}^{\lambda} f(x) d x$ exists and the limit from above $\lim _{\delta \downarrow c} \int_{\delta}^{b} f(x) d x$ exists, in which case we have

$$
\begin{aligned}
& \int_{a}^{b} f(x) d x=\int_{a}^{c} f(x) d x+\int_{c}^{b} f(x) d x \\
= & \lim _{\lambda \uparrow c} \int_{a}^{\lambda} f(x) d x+\lim _{\delta \downarrow c} \int_{\delta}^{b} f(x) d x 
\end{aligned}
$$


## Some economic and econometric applications

- Consumer Welfare: Total Consumer Benefit, Consumer Surplus and Change in Consumer Surplus. (See separate section below.)
- Producer Welfare: Total Operating Costs, Producers Surplus, and Change in Producers Surplus. (See separate section below.)
- Choice over Time: Lifetime Utility
- Choice under Uncertainty: Expected Utility
- The Relationship between Probability Density Functions and Cumulative Distribution Functions
- The Expected Value and Other Moments of a Probability Distribution
- The Moment Generating Function and the Characteristic Function


### Preferences over time contingent consumption

Consider a consumer that must choose how to allocate their lifetime wealth over consumption at various points in time

If time is continuous over some interval $[0, T]$ and the consumer can potentially consume at every point in time $t \in[0, T]$, then a time-stream of consumption is a function of the form $c:[0, T] \longrightarrow[0, \infty)$. This function specifies, for each point in time $t \in[0, T]$, the amount of consumption $c(t) \in[0, \infty)$ that is chosen by the consumer (at time zero) for the point in time $t \in[0, T]$

In such cases, we sometimes assume (at least partly for tractability reasons) that such a consumer's preferences over alternative consumption streams can be represented by a stationary "lifetime utility function" of the form

$$
U\left(\{c(t)\}_{t \in[0, T]}\right)=\int_{0}^{T} u(c(t)) e^{-\rho t} d t
$$

where $\rho \in(0,1)$ is a fixed rate of time preference and $u(c)$ is a stationary per-period (or point-in-time) utility function

### Preferences over state contingent consumption

Suppose that there are an uncountably infinite number of potential states of the world, with each point in the interval non-empty closed interval $(a, b)$ corresponding to a particular state. Denote the state variable by $\omega \in[a, b]$

Nature chooses which state of nature will actually prevail by drawing one state from $(a, b)$ according to a commonly known probability distribution that has a probability density function of the form $f:(a, b) \longrightarrow[0,1]$

Suppose that a consumer's consumption level varies with the random state of Nature, so that it is given by a function of the form $c:(a, b) \longrightarrow[0, \infty)$

If the consumer is a von Neumann-Morgenstern (vNM) expected utility maximiser with a Bernoulli utility function $u:[0, \infty] \longrightarrow \mathbb{R}$ of the form $u(c)$, then the "vNM expected utility function" for this consumer is

$$
U\left(\{c(\omega)\}_{\omega \in[a, b]}\right)=\int_{a}^{b} u(c(\omega)) f(\omega) d \omega 
$$










```{dropdown} Further reading and self-learning
- Gaussian integral [YouTube 3Blue1Brown](https://youtu.be/cy8r7WSuT1I?si=corMbP8Bnd3mnyqt)
```