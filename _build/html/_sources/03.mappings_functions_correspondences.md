
# Mappings: functions and correspondences

## Reading guide

Introductory mathematical economics references:
- Haeussler, EF Jr, and RS Paul (1987), *Introductory mathematical analysis for business, economics, and the life and social sciences (fifth edition)*, Prentice-Hall, USA:Chapters 0, 3, 4, 5, and 17.1.
- Sydsaeter, K, P Hammond, A Strom, and A Carvajal (2016), *Essential mathematics for economic analysis (fifth edition)*, Pearson Education, Italy: Chapters 2, 4, 5, 9.6 (pp. 350-351 only), 11.1, and 11.5.
- Shannon, J (1995), *Mathematics for business, economics and finance*, John Wiley and Sons, Brisbane: Chapters 1, 2, and 6.

Advanced high school references:
- Coroneos, J. (Undated a), *A Higher School Certificate Course in Mathematics: Year Eleven, Three Unit Course*, Coroneos Publications, Australia: Chapters 1, 2, 4, and 7.
- Coroneos, J. (Undated b), *A Higher School Certificate Course in Mathematics: Years Eleven and Twelve, Revised Four Unit Course (for Mathematics Extension Two)*, Coroneos Publications, Australia: Chapters 1 and 2.

Introductory mathematics references:
- Adams, RA, and C Essex (2018), *Calculus: A complete course (ninth edition)* Pearson, Canada: Chapters P, 3, and 11.
- Kline, M (1967), *Calculus: An intuitive and physical approach (second edition)*, The 1998 Dover republication of the original John Wiley and Sons second edition, Dover Publications, USA: pp. 419–432.
- Silverman, RA (1969), *Modern calculus and analytic geometry*, The 2002 Dover corrected republication of the original 1969 Macmillan Company edition, Dover Publications, USA: Chapters 7 and 14.
- Spivak, M (2006), *Calculus (third edition)*, Cambridge University Press, The United Kingdom: Chapters 1, 2, 3, 4, 16, 18, and 19.
- Thomas, GB Jr, and RL Finney (1996), *Calculus and analytic geometry (ninth edition)*, The 1998 corrected reprint version, Addison-Wesley Publishing Company, USA: Chapters P, 6, and 12.

More advanced references:
- Banks, J, G Elton and J Strantzen (2009), *Topology and analysis: Unit text for MAT3TA (2009 and 2010 edition)*, Department of Mathematics and Statistics, La Trobe University, Bundoora, February.
- Corbae, D, MB Stinchcombe and J Zeman (2009), *An introduction to mathematical analysis for economic theory and econometrics*, Princeton University Press, USA: Chapter 2 (pp. 15-71).
- Kolmogorov, AN and SV Fomin (1970), *Introductory real analysis*, Translated and Edited by RA Silverman, The 1975 Dover Edition (an unabridged, slightly corrected republication of the original 1970 Prentice-Hall edition), Dover Publications, USA: Chapter 1 (pp. 1-36).
- Simon, C, and L Blume (1994), *Mathematics for economists*, WW Norton and Co, USA: Chapters 2 and 13 (pp. 10-38 and 273-299).

Websites:

The following websites contain discussions of the concept of relatively prime, or co-prime, numbers and polynomials. This is relevant to the topic of rational functions and partial fractions.
- https://www.mathsisfun.com/definitions/relatively-prime.html
- http://mathworld.wolfram.com/RelativelyPrime.html
- https://www.varsitytutors.com/hotmath/hotmath_help/topics/relatively-prime


## Mappings
Let $X$ and $Y$ be two sets. A rule $f$ that assigns one or more elements of $Y$ to each element of $X$ is called a **mapping** from $X$ into $Y$. It is denoted by $f: X \rightarrow Y$.

The set $X$ is known as the **domain** of the mapping $f$. The mapping must be defined for every element of $X$. This means that $x \in X \implies f(x) \in Y$.

The set $Y$ is known as the **co-domain** of the mapping $f$. Mappings are not required to generate $Y$ from $X$. This means that there might exist one or more elements $y \in Y$ such that $y \ne f(x)$ for any $x \in X$.

The set of values $y \in Y$ that can be generated from $X$ by the function $f$ is known as the **image** of $X$ under $f$. Sometimes the image of $X$ under $f$ is referred to as the **range** of $f$. We will denote the range of $f$ by $f(X)$.

```{figure} _static/img/lecture_03/mapping_diagram.png
:width: 80%
:align: center

Diagrammatic representation of a mapping
```

### Images
Consider a mapping $f: X \rightarrow Y$.
The *image of the point* $x \in X$ under the mapping $f$ is the point, or collection of points, given by $f(x) \in Y$.

The *image of the set* $A \subseteq X$ under the mapping $f$ is the set $f(A) = \{f(x) \in Y : x \in A\}$. 
- Clearly $f(A) \subseteq Y$.

The *image of the domain* ($X$) under $f$ is the set $f(X) = \{f(x) \in Y : x \in X \}$.
- Clearly $f(X) \subseteq Y$.

Note that if $f: X \rightarrow Y$ and $A \subseteq X$, then $f(A) \subseteq f(X) \subseteq Y$.


### Pre-images
Consider a mapping $f: X \rightarrow Y$.

The **pre-image** *of the point* $y \in Y$ under the mapping $f$ is the point, or collection of points, in $X$ for which $y = f(x)$.

It is possible for a point $y \in Y$ to have either 
- no pre-image 
- a unique pre-image, or 
- multiple pre-images. 
If a point $y \in Y$ has a unique pre-image under the mapping $f$, then it is denoted by $f^{−1}(y)$.

The *pre-image of the set* $B \subseteq Y$ under $f$ is the set $f^{−1}(B) = \{x \in X : f(x) \in B\}$.

Recall that it is possible for there to exist $y \in Y$ such that $y \ne f(x)$ for any $x \in X$. If the set B consists entirely of such points, then $f^{−1}(B) = \varnothing$.

Since $f(x) \in Y$ for all $x \in X$, it must be the case that $f^{-1}(Y) = X$.

### Types of mappings

There are four basic types of mappings. These are as follows.
- A one-to-one mapping:
    - Each point in $X$ has a unique image in $Y$; and
    - Each point in $Y$ has either a unique pre-image in $X$ or no pre-image in $X$.
- A many-to-one mapping:
    - Each point in $X$ has a unique image in $Y$; but
    - At least one point in $Y$ has multiple pre-images in $X$.
- A one-to-many mapping:
    - At least one point in $X$ has multiple images in $Y$; but
    - Each point in $Y$ has either a unique pre-image in $X$ or no pre-image in $X$.
- A many-to-many mapping:
    - At least one point in $X$ has multiple images in $Y$; and
    - At least one point in $Y$ has multiple pre-images in $X$.
    
Mappings whose domain points all have unique images are known as
**functions**. In other words, one-to-one mappings and many-to-one mappings are
known as functions.

A one-to-one function $f: X \rightarrow Y$ is called an **injection**. The pre-image of a one-to-one function is known as its **inverse**.  

Mappings that have at least one domain point with multiple images are known as **correspondences**. In other words, one-to-many mappings and many-to-many mappings are known as correspondences.

Note that we could express a correspondence of the form $f : X \rightarrow Y$ as a function of the form $g: X \rightarrow 2^Y$.

### Into and onto
Consider a mapping $f : X \rightarrow Y$. Clearly we must have $f(X) \subseteq Y$.
- If $f(X ) \subset Y$, so that $f(X) \ne Y$, we say that $f$ maps $X$ “into” $Y$.
- If $f(X) = Y$, we say that $f$ maps $X$ “onto” $Y$.
    - If $f(X) = Y$ and $f$ is a function, then we call $f$ a **surjection**.

A mapping that is both an injection and a surjection is called a **bijection**. In other words, a function that is *both one-to-one and onto* is called a
bijection.

### Examples

Consider the mapping $f: \mathbb{R} \rightarrow \mathbb{R}$ defined by $f(x) = x$. This is sometimes called the identity map. Note that $f$ is both onto and one-to-one. This means that $f$ is a bijection. It also means that the pre-image of $f$ is an inverse function.

Consider the mapping $f: \mathbb{R} \rightarrow \mathbb{R}$ defined by $f(x) = x^2$. Note that $f$ is into, but not onto, because $f^{−1}(R_{−−}) = \varnothing$, where $\mathbb{R}_{−−} = \{x \in \mathbb{R} : x < 0\}$.

Note also that f is many-to-one, and hence not one-to-one, because $2 \in \mathbb{R}, (−2) \in \mathbb{R}, 2 \ne (−2)$, and both $2^2 = 4$ and $(−2)^2 = 4$.
This means that f is neither an injection nor a surjection. Thus it cannot be a bijection. It also means that the pre-image of f is not an inverse function.

### Composite functions
Let $f : X \rightarrow Y$ be a function of the form $y = f(x)$.
Let $g : Y \rightarrow Z$ be a function of the form $z = g(y)$.
The composite function $h = g \circ f$ is defined by $h(x) = g(f(x))$.
The composite function $h = g \circ f$ is a mapping $h : X \rightarrow Z$ of the
form $z = h(x)$.

Example:
Let $f : \mathbb{R}^2_{++} \rightarrow \mathbb{R}_{++}$ be defined by 
$f(x_1, x_2) = x_1^\alpha \; x_2^{(1 − \alpha)}$
for some fixed $\alpha \in (0, 1)$.

Let $g : \mathbb{R}_{++} \rightarrow \mathbb{R}$ be defined by $g(x) = ln(x)$.

Then the composite function $h = g \circ f$ is a mapping $h: \mathbb{R}^2_{++} \rightarrow \mathbb{R}$ that is defined by $h(x_1, x_2) = g(f(x_1, x_2)) = ln(x_1^\alpha \; x_2^{(1 − \alpha)}) = \alpha \; ln(x_1) + (1 − \alpha) \; ln(x_2)$

### One-to-one functions
A function $f : X \rightarrow Y$ is **one-to-one** if
```{math}
x \ne y \iff f(x) \ne f(y)
```

The contra-positive version of this condition is that
```{math}
f(x) = f(y) \iff x = y
```

Examples:
- $f : \mathbb{R} \rightarrow \mathbb{R}$ defined by $f(x ) = x$ is a one-to-one function.
- $f : \mathbb{R} \rightarrow \mathbb{R}$ defined by $f(x ) = x^2$ is not a one-to-one function.
- $f : \mathbb{R}_+ \rightarrow \mathbb{R}$ defined by $f(x) = x^2$ is a one-to-one function.

### Non-decreasing and strictly increasing functions
A function $f : X \rightarrow \mathbb{R}$, where $X \subseteq \mathbb{R}$, is said to be a **non-decreasing** function if
```{math}
x \leqslant y \iff f(x) \leqslant f(y)
```

A function $f : X \rightarrow \mathbb{R}$, where $X \subseteq \mathbb{R}$, is said to be a **strictly increasing** function if both
- (a) $x = y \iff f(x) = f(y)$; and
- (b) $x < y \iff f(x) < f(y)$.

Note the following:
- A strictly increasing function is also a one-to-one function.
- There are some one-to-one functions that are not strictly increasing.
- A strictly increasing function is also a non-decreasing function.
- There are some non-decreasing functions that are not strictly increasing.

### Economic application: utility functions are not unique
Suppose that $U : X \rightarrow \mathbb{R}$ is a utility function that represents the weak preference relation $\succsim$. This means that $x \succsim y \iff U(x) \geqslant U(y)$.

Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be a strictly increasing function. Consider the composite function $V = f \circ U$. It can be shown that $V$ is also a utility function that represents the weak preference relation $\succsim$. In other words, it can be shown that $x \succsim y \iff V(x) \geqslant V(y)$.

### Example: A Cobb-Douglas utility function
Consider a consumer whose preferences over bundles of strictly positive amounts of each of two commodities can be represented by a utility function $U : \mathbb{R}^2_{++} \rightarrow \mathbb{R}_{++}$ of the form
```{math}
U(x_1, x_2) = Ax_1^\alpha x_2^\beta
```
where $A > 0, \alpha > 0$, and $\beta > 0$.

Such preferences are known as Cobb-Douglas preferences.

- The function $f: \mathbb{R}_{++} \rightarrow \mathbb{R}_{++}$ defined by $f(x) = \left( \frac{1}{A} \right)x$ is strictly increasing. Thus we know that another utility function that represents this consumer’s preferences is
```{math}
V(x_1, x_2) = f(U((x_1, x_2)) = \left( \frac{1}{A} \right) (Ax_1^\alpha x_2^\beta) 
= x_1^\alpha x_2^\beta
```

- The function $g: \mathbb{R}_{++} \rightarrow \mathbb{R}_{++}$ defined by $g(x) = x^{\frac{1}{(\alpha + \beta)}}$ is strictly increasing. (If any relevant surd expression can be either positive or negative, then we will assume that the positive option is chosen throughout this Cobb-Douglas preferences example.) Thus we know that another utility function that represents this consumer’s preferences is
```{math}
W(x_1, x_2) = g(V((x_1, x_2)) = (x_1^\alpha x_2^\beta)^{\frac{1}{(\alpha + \beta)}}
= x_1^\gamma x_2^{(1 - \gamma)}
```
where $ \gamma = \frac{\alpha}{\alpha + \beta} \in (0, 1)$.

- The function $k: \mathbb{R}_{++} \rightarrow \mathbb{R}$ defined by $k(x) = ln(x )$ is strictly increasing. Thus we know that another utility function that represents this consumer’s preferences is
```{math}
Z(x_1, x_2) = k(W((x_1, x_2)) = ln (x_1^\gamma x_2^{(1 - \gamma)})
```
```{math}
= \gamma \; ln(x_1) + (1 − \gamma) \; ln(x_2) 
```


## Some types of functions
Some types of univariate functions include the following:
- Polynomial functions
    - These include constant functions, linear (and affine) functions, quadratic functions, and some power functions as special cases.
- Exponentional functions
- Power functions
- Logarithmic functions
- Trigonometric functions
    - We are unlikely to have enough time to cover trigonometric functions in this course.
There are also multivariate versions of these types of functions.

### Polynomial functions
A **polynomial function** (of one variable) is a function of the form

$$
\begin{align*}
f(x) &= \sum_{i = 0}^n a_i x^i
\\
&= a_n x^n + a_{n − 1} x^{n − 1} + · · · + a_1 x^1 + a_0 x^0
\\
&= a_n x^n + a_{n − 1} x^{n − 1} + · · · + a_1 x + a_0
\end{align*}
$$

In order to distinguish between different types of polynomials, we will typically assume that the coefficient on the term with the highest power of the variable $x$ is non-zero. The only exception is the case in which this term involves $x^0 = 1$, in which case we will allow both $a_0 \ne 0$ and $a_0 = 0$.

#### Examples
- A constant (degree zero) polynomial ($a_0 \ne 0$ or $a_0 = 0$):

$$
f(x) = a_0
$$

- A linear (degree one) polynomial ($a_1 \ne 0$):

$$
f(x) = a_1 x + a_0
$$
It is sometimes useful to distinguish between linear functions and affine functions. See below for details.

- A quadratic (degree two) polynomial ($a_2 \ne 0$):

$$
f(x) = a_2 x^2 + a_1 x + a_0
$$

- A cubic (degree three) polynomial ($a_3 \ne 0$):

$$
f(x) = a_3 x^3 + a_2 x^2 + a_1 x + a_0
$$

### Affine functions and linear functions
We often loosely speak about a linear function of one variable being a function of the form $f(x) = a_1 x + a_0$, where $a_0 \in \mathbb{R}$ and $a_1 \in \mathbb{R} \setminus \{0\}$ are fixed parameters, and $x \in \mathbb{R}$ is the single variable. 

Sometimes, we want to be more precise than this in order to identify the special case in which $a_0 = 0$. In such cases, we call a function of the general form $f(x) = a_1 x + a_0$, in which $a_0 \in \mathbb{R}$, an **affine function**; and a function of the specific form $f(x) = a_1 x$, in which $a_0 = 0$, a **linear function**.

Using this more precise terminology, the family of linear functions is a proper subset of the family of affine functions. Note that we assume that $a_1 \in \mathbb{R} \setminus \{0\}$ in both cases.

### Exponential functions
An **exponential function** is a non-linear function in which the independent variable appears as an exponent.

An example of an exponential function is

$$
f(x) = Ca^x
$$

where $C$ is a fixed parameter (called the **coefficient**), $a \in \mathbb{R}$ is a fixed parameter (called the **base**), and $x \in \mathbb{R}$ is an independent variable (called the **exponent**).

- Note that if $a = 0$, then $f(x)$ is only defined for $x > 0$.
- Note also that if $a < 0$, then sometimes $f(x) \notin \mathbb{R}$. An example of this is the case when $C = 1, a = (−1)$ and $x = \frac{1}{2}$. In this case, we have:

$$
f(\frac{1}{2}) = (1)(−1)^{\frac{1}{2}} = \sqrt{−1} = i \notin \mathbb{R}
$$


#### Popular choices of base
Two popular choices of base for exponential functions are $a = 10$ and $a = e$, where $e$ denotes Euler’s constant. Euler’s constant is defined to be the number

$$
e = \lim_{n \rightarrow \infty} \left(1 + \frac{1}{n} \right)^n
$$
Note that Euler’s constant is an irrational number. This means that it is a real number that cannot be represented as the ratio of an integer to a natural number.

The function $f(x) = e^x$ is sometimes called “the” exponential function.


#### Exponential arithmetic
Assuming that the expressions are well-defined, we have the following laws of exponential arithmetic.

- The power of zero: $a_0 = 1$ if $a \ne 0$, while $a^0$ is undefined if $a = 0$.
- Multiplication of two exponential functions with the same base:

$$
(Ca^x)(Da^y) = CD a^{(x + y)}
$$

- Division of two exponential functions with the same base:

$$
\frac{(Ca^x)}{(Da^y)} = \frac{C}{D} a^{(x - y)}
$$


- An exponential function whose base is an exponential function:

$$
(Ca^x)^y = C^y a^{xy}
$$

### Power functions
A **power function** takes the form

$$
f(x) = Cx^a
$$
where $C \in \mathbb{R}$ is a fixed parameter, $a \in \mathbb{R}$ is a fixed parameter, and $x \in \mathbb{R}$ is an independent variable.

- Note that when $a \in \mathbb{N}$, a power function can also be viewed as a polynomial function with a single term.
- Note that a power function can also be viewed as a type of exponential expression in which the base is $x$ and the exponent is $a$. This means that the laws of exponential arithmetic carry over to “power function arithmetic”.

#### Power function arithmetic
Assuming that the expressions are well-defined, we have the following laws of power function arithmetic.

- The power of zero: $x_0 = 1$ if $x \ne 0$, while $x^0$ is undefined if $x = 0$.
- Multiplication of two power functions with the same base:

$$
(Cx^a)(Dx^b) = CD x^{(a + b)}
$$

- Division of two power functions with the same base:

$$
\frac{(Cx^a)}{(Dx^b)} = \frac{C}{D} x^{(a - b)}
$$


- A power function whose base is itself a power function:

$$
(Cx^a)^b = C^b x^{ab}
$$


#### A rectangular hyperbola
Consider the function $f : \mathbb{R} \setminus \{0\} \rightarrow \mathbb{R}$ defined by $f(x) = \frac{a}{x}$, where $a \ne 0$. This is a special type of power function, as can be seen by noting that it can be rewritten as $f(x) = ax^{−1}$. The equation for the graph of this function is

$$
y = \frac{a}{x}
$$
Note that this equation can be rewritten as $xy = a$. This is the equation of a rectangular hyperbola.

*Graph it on the whiteboard for both the case where $a > 0$ and the case where $a < 0$.*
- Economic application: A constant “own-price elasticity of demand” demand curve.

### Logarithms
A **logarithm** undoes an exponent.
Thus we have

$$
log_a (a^x) = x
$$

The expression $log_a$ stands for “log base $a$” or “logarithm base $a$”. Popular choices of base are $a = 10$ and $a = e$.

The function

$$
g(x) = log_a(x)
$$

is the “logarithm base $a$” function. The “logarithm base $a$” function is the inverse for the “exponential base $a$” function. The reason for this is that

$$
g(f(x)) = g(a^x) = log_a(a^x) = x
$$

#### Natural (or Naperian) logarithms
A “logarithm base *e*” is known as a natural, or Naperian, logarithm. It is named after John Napier. See Shannon (1995, pp. 270-271) for a brief introduction to John Napier. The standard notation for a **natural logarithm** is $ln$, although you could also use $log_e$.

The function

$$ g(x) = ln(x) $$
is the “logarithm base $e$” function. The natural logarithm function is the inverse function for “the” exponential function, since

$$ g(f(x)) = g(e^x) = ln(e^x) = log_e(e^x) = x $$

*Illustrate the inverse (or “reflection through the 45 degree (y = x) line”) relationship between ln (x ) and ex on the whiteboard.*

#### Logarithmic arithmetic
Assuming that the expressions are well-defined, we have the following
laws of logarithmic arithmetic.
- Multiplication of two logarithmic functions with the same base:

$$ log_a(xy) = log_a(x) + log_a(y) $$

- Division of two logarithmic functions with the same base:

$$log_a \left( \frac{x}{y} \right) =  log_a(x) − log_a(y) $$

- A logarithmic function whose argument is an exponential function:

$$log_a(x^y) = y \; log_a(x)$$

Note that

$$log_a(a) = log_a(a^1) = 1$$



### Rational functions
A **rational function** $R(x)$ is simply the ratio of two polynomial functions, $P(x)$ and $Q(x)$. It takes the form

$$
R(x) = \frac{P(x)}{Q(x)} = 
\frac{a_mx^m + a_{m−1} x^{m−1} + · · · + a_1 x + a_0}
{b_n x^n + b_{n−1} x^{n−1} + · · · + b_1 x + b_0}
$$
where

$$ P(x) = a_mx^m + a_{m−1} x^{m−1} + · · · + a_1 x + a_0 $$
is an $m$-th order polynomial (so that $a_m \ne 0$), and

$$ Q(x) =  b_n x^n + b_{n−1} x^{n−1} + · · · + b_1 x + b_0 $$
is an $n$-th order polynomial (so that $b_n \ne 0$).

- Note that there is no requirement that the polynomial functions $P(x)$ and $Q(x)$ be of the same order. (In other words, we do not require that $m = n$.)
- The most interesting case is when $m < n$. In such cases, the rational function $R(x)$ is called a **“proper” rational function**.
- When $m > n$, then we can always use the process of long division to write the original rational function $R(x)$ as the sum of a polynomial function $Y(x)$ and another proper rational function $R^∗(x)$.

This is nicely illustrated by the following example from Chapter 14 of Silverman (1969).

Consider the rational function $R(x) = \frac{x^2 + x − 1}{x − 1}$. Note the following.

$$
\usepackage{polynom}
\polylongdiv{x^2 + x − 1}{x − 1}
$$

Thus we have

$$
R(x ) = x2 + x − 1
x − 1 = (x + 2) +
( 1
x − 1
)
$$
.