# Sequences, series and limits

## Reading guide

### Introductory level references
- {cite:ps}`ayres2013`
- {cite:ps}`basov2011`
- {cite:ps}`haeussler1987`: Chapters 6 and 10 (pp. 164–193 and 375–402).
- {cite:ps}`shannon1995`: Chapters 1.6, 6.6, and 7 (pp. 19–25, 252–256, and 285–355).
- {cite:ps}`sydsaeter2016`: Chapters 2.8, 2.9, 2.10, 2.11, 6.5, 7.9, 7.11, and 10 (pp. 52–62, 182–188, 257–266, 270–273, and 375–406).

### More advanced references
- {cite:ps}`banks2009`
- {cite:ps}`corbae2009`: Chapters 3, 4 and 6 (pp. 72-171 and 259-354).
- {cite:ps}`kolmogorov1970`: Chapters 2 and 3 (pp. 37-117).
- {cite:ps}`simon1994`: Chapters 12 and 29 (pp. 253-272 and 803-821).
- {cite:ps}`spiegel1981a`: Chapters 2 and 3 (pp. 20-56).
- {cite:ps}`takayama1993`: Chapter 1 (pp. 3-71).





## The foundations

Let $X$ be a set and let $d$ be a distance metric that can be used to measure the distance between any two elements of that set. In this course (and in much, but not all, of economics), $X \subseteq \mathbb{R}^n$ for some $n \in \mathbb{N}$, and $d$ will be the Euclidean metric on $\mathbb{R}^n$.

Recall that $\mathbb{R}^n = \times^{n}_{i = 1} \mathbb{R}$.

Let $x \in \mathbb{R}^n$ be the point $x = (x_1, x_2, · · · , x_n)$ and $y \in \mathbb{R}^n$ be the point $(y_1, y_2, · · · , y_n)$. Recall that the Euclidean distance between $x$ and $y$ is defined to be

$$d(x, y) = \sqrt{ \sum_{i = 1}^n (y_i − x_i)^2}$$


## Sequences

A **sequence** from a set $X$ is a mapping of the form $f: \mathbb{N} \rightarrow X$. In effect, it is an assignment of an element from $X$ to each of the natural numbers.

It is often denoted by $\{ x_n \}^\infty_{n=1}$ or $\{ x_n \}_{n \in \mathbb{N}}$, where $x_n \in X$ for all $n \in \mathbb{N}$.

It can be viewed as an indexed set of elements from the set $X$ because it looks like $\{ x_1, x_2, · · · , x_n, · · ·  \}$.

Note that this definition of a sequence requires that all sequences be of countably infinite length.

It does not explicitly allow for finite sequences.

But we can think about a finite sequence as being a truncated sequence, where we throw away all terms for which $n > \hat n$ for some $\hat n \in \mathbb{N}$.  Such a sequence would be written as $\{ x_n \} ^{\hat n}_{n=1}$.

It would look like $\{ x_1, x_2, · · · , x_{\hat n} \}$.
In practice, we are often interested in the limiting behaviour of sequences, so that the restriction to infinite sequences is not a problem.

### Important notational comment

We have been looking at sequences drawn from some set $X$. The $n$-th element of such a sequence was denoted by $x_n$.  This requires that $x_n \in X$.

Do not confuse this $x_n$ with the $n$-th coordinate of the point $x = (x_1, x_2, · · · , x_{(n−1)}, x_n, x+{(n+1)}, · · · , x_L) \in \mathbb{R}^L$.

If we are considering sequences of points (or vectors) in $\mathbb{R}^L$, then we might want to use superscripts to denote sequence position and subscripts to denote coordinates.
- In this way, the $k$-th element of the sequence $\{ x_n \}^\infty_{n=1}$ would be the point (or vector) 
$x_k = (x^k_1, x^k_2, · · · , x^k_{(n−1)}, x^k_n, x^k_{(n+1)}, · · · , x^k_L)$.  Note that the $k$ in this case is an index, NOT a power.


## Sub-sequences
Let $g: \mathbb{N} \rightarrow \mathbb{N}$ be an increasing map of the form $g(k) = n_k$.
- This means that $g(k + 1) = n_{k+1} > n_k = g(k)$ for all $k \in \mathbb{N}$.

If the map $f: \mathbb{N} \rightarrow X$ is a sequence from $X$, then so is the map $h: \mathbb{N} \rightarrow X$ given by $h = f \circ g$.
- Note that $h(k) = f(g(k)) = f(n_k)$.
- If $f$ generates the sequence
$\{x_1, x_2, · · · , x_{n_1 − 1}, x_{n_1} , x_{n_1 + 1}, · · · , x_{n_2 − 1}, x_{n_2}, x_{n_2 + 1}, · · ·  \}$, then $h$ generates the sequence $\{x_{n_1} , x_{n_2} , · · ·  \}$.

The sequence $\{x_{n_k} \}_{n_k \in \mathbb{N}}$ is a **sub-sequence** of the sequence $\{ x_n \}_{n \in \mathbb{N}}$.

Note that every term in the sequence $\{ x_{n_k} \}_{n_k \in \mathbb{N}}$ falls somewhere in the sequence $\{ x_n \}_{n \in \mathbb{N}}$.

Note also that the (relative) order in which the terms appear is the same for each of the sequences.


### Example
Consider the sequence $\{ x_n \}_{n \in \mathbb{N}}$ where $x_n = \frac{1}{n}$.
- The map for this sequence is $f(n) = \frac{1}{n}$.
- The sequence looks like $\left\{1, \frac{1}{2}, \frac{1}{3} , · · · , \frac{1}{n}, · · ·  \right\}$.

Consider the increasing map $g: \mathbb{N} \rightarrow \mathbb{N}$ defined by $g(k) = k^2$.
- This, along with $f$, generates the sub-sequence map

$$
h(k) = f(g(k)) = f(k^2) = \frac{1}{k^2}$$

- The associated sub-sequence is

$$
\left\{  \frac{1}{k^2}  \right\}_{k \in \mathbb{N}}
=
\left\{ 1, \frac{1}{4}, \frac{1}{9}, · · · , \frac{1}{n^2} , · · ·  \right\}$$

Consider the increasing map $g: \mathbb{N} \rightarrow \mathbb{N}$ defined by $g(k) = 2^k$.
- This, along with $f$, generates the sub-sequence map

$$h(k) = f(g(k)) = f(2^k) = \frac{1}{2^k}$$

- The associated sub-sequence is

$$\left\{  \frac{1}{2^k}  \right\}_{k \in \mathbb{N}}
=
\left\{ \frac{1}{2}, \frac{1}{4}, \frac{1}{8} , · · · , \frac{1}{2^n}, · · · \right\} $$


## Open and closed balls

Let $X \subseteq \mathbb{R}^n$, and $d^n$ be the $n$–dimensional Euclidean distance.

An **open ball** with radius $\epsilon$ around the point $x_0 \in X$ in this metric
space is a set of the form

$$ B(x_0, \epsilon) = \{ x \in X : d^n(x, x_0) < \epsilon \}$$

This set is sometimes known as an $\epsilon$–neighbourhood of $x_0$.


A **closed ball** with radius $\epsilon$ around the point $x_0 \in X$ is a set of the form

$$ \overline{B} (x_0, \epsilon) = \{ x \in X : d^n(x, x_0) \leqslant \epsilon \}$$


### Economic application: local non-satiation

Suppose that $X \subseteq \mathbb{R}^n$, $\succsim$ is a rational weak preference relation defined on $X$ , and $\succ$ is the induced strict preference relation on $X$.

$\succsim$ is said to be locally non-satiated at the point $x \in X$ if, for each $\epsilon > 0$, there exists some other point $x′ \in B_\epsilon (x)$ such that $x′ \succ x$.
- Note that that $B_\epsilon (x) = \{ y \in X : d(y, x) < \epsilon \}$.

$\succsim$ is said to be locally non-satiated on $X$ if it is locally non-satiated at every point $x \in X$.

Local non-satiation of preferences on $X$ ensures that:
- Individuals exhaust their budgets;
- Bliss points do not exist; and
- Indifference curves are not fat.

*Briefly illustrate these three implications of local non-satiation on the white-board.*


## Convergence and limits
Let $\{ x_n \}_{n \in \mathbb{N}}$ be a sequence from $X$ and $x \in X$ be a point in $X$.

The sequence $\{ x_n \}_{n \in \mathbb{N}}$ is said to be a **convergent sequence** if, for each $\epsilon > 0$, there exists $\hat n_\epsilon \in \mathbb{N}$ such that $d(x_i, x_j) < \epsilon$ for all $(i, j) \in \{ (k, l) \in \mathbb{N} \times \mathbb{N}: k > \hat n_\epsilon, l > \hat n_\epsilon \}$ (in other words, for all
$i, j > \hat n_\epsilon$).


A convergent sequence is known as a **Cauchy sequence**.


The sequence $\{ x_n \}_{n \in \mathbb{N}}$ is said to converge to $x \in X$ if, for each $\epsilon > 0$, there exists $\hat n_\epsilon \in \mathbb{N}$ such that $x_n \in B(x, \epsilon)$ for all $n > \hat n_\epsilon$.

In this case, we say that $x$ is the **limit** of the sequence $\{ x_n \}_{n \in \mathbb{N}}$.

- If a sequence converges to a particular limit, say $x$, then so does every sub-sequence of that sequence.

Sequences in metric spaces can have at most one limit.
- Such a sequence either converges to a unique limit or it does not converge.
- This is not true for sequences in some non-metrisable topological spaces. However, we will not encounter such spaces in this course.


### Example

Consider the sequence $\left\{  \frac{1}{n} \right\}_{n \in \mathbb{N}}$ on $\mathbb{R}$. Claim: This sequence converges to the point $0 \in \mathbb{R}$.

Note that

$$
d \left( \frac{1}{k}, 0 \right)
=
| 0 − \frac{1}{k} |
=
∣ −\frac{1}{k} ∣
= \frac{1}{k}
$$

Consider some arbitrary $\epsilon > 0$. Note that

$$
d \left( \frac{1}{k}, 0 \right) < \epsilon
\iff \frac{1}{k} < \epsilon \iff k > \frac{1}{e}
$$
Thus we can set $\hat n_\epsilon = min (n \in \mathbb{N} : n > \frac{1}{e})$.


### Convergence examples
- The sequence $\left\{  \frac{1}{n} \right\}_{n \in \mathbb{N}}$ converges to the point $x = 0$.
- The sequence $\left\{  \frac{1}{n^2} \right\}_{n \in \mathbb{N}}$ converges to the point $x = 0$.
    - Recall that $\left\{  \frac{1}{n^2} \right\}_{n \in \mathbb{N}}$ is a sub-sequence of $\left\{  \frac{1}{n} \right\}_{n \in \mathbb{N}}$
- The sequence $\left\{  \frac{1}{2^n} \right\}_{n \in \mathbb{N}}$ converges to the point $x = 0$.
    - Recall that $\left\{  \frac{1}{2^n} \right\}_{n \in \mathbb{N}}$ is a sub-sequence of $\left\{  \frac{1}{n} \right\}_{n \in \mathbb{N}}$
- The sequence $\left\{  \frac{(−1)^n}{n} \right\}_{n \in \mathbb{N}} = \{ −1, \frac{1}{2}, \frac{−1}{3} , · · ·  \}$ converges to the point $x = 0$.
- The sequence $\left\{  \frac{n}{n + 1} \right\}_{n \in \mathbb{N}} = \{  \frac{1}{2}, \frac{2}{3}, \frac{3}{4}, · · ·  \}$ converges to the point $x = 1$.
- The sequence $\{ (−1)^n \}_{n \in \mathbb{N}} = \{ −1, 1, −1, 1, · · ·  \}$ does not converge.
- The sequence $\{ n \}_{n \in \mathbb{N}}$ does not converge.
- The sequence $\left\{ ( \frac{1}{n} , \frac{(n−1)}{n} ) \right\}_{n \in \mathbb{N}}$ converges to $(0, 1)$.
- The sequence $\left\{ ( \frac{(−1)^n}{n}, \frac{(−1)^n}{n} ) \right\}_{n \in \mathbb{N}}$ converges to $(0, 0)$.
- The sequence $\{ ((−1)^n, (−1)^n) \}_{n \in \mathbb{N}}$ does not converge.
- The sequence $\{ (n, n) \}_{n \in \mathbb{N}}$ does not converge.


### Mathematical application: Euler's constant (e)

**Euler’s constant**, which is usually denoted by $e$, is an irrational number that is defined as the limit of a particular sequence of rational numbers.

Consider the sequence

$$
\{ x_n \}_{n \in \mathbb{N}} = \left\{ \left(1 + \frac{1}{n} \right)^n \right\}_{n \in \mathbb{N}} $$

This sequence converges to Euler’s constant. Euler’s constant is defined to be

$$
e = \lim_{n \rightarrow \infty} \left(1 + \frac{1}{n} \right)^n $$

An excel file that was created by Suren Basov calculates the first 5, 193 terms in this sequence. This excel file is available on the Wattle site for this course.


### Economic application: equilibria in games

Some equilibrium concepts in non-cooperative games make use of convergent sequences of beliefs. These include:
- Sequential equilibria in extensive form games
- Trembling-hand perfect equilibria in extensive form games
- Trembling-hand perfect equilibria in normal form games
- Proper equilibria in normal form games

### Econometric application: asymptotic results
Various asymptotic results in econometrics make use of convergent sequences. Examples include the following:
- The consistency of some estimators
    - This involves convergence in probability
    - An estimator $\hat \theta$ of a parameter $\theta$ is said to be consistent if $\text{plim } \hat \theta = \theta$.
- The asymptotic distribution of some transformation of an estimator.
    - This involves the convergence in distribution of some transformation of an estimator.
    - A transformation is typically needed to stabilise the variance of the asymptotic distribution (that is, prevent the asymptotic variance of the estimator from collapsing to zero).
    - For example, sometimes we will get something like $\sqrt{n}(\hat \theta − \theta) \xrightarrow{d} N(0, \sigma^2)$.
 
 
### Economic application: continuity of preferences

Suppose that $X \subseteq \mathbb{R}^L_{+}$ and $\succsim$ is a rational weak preference relation defined on X .

Let $\{ x_n \}_{n \in \mathbb{N}}$ and $\{ yn \}_{n \in \mathbb{N}}$ be a pair of sequences from $X$ such that $x_n \succsim y_n$ for all $n \in \mathbb{N}$, $\lim_{n \rightarrow \infty} x_n = x_\infty \in X$, and $\lim_{n \rightarrow \infty} y_n = y_\infty \in X$.

The weak preference relation $\succsim$ is said to be **continuous** if, for any such pair of sequences, we have $x_\infty \succsim y_\infty$.

### Economic application: lexicographic preferences are NOT continuous on $\mathbb{R}^2_+$

Suppose that a consumer has preferences defined over bundles of non-negative amounts of each of two goods. More precisely, suppose that the consumption set for this consumer (over which his or her preferences are defined) is $X = \mathbb{R}^2_{+}$.

Suppose that the consumer has lexicographic preferences on $\mathbb{R}^2_{+}$. This means that the consumer weakly prefers bundle $x = (x_1, x_2)$ to bundle $y = (y1, y2)$ (denoted by $x \succsim y$ ) if either (i) $x_1 > y_1$, or (ii) both $x_1 = y_1$ and $x_2 > y_2$. In any other circumstance, the consumer does not weakly prefer bundle $x$ to bundle $y$ (denoted by $x \not\succsim y$).

- Consider the sequence of bundles $\{ x^n \}_{n \in \mathbb{N}}$ where  $x_n = (x^n_1 , x^n_2) = (\frac{1}{n} , 0)$
- Consider also the sequence of bundles \{ y^n \}n \in \mathbb{N} where $y_n = (y^n_1 , y^n_2) = (0, 1)$

Note that 
$x^n_1 = \frac{1}{n} > 0 = y_1^n$ for all $n \in \mathbb{N}$. Thus we know that $x^n \succsim y^n$ for all $n \in \mathbb{N}$.

However, note also that $x^\infty_1 = \lim_{n \rightarrow \infty} x^n_1 = \lim_{n\rightarrow \infty} \frac{1}{n} = 0$. Thus we have $x^\infty_1 = 0 = y^\infty_1$ and $x^\infty_2 = 0 < 1 = y^\infty_2$. In other words, $x^\infty_1 = y^\infty_1$ and $x^\infty_2 \not\geqslant y^\infty_2$. Thus we know that $x^\infty \not\succsim y^\infty$.

Since there are two sequence of bundles, $\{ x^n \}_{n \in \mathbb{N}}$ and $\{ y^n \}_{n \in \mathbb{N}}$, such that both (i) $x^n \succsim y^n$ for all $n \in \mathbb{N}$, and (ii) $x^\infty \not\succsim y^\infty$, we know that this preference ordering is NOT continuous.


## Series

A **series** can be viewed as the sum of the terms in a sequence.
If we have a sequence $\{ x_n \}_{n \in \mathbb{N}}$ on $X$, then the associated series is the sum

$$ \sum_{n \in \mathbb{N}} x_n = \sum_{n=1}^{\infty} x_n = x_1 + x_2 + x_3 + · · · $$

Sometimes we are interested in the total sum of the sequence, as above. At other times, we might be interested in the partial sum of the first $N$ terms of the sequence, 

$$\sum_{n=1}^N x_n = x_1 + x_2 + x_3 + · · · + x_N $$


We might sometimes want to start the summation at $n = 0$. We can do this by employing a change of index.

- If we let $k = n − 1$, the total sum of the sequence can be expressed as

$$ \sum_{n=1}^{\infty} x_n = \sum_{k=0}^{\infty−1} x_{k+1} = \sum_{k=0}^{\infty} x_{k+1}$$

(because $\infty − 1 = \infty$).

- If we let $k = n − 1$, the partial sum of the first $N$ terms of the sequence can be expressed as

$$\sum_{n=1}^{N} x_n = \sum_{k=0}^{N - 1} x_{k+1}$$


## The principle of mathematical induction
Note that the components of a sequence (and hence the individual terms in a series) are indexed by natural numbers.

Suppose that we have a claim that can be indexed by the set of natural numbers ($\mathbb{N} = \{ 1, 2, · · · , n, · · ·  \}$) and we want to prove that this claim is true for all $n \in \mathbb{N}$.  Denote the $n$-th case of this claim by $A_n$. 

A proof of the claim by **deduction** might proceed as follows (where the symbol “$\land$” can be interpreted as meaning “and”):

$$ A_1 \land A_2 \land A_3 · · · \land A_n \land · · · \Rightarrow A$$

The (countably) infinite number of cases that would need to be verified for such a proof by deduction to be implemented make it unfeasible. Instead, a **proof by induction** might be appropriate in such cases.


A proof by induction makes use of the “principle of mathematical induction”, which is one of the three Peano axioms that are sometimes used to construct the set of natural numbers.

The principle of mathematical induction says that if $X \subseteq \mathbb{N}$ has the following properties: (a) $1 \in X$ and (b) $s(n) \in X$ for all $n \in X$; then $X = \mathbb{N}$.


### The Peano axioms
This material is drawn from {cite:ps}`banks2009` (pp. 2-13).

The following three axioms are sometimes used to formally construct the set of natural numbers. They are known as the *Peano axioms* because they were developed by Guiseppe Peano.

The Peano axioms are as follows:
- (PA1): There is a non-empty set of natural numbers $\mathbb{N}$, and a one-to-one function $s: \mathbb{N} \rightarrow \mathbb{N}$ called the successor function.
- (PA2): $\mathbb{N}$ has an element $1$ that satisfies $s(n) \ne 1$ for all $n \in \mathbb{N}$.
- (PA3) (The Principle of Mathematical Induction): If $X \subseteq \mathbb{N}$ has the following properties: (a) $1 \in X$ and (b) $s(n) \in X$ for all $n \in X$; then $X = \mathbb{N}$.


### Proof by induction
Again suppose that we have a claim that can be indexed by the set of natural numbers ($\mathbb{N} = \{ 1, 2, · · · , n, · · ·  \}$) and we want to prove that this claim is true for all $n \in \mathbb{N}$.  Denote the $n$-th case of this claim by $A_n$.

A proof of this claim by **induction** proceeds as follows:

$$A_1 \land (\forall n \in N)(A_n \Rightarrow A_{(n+1)}) \Rightarrow A$$


In effect, proofs by mathematical induction proceed as follows:
- Step 1: Show that the claim is true when $n = 1$.
- Step 2: Assume that the claim is true for the arbitrary case of $n = k$ (this is known as the inductive assumption) and show that, if this inductive assumption is true, then the claim must also be true for the case of $n = (k + 1)$. Note that it is imperative that the inductive assumption be used in the process of showing that the claim is true for $n = (k + 1)$ if an inductive proof is to be valid.
- Step 3: Apply the principle of mathematical induction to conclude that the claim is true for all $n \in \mathbb{N}$.

The logic underlying a proof by induction is very intuitive. It basically establishes that the claim is true for $n = 1$, and that if the claim is true for $n = 1$, then it must also be true for $n = 2$, which means it must also be true for $n = 3$, which means it must also be true for $n = 4$, and so on and so forth, *ad infinitum*.

The validity of the method of proof by induction can actually be established through a proof by contradiction. See {cite:ps}`kolmogorov1970` (p. 28) for details.

The method of proof by induction can be extended beyond the set of natural numbers to any “well-ordered set”, where “well-ordered” has a very precise mathematical meaning. This extended version of proof by induction is known as “proof by transfinite induction”. See {cite:ps}`kolmogorov1970` (pp. 28-29) for details.

#### Examples

```{dropdown} Example 1

This example comes from {cite:ps}`simon1994` (pp. 856-857).

We want to show that 
$\sum\limits_{i = 1}^n x = \frac{n(n+1)}{2}$ for all $n \in \mathbb{N}$.

The proof proceeds as follows.

Note that $\sum\limits_{i = 1}^{n} x = 1$ and $\frac{1(1+1)}{2} = \frac{2}{2} = 1$. Thus the claim is true for $n = 1$.

Assume that the claim is true for $n = k$. In other words, assume that 
$\sum\limits_{i = 1}^k x = \frac{k(k+1)}{2}$.

Consider the case of $n = (k + 1)$. 
- Note that $\sum\limits^{k+1}_{i =1} x = (\sum\limits^{k}_{i = 1} x ) + (k + 1) = \frac{k(k+1)}{2} + (k + 1)$ by our inductive assumption. 
- Note that $\frac{k(k+1)}{2} + (k + 1) = \frac{k(k+1)}{2} + \frac{2(k+1)}{2} = \frac{(k+2)(k+1)}{2}$.
- Note that $\frac{(k+2)(k+1)}{2} = \frac{((k+1)+1)(k+1)}{2} = \frac{(k+1)((k+1)+1)}{2}$.

Thus we have shown that, if the claim is true for $n = k$, then it must also be true for $n = (k + 1)$.

Since (a) the claim is true for $n = 1$, and (b) if the claim is true for $n = k$, then it is also true for $n = (k + 1)$, we can conclude by the principle of mathematical induction that the claim is true for all $n \in \mathbb{N}$.
```


```{dropdown} Example 2

Claim: $\sum\limits^{n}_{x = 1} x^2 = \frac{n(n+1)(2n+1)}{6}$.

We will prove this claim by induction.

**Step one: $P(1)$ is true**.

Consider the case where $n = 1$. Note that $\sum\limits_{x = 1}^1 x^2 = 1^2 = 1$.

Note also that

$$
\begin{align*}
\frac{n (n + 1) (2n + 1)}{6} &= {1 (1 + 1) (2 (1) + 1)}{6} \\
&= \frac{1 (2) (2 + 1)}{6} \\
&= \frac{1 (2) (3)}{6} \\
&= \frac{6}{6} \\
&= 1
\end{align*}
$$
Thus the claim is true when $n = 1$.

**Step two: $P(k)$ true implies $P(k+1)$ true.**
Suppose that the claim is true when $n = k$, so that

$$\sum_{x = 1}^k x^2 = \frac{k (k + 1) (2k + 1)}{6}$$

Consider the case where $n = (k + 1)$. We have

$$
\begin{align*}
\sum_{x = 1}^{k + 1} x^2 &= \left( \sum_{x = 1}^{k} x^2 \right) + (k + 1)^2 \\
&= \frac{k (k + 1) (2k + 1)}{6} + (k + 1)^2 \text{ from the inductive assumption} \\
&= \frac{k (k + 1) (2k + 1)}{6} + \frac{6(k + 1)^2}{6} \\
&= \frac{k (k + 1) (2k + 1) + 6 (k + 1)^2}{6} \\
&= \frac{(k + 1) \{ k (2k + 1) + 6 (k + 1) \}}{6} \\
&= \frac{(k + 1) \{ 2k^2 + k + 6k + 6 \}}{6} \\
&= \frac{(k + 1) \{ 2k^2 + 7k + 6 \}}{6} \\
&= \frac{(k + 1) \{ (2k + 3) (k + 2) \}}{6} \\ 
&= \frac{(k + 1) (2k + 3) (k + 2)}{6} \\
&= \frac{(k + 1) (k + 2) (2k + 3)}{6} \\
&= \frac{(k + 1) ((k + 1) + 1) (2 (k + 1) + 1)}{6}
\end{align*}
$$

Thus we have

$$
\sum_{x = 1}^{k + 1} x^2 = \frac{(k + 1) ((k + 1) + 1) (2 (k + 1) + 1)}{6}
$$

As such, we know that $P(k)$ implies $P(k + 1)$.

**Step three: Conclusion**

We have shown that the claim is true for the case where $n = (k + 1)$ if it is true for the case where $n = k$. We have also shown that the claim is true for the case where $n = 1$. Thus we know, from the principle of mathematical induction, that the claim is true for all $n \in \mathbb{N}$.
```



```{dropdown} Example 3

Claim: $\sum\limits^{n}_{x = 1} x^3 = \frac{n^2(n+1)^2}{4}$. We will prove this claim by induction.

**Step one: P(1) is true.**
Consider the case where $n = 1$.

- Note that $\sum\limits_{x = 1}^1 x^3 = 1^3 = 1$.
- Note also that

$$
\begin{align*}
\frac{n^2 (n + 1)^2}{4} &= \frac{1^2 (1 + 1)^2}{4} \\
&= \frac{1 (2)^2}{4} \\
&= \frac{1 (4)}{4} \\
&= \frac{4}{4} \\
&= 1
\end{align*}
$$

Thus the claim is true when $n = 1$.


**Step two: $P(k)$ true implies $P(k+1)$ true.**
Suppose that the claim is true when $n = k$, so that

$$\sum_{x = 1}^k x^3 = \frac{k^2 (k + 1)^2}{4}$$
Consider the case where $n = (k + 1)$. We have

$$
\begin{align*}
\sum_{x = 1}^{k + 1} x^3 &= \left( \sum_{x =1}^k x^3 \right) + (k + 1)^3 \\
&= \frac{k^2 (k + 1)^2}{4} + (k + 1)^3  \text{ from the inductive assumption } \\
&= \frac{k^2 (k + 1)^2}{4} + \frac{4 (k + 1)^3}{4} \\
&= \frac{k^2 (k + 1)^2 + 4 (k + 1)^3}{4} \\
&= \frac{(k + 1)^2 \{ k^2 + 4 (k + 1) \}}{4} \\
&= \frac{(k + 1)^2 \{ k^2 + 4k + 4 \}}{4} \\
&= \frac{(k + 1)^2 (k + 2)^2}{4} \\
&= \frac{(k + 1)^2 ((k + 1) + 1)^2}{4}
\end{align*}
$$
Thus we have 

$$\sum_{ x = 1}^n x^3 = \frac{n^2 (n + 1)^2}{4}$$

As such, we know that $P(k)$ implies $P(k + 1)$.

**Step three: Conclusion**

We have shown that the claim is true for the case where $n = (k + 1)$ if it is true for the case where $n = k$. We have also shown that the claim is true for the case where $n = 1$. Thus we know, from the principle of mathematical induction, that the claim is true for all $n \in \mathbb{N}$.
```


```{dropdown} Example 4

Claim: $\sum^n_{x = 1} (2x − 1) = n^2$

We will prove this claim by induction.

**Step one: P(1) is true.**
Consider the case where $n = 1$.

Note that $\sum_{x = 1}^{1} (2x − 1) = 2 (1) − 1 = 2 − 1 = 1$

and $1^2 = 1$. Thus the claim is true when $n = 1$.


**Step two: $P(k)$ true implies $P(k+1)$ true.**
Suppose that the claim is true when $n = k$, so that

$$\sum^k_{x = 1} (2x − 1) = k^2$$

Consider the case where $n = (k + 1)$. We have

$$
\begin{align*}
\sum_{x = 1}^{k + 1} (2x − 1) \\
&= \left( \sum_{x =1}^k (2x − 1) \right) + (2 (k + 1) − 1) \\
&= k^2 + (2 (k + 1) − 1) \text{ from the inductive assumption } \\
&= k^2 + (2k + 2 − 1) \\
&= k^2 + (2k + 1) \\
&= k2 + 2k + 1 \\
&= (k + 1)^2
\end{align*}
$$

Thus we have  

$$\sum_{x = 1}^{k + 1} (2x − 1) = (k + 1)^2$$

As such, we know that $P(k)$ implies $P(k + 1)$.

**Step three: Conclusion**

We have shown that the claim is true for the case where $n = (k + 1)$ if it is true for the case where $n = k$. We have also shown that the claim is true for the case where $n = 1$. Thus we know, from the principle of mathematical induction, that the claim is true for all $n \in \mathbb{N}$.
```


```{dropdown} Example 5


This example comes from Exercise A.1.7 in {cite:ps}`simon1994` (p. 858).

We want to show that $n < 2^n$ for all $n \in \mathbb{N}$. The proof proceeds as follows:
- Note that $1 < 2^1 = 2$, so the claim is true when $n = 1$.
- Assume that the claim is true when $n = k$. This means that $k < 2^k$.
- Consider the case of $n = (k + 1)$.
- If we add $1$ to both sides of the inequality in our inductive assumption, we obtain $k + 1 < 2^k + 1$.
- Since $k \geqslant 1$, we know that $1 < 2 = 2^1 \leqslant 2^k$.
- This means that $1 \leqslant 2^k$.
- This means that $2^k + 1 < 2^k + 2^k$.
- Note that $2^k + 2^k = 2(2^k ) = 2^{k+1}$.
- This means that $2^k + 1 < 2^{k+1}$.
- Since $k + 1 < 2^k + 1$ and $2^k + 1 < 2^{k+1}$, we know that $(k + 1) < 2^{k+1}$.
- Thus, if the proposition is true when $n = k$, then it must also be true when $n = (k + 1)$.
- Since (a) the claim is true for $n = 1$, and (b) the claim is true for $n = k$, then it is also true for $n = (k + 1)$, we can conclude, by the principle of mathematical induction, that the claim is true for all $n \in \mathbb{N}$.
```



## Arithmetic progressions

Consider a real sequence $\{ x_n \}_{n \in \mathbb{N}}$ in which $x_n = a + (n − 1) d$.

This sequence is known as an **arithmetic progression** because the difference between any two consecutive terms of the sequence (with the highest index first: $x_{m+1} − x_m$) is equal to $d$.

The infinite series associated with this sequence is

$$
\sum_{n=1}^\infty (a + (n − 1) d ) = \sum_{k=0}^\infty (a + kd)$$

The partial sum of the first (N + 1) terms of this series is given by

$$
\begin{align*}
S_{(N+1)} &= \sum_{n=1}^{N + 1} (a + (n − 1) d ) \\
&= \sum_{k=0}^{N} (a + kd ) \\
&= \frac{(2a + Nd ) (N + 1)}{2}
\end{align*}
$$
This validity of this formula can be established through a proof by induction. We do this below (after some other brief comments).

Note that the partial sum of the first $N$ terms of an arithmetic progression is given by

$$S_N = \frac{(2a + (N − 1)d ) N}{2} = (N) \left( \frac{\{ (a) + (a + (N − 1) d ) \}}{2} \right)$$

As is noted in {cite:ps}`shannon1995` (p. 302), this formula has a very simple interpretation. It is simply the number of terms in the sequence that are being summed times the average of the first and last terms in that sequence.

**Claim:** $\sum\limits^{N+1}_{n=1} (a + (n − 1) d ) = \frac{(2a+Nd )(N+1)}{2}$.

**Proof:** (Note that the following proof is based on the one that is provided in {cite:ps}`basov2011` (pp. 22-23). By mathematical induction on $N$.

Let $N = 1$. We have

$$
\sum_{n=1}^{N + 1} (a + (n − 1) d ) = \sum_{n=1}^2 (a + (n − 1) d ) \\
= (a + (1 − 1)d ) + (a + (2 − 1)d ) \\
= (a + 0d + a + 1d ) \\
= (2a + d )
$$
and

$$
\frac{(2a + Nd ) (N + 1)}{2} = \frac{(2a + 1d ) (1 + 1)}{2} = \frac{(2a + d )(2)}{2} = (2a + d )$$

Thus the claim is true for $N = 1$.

Assume that the claim is true for $N = k$. In other words, assume that 

$$
\sum_{n=1}^{k + 1} (a + (n − 1) d ) = \frac{(2a + kd ) (k + 1)}{2}$$

(Call this the “inductive assumption”.)

Now consider the case when $N = (k + 1)$. We have

$$
\begin{align*}
\sum_{n=1}^{k + 2} (a + (n − 1) d ) \\
&= \left( \sum_{n=1}^{k + 1} (a + (n − 1) d ) \right) + (a + (k + 2 − 1) d ) \\
&= \frac{(2a + kd ) (k + 1)}{2} + (a + (k + 1)d ) \text{ (by the inductive assumption) } \\
&= \frac{(2a + kd ) (k + 1)}{2} + \frac{(2a + 2(k + 1)d )}{2} \\
&= \frac{2a(k + 1) + k(k + 1)d + 2a + 2(k + 1)d}{2} \\
&= \frac{2a ((k + 1) + 1) + ((k + 1) + 1) (k + 1)d}{2} \\
&= \frac{(2a + (k + 1)d ) ((k + 1) + 1)}{2}
\end{align*}
$$

Since this is in the required form, and we used the inductive assumption in the process of deriving it, we have shown that, if the claim is true when $N = k$, then it is also true when $N = (k + 1)$.

Since $P(1)$ is true, and $P(k) \Rightarrow P(k + 1)$, we know, by the principle of mathematical induction, that the claim is true for all $N \in \mathbb{N}$.


Note that the sum of all of the terms in an infinite arithmetic progression is unbounded, since

$$
\begin{align*}
S_\infty &= \lim_{N \rightarrow \infty} S_{N + 1} \\
&= \lim_{N \rightarrow \infty} \sum_{n=1}^{N + 1} (a + (n − 1)d ) \\
&= \lim_{N \rightarrow \infty} \frac{(2a + Nd ) (N + 1)}{2} \\
&= \begin{cases}
\infty \quad \text{ if } d > 0, \\
−\infty \quad \text{ if } d < 0.
\end{cases}
\end{align*}
$$


## Geometric progressions

Consider a real sequence $\{ x_n \}_{n \in \mathbb{N}}$ in which $x_n = ar^{(n−1)}$. We will assume that $r \notin \{ 0, 1 \}$.

This sequence is known as a **geometric progression** because the ratio of any two consecutive terms of the sequence (with the highest index on numerator: $\frac{x_{m+1}}{x_m}$ ) is equal to $r$.

The infinite series associated with this sequence is

$$
\sum_{n=1}^{\infty} ar^{(n−1)} = \sum_{k=0}^{\infty} ar^k$$

The partial sum of the first $(N + 1)$ terms of this series is given by

$$
\begin{align*}
S_{(N+1)} &= \sum_{n=1}^{N+1} ar^{(n−1)} \\
&= \sum_{k=0}^{N} ar^k \\
&= a \sum_{k=0}^N r^k \\
&= \frac{a ( 1 − r^{(N+1)})}{(1 − r )}
\end{align*}
$$

This validity of this formula can be established through a proof by induction. This is left for you to do as an exercise.

The sum of all of the terms in an infinite geometric progression is given by

$$
\begin{align*}
S_\infty &= \lim_{N \rightarrow \infty} S_{N+1} \\
&= \lim_{N \rightarrow \infty} \sum_{n=1}^{N+1} ar^{(n−1)} \\
&= \lim_{N \rightarrow \infty} \frac{a ( 1 − r^{(N+1)})}{(1 − r )} \\
&= \begin{cases}
\frac{a}{(1−r )} \quad \text{ if } |r| < 1, \\
\pm\infty \quad \text{ if } |r| > 1.
\end{cases}
\end{align*}
$$


## Application: financial economics
- In economics, finance, and accounting, we often need to evaluate time streams of payoffs.
- In general, we cannot simply add them all together in their raw form.
- There are many reasons for this. Some of these reasons include the following:
    - Inflation (or deflation): The purchasing power of one dollar varies over time.
    - Foregone interest: There is an opportunity cost of time in the form of interest that could be earned.
    - Time preference: People might have a preference for the timing of payoffs.

- We need to adjust the raw payoffs to put them in a commensurable form.
- This might involve using constant dollar estimates or accounting for expected inflation to deal with changes in the price level.
- It might involve calculating the present value (or a specific period future value) of all of the payoffs.
- It might involve discounting future payoffs in some fashion if the decision-maker is impatient.
- The techniques for doing this are part of the subject matter of decision theory (from microeconomics) and financial mathematics.
- The mathematical techniques that are employed in financial mathematics include sequences, series, limits, and polynomial equations.

Overview of this application:
- Simple interest
- Compound interest
- Present value and future value

### Simple interest
- Suppose that you borrow $\$P$ now (period zero) and are required to pay it off in one single payment in period $n$.
- You will be charged *simple* interest at the rate of $100 (i )$ per cent per period.
- Simple interest is only charged on the remaining principal at a point in time and not on the entire balance owed at that point in time.
- If you do not make any payments on the loan until the end of the loan, the sequence of additions to your loan balance is $\{ At  \}^n_{t=0} = \{ P, iP, iP, · · · , iP \}$.
- If you do not make any payments on the loan until the end of the loan, the sequence of outstanding loan balances is $\{ Bt  \}^n_{t=0} = \{ P, P + iP, P + 2iP, · · · , P + niP \}$. (Note that this is an arithmetic progression. However, this does not really matter here, because we do not need to calculate its sum.)
- If no repayments are made until period n and the entire outstanding balance is repaid in that period, the future amount that must be paid in period $n$ is given by

$$
S_n = P + \sum_{k=1}^n iP = P + niP = (1 + ni ) P$$

In this case, the total interest payments on this loan are equal to

$$ I_S = S_n − P = (1 + ni ) P − P = niP $$

### Compound interest
- Suppose that you borrow $\$P$ now (period zero) and are required to pay it off in one single payment in period $n$.
- You will be charged *compound* interest at the rate of $100 (i )$ per cent per period.
- Compound interest is charged on the entire balance owed at a point in time.
- The compounding will take place once per period, so that the compounding periods and the charging periods coincide.

- If you do not make any payments on the loan until the end of the loan, the sequence of additions to your loan balance is
$ \{ At  \}^n_{t=0} = \{ P, iP, i (1 + i )P, · · · , i (1 + i )^{(n−1)}P  \}$.
- If you do not make any payments on the loan until the end of the loan, the sequence of outstanding loan balances is
$\{ Bt  \}^n_{t=0} = \{ P, (1 + i )P, (1 + i )^2 P, · · · , (1 + i )^n P \}$. (Note that this is a geometric progression. However, this does not really matter here, because we do not need to calculate its sum.)
- How do we get this sequence of balances? If your balance in period $(n − 1)$ is $(1 + i )^{(n−1)}P$, then you will be charged $iB_{(n−1)} = i(1 + i )^{(n−1)}P$ in interest. This will be added to your balance. Thus your new balance in period n will be

$$B_{(n−1)} + iB_{(n−1)} = (1 + i )B+{(n−1)} = (1 + i )(1 + i )^{(n−1)}P = (1 + i )^n P$$

Another way to think about the future amount that must be paid in period $n$ (that is, the balance in period $n$) is as follows.

$$ S_n = S_{n−1} + iS_{n−1} = (1 + i ) S+{n−1} $$

This means that

$$
\begin{align*}
S_n &= (1 + i ) S+{n−1} \\
&= (1 + i ) (1 + i ) S_{n−2} \\
&= (1 + i )^2 S_{n−2} \\
&= · · · \\
&= (1 + i )^n S_{n−n} \\
&= (1 + i )^n S_0
\end{align*}
$$

Since $S_0 = P$, we have $S_n = (1 + i)^n P$.

Thus the total interest payments are equal to

$$ I_C = S_n − P = (1 + i )^n P − P = \{(1 + i )^n − 1\} P$$


### Extensions
In introductory courses on finance, financial economics, and financial mathematics, you would encounter numerous extensions of these ideas. Some of these include the following.
- What happens when the compounding periods and the payment / charging periods don’t coincide?
- Amortisation
- Present value and future value
- Cost-benefit analysis and project evaluation
- Net present value
- Internal rate of return
- Annuities, annuities due, perpetuities, and perpetuities due

We will briefly discuss present and future values, and some terminology to do with annuities below. The other topics will be left to other courses.


### Present and future values

We will often be interested in calculating the present value or future value of a payment stream. Suppose that we have a sequence of $(n + 1)$ payments given by $\{ P_0, P_1, P_2, · · · , P_n \}$.

Suppose also that the expected per-period interest rate is believed to be constant over the entire length of time that is covered by this payment sequence. This interest rate is given by $r \in (0, 1)$. (Note that $r \in (0, 1)$ simply means that $0 < r < 1$.)

If you invest \$1 in period $t$, you will expect to recieve \$$1(1 + r)$ in period $(t + 1)$. Applying this logic and the principle of compounding, we can obtain the future value of this payment stream. We will assume that the compounding period is the same as the payment period.

The future value of this payment stream is

$$
S_n = \sum_{t=0}^n P_t (1 + r )^{n−t} \\
= P_0 (1 + r )^{n−0} + P_1 (1 + r )^{n−1} + P_2 (1 + r )^{n−2} + · · · + P_n (1 + r )^{n−n} \\
= P_0 (1 + r )^{n} + P_1 (1 + r )^{n−1} + P_2 (1 + r )^{n−2} + · · · + P_n (1 + r )^{0} \\
= P_0 (1 + r )^{n} + P_1 (1 + r )^{n−1} + P_2 (1 + r )^{n−2} + · · · + P_n (1) \\
= P_0 (1 + r )^{n} + P_1 (1 + r )^{n−1} + P_2 (1 + r )^{n−2} + · · · + P_n
$$

The present value of the payment stream is simply the amount that you would need to invest now to receive this future value in the presence of compounding without making any further deposits. As before, we will assume that the compounding period is the same as the payment period. The present value of this payment stream is given by:

$$
\begin{align*}
S_0 &= \frac{S_n}{(1 + r )^n} \\
&= \left( \frac{1}{(1 + r )^n} \right) \left( \sum_{t=0}^n P_t (1 + r )^{n−t} \right) \\
&= \sum_{t=0}^n P_t \frac{(1 + r )^{n−t}}{(1 + r )^n} \\
&= \sum_{t=0}^n \frac{P_t}{(1 + r)^t}
\end{align*}
$$

Note that the present value of this payment stream can be written as

$$
S_0 = \sum_{t=0}^n \frac{P_t}{(1 + r )^t} \\
= \frac{P_0}{(1 + r )^0} + \frac{P_1}{(1 + r )^1} + \frac{P_2}{(1 + r)^2} + · · · + \frac{P_n}{(1 + r )^n} \\
= \frac{P_0}{1} + \frac{P_1}{(1 + r )^1} + \frac{P_2}{(1 + r)^2} + · · · + \frac{P_n}{(1 + r )^n} \\
= P_0 + \frac{P_1}{(1 + r )^1} + \frac{P_2}{(1 + r)^2} + · · · + \frac{P_n}{(1 + r )^n} 
$$


### Identical payments

Suppose that you receive a constant stream of $(n + 1)$ payments (or, rather, a stream of constant payments) of the form $\{ P_0, P_1, P_2, · · · , P_n \} = \{ A, A, A, · · · , A \}$.

These types of payment streams, along with some variations, are known as “annuities”.

In future value terms, this stream of payments is

$$ \{ P^n_0 , P^n_1 , P^n_2 , · · · , P^n_n \} \\
= \{  A (1 + r )^n , A (1 + r )^{n−1} , A (1 + r )^{n−2} , · · · , A \}$$

Note that this is a geometric progression in which $a = A$, "r" $= q = (1 + r )$, and there are $(n + 1)$ terms.

In present value terms, this stream of payments is

$$
\{ P^0_0, P^0_1 , P^0_2, · · · , P^0_n \} \\
= \left\{ A, \frac{A}{(1 + r )} , \frac{A}{(1 + r )^2} , · · · , \frac{A}{(1 + r)^n}  \right\} \\
= \{ A, A (1 + r)^{−1} , A (1 + r)^{−2} , · · · , A (1 + r )^{−n} \}
$$

Note that this is a geometric progression in which $a = A$, "r"$ = q = \frac{1}{(1+r )} = (1 + r )^{−1}$, and there are $(n + 1)$ terms.

The future value of this stream of payments is

$$
\begin{align*}
S_n &= \sum_{t=0}^n P_t (1 + r)^{n−t} \\
&= \sum_{t=0}^n A (1 + r )^{n−t} \\
&= \frac{A ( 1 − (1 + r )^{n+1})}{1 − (1 + r )} \\
&= \frac{A ( 1 − (1 + r )^{n+1})}{1 − 1 - r } \\
&= \frac{A ( 1 − (1 + r )^{n+1})}{- r } \\
&= \frac{A ( (1 + r )^{n+1} + 1)}{ r } \\
\end{align*}
$$

The present value of this stream of payments is

$$
\begin{align*}
S_0 &= \sum_{t=0}^n \frac{P_t}{(1 + r )^t} \\
&= \sum_{t=0}^n \frac{A}{(1 + r )^t} \\
&= \frac{A( 1 − ((1 + r )^{−1})^{n+1})}{1 − (1 + r )^{−1}} \\
&= \frac{A(1 − (1 + r )^{−(n+1)})}{( \frac{1+r}{1+r}) − ( \frac{1}{1+r})} \\
&= \frac{A(1 − (1 + r )^{−(n+1)})}{( \frac{1+r −1}{1+r})} \\
&= \frac{A(1 − (1 + r )^{−(n+1)})}{( \frac{r}{1+r})} \\
&= \frac{A(1 + r)(1 − (1 + r )^{−(n+1)})}{( r)}
\end{align*}
$$

Note that

$$
\begin{align*}
\frac{S_n}{(1 + r )^n} &=
\left( \frac{1}{(1 + r )^n} \right) \bigg( \frac{A((1 + r )^{n+1} − 1)}{r} \bigg) \\
&= \frac{A((1 + r )^{n+1} − 1)}{r (1 + r )^n} \\
&= \frac{A((1 + r )^{n+1} − 1)(1 + r )^{−n}}{r} \\
&= \frac{A((1 + r )^{n+1−n} − (1 + r ){−n})}{r} \\
&= \frac{A((1 + r ) − (1 + r )^{−n})}{r} \\
&= \frac{A (1 + r )( 1 − (1 + r )^{−(n+1)})}{r} \\
&= S_0
\end{align*}
$$

### Types of Annuities
There are many types of annuities. Using the terminology that is employed by {cite:ps}`shannon1995`, these include the following:
- Ordinary annuity: Payment periods and compounding periods coincide, payments begin in the next period (or, equivalently, at the “end” of this period).
- Ordinary annuity due: Payment periods and compounding periods coincide, payments begin in the current period (or, equivalently, at the “beginning” of this period).
- General annuities: Payment periods and compounding periods differ. (These may occur in both annuity and annuity due form.)
- Perpetuities: An annuity in which there are an infinite number of payment periods. (These may occur in both annuity and annuity due form. They may also occur in both ordinary and general form.)

