
# Taylor series approximations of functions

In situations where functions are rather complicated (especially when they are non-linear and non-separable in the components that make use of the independent variable), it is sometimes convenient to approximate the function, or the change in the value generated by the function, rather than calculate it directly. Obviously, we need to worry about the accuracy of the approximation when we do this.

Derivatives can be used to form some such approximations. In particular, they can be used to form the following approximations:
- Polynomial (Power Series) approximations of a function.
    - We will look at an example of this known as a Taylor series approximation of a function $f(x)$ around the point $x=x_{0}$.
    - The special case of a Taylor series approximation of the function $f(x)$ that takes place around the point $x=0$ is known as a McLauren series approximation of that function.
- We will also look at differential approximations to the change in the value taken by a function when there is a change in the value taken by the independent variable.



Consider the function $f:(a, b) \longrightarrow \mathbb{R}$, where $-\infty<a<b<\infty$. Denote this function by $f(x)$.

Suppose that $f(x)$ is at least $n$-times differentiable with respect to $x$ on the interval $(a, b)$, and let $x_{0} \in(a, b)$.  The **$n$-th order Taylor series approximation** of $f(x)$ around the point $x=x_{0}$ is defined to be: 

$$
\begin{gathered}
f(x) \approx \sum_{k=0}^{n}\left(\frac{1}{k !}\right) f^{(k)}\left(x_{0}\right)\left(x-x_{0}\right)^{k} \\
\approx\left(\frac{1}{0 !}\right) f^{(0)}\left(x_{0}\right)\left(x-x_{0}\right)^{0}+\left(\frac{1}{1 !}\right) f^{(1)}\left(x_{0}\right)\left(x-x_{0}\right)^{1} \\
+\left(\frac{1}{2 !}\right) f^{(2)}\left(x_{0}\right)\left(x-x_{0}\right)^{2}+\cdots+\left(\frac{1}{n !}\right) f^{(n)}\left(x_{0}\right)\left(x-x_{0}\right)^{n} \\
\approx\left(\frac{1}{1}\right) f\left(x_{0}\right)+\left(\frac{1}{1}\right) f^{\prime}\left(x_{0}\right)\left(x-x_{0}\right)+\left(\frac{1}{2}\right) f^{\prime \prime}\left(x_{0}\right)\left(x-x_{0}\right)^{2} \\
+\cdots+\left(\frac{1}{n !}\right) f^{(n)}\left(x_{0}\right)\left(x-x_{0}\right)^{n} \\
\approx f\left(x_{0}\right)+f^{\prime}\left(x_{0}\right)\left(x-x_{0}\right)+\left(\frac{1}{2}\right) f^{\prime \prime}\left(x_{0}\right)\left(x-x_{0}\right)^{2} \\
+\cdots+\left(\frac{1}{n !}\right) f^{(n)}\left(x_{0}\right)\left(x-x_{0}\right)^{n} 
\end{gathered}
$$

- A **linear (or first-order) Taylor series approximation** of a function would take the form

$$
f(x) \approx f\left(x_{0}\right)+f^{\prime}\left(x_{0}\right)\left(x-x_{0}\right) 
$$

- A **quadratic (or second-order) Taylor series approximation** of a function would take the form

$$
f(x) \approx f\left(x_{0}\right)+f^{\prime}\left(x_{0}\right)\left(x-x_{0}\right)+\left(\frac{1}{2}\right) f^{\prime \prime}\left(x_{0}\right)\left(x-x_{0}\right)^{2}
$$

- If the function was differentiable an infinite number of times, then we could imagine forming the **$\infty$-order Taylor series approximation** of it around the point $x=x_{0}$. This would take the form

$$
f(x) \approx \sum_{k=0}^{\infty}\left(\frac{1}{k !}\right) f^{(k)}\left(x_{0}\right)\left(x-x_{0}\right)^{k}
$$


```{figure} _static/img/lecture_06/taylor_4.png
:width: 60%

4th order Taylor series for $f(x) = \sin(x)/x$ at 0
```

```{figure} _static/img/lecture_06/taylor_6.png
:width: 60%

6th order Taylor series for $f(x) = \sin(x)/x$ at 0
```

```{figure} _static/img/lecture_06/taylor_8.png
:width: 60%

8th order Taylor series for $f(x) = \sin(x)/x$ at 0
```

```{figure} _static/img/lecture_06/taylor_10.png
:width: 60%

10th order Taylor series for $f(x) = \sin(x)/x$ at 0
```


It is important to remember that Taylor series approximations of functions are just that: An approximation of the function.

The accuracy of the approximation will depend on a number of factors. These include the form of the underlying function, the closeness of the independent variable $(x)$ to the value around which the Taylor series approximation is centred $\left(x_{0}\right)$, and the order of the approximation.

In many cases, the Taylor series approximation of a function $f(x)$ that is centred on the point $x=x_{0}$ will be a reasonably accurate approximation of the function in a sufficiently small neighbourhood of the point $x=x_{0}$.

Nonetheless, it is important to recognise that we will usually have

$$
f(x) \approx\left(\sum_{k=0}^{n}\left(\frac{1}{k !}\right) f^{(k)}\left(x_{0}\right)\left(x-x_{0}\right)^{k}\right)+R_{n+1}(x)
$$

where $R_{n+1}(x)$ is a "remainder" term.


- The $n$ th-order Taylor series approximation of the function $f(x)$ around the point $x=x_{0}$ is given by

$$
f(x) \approx \sum_{k=0}^{n}\left(\frac{1}{k !}\right) f^{(k)}\left(x_{0}\right)\left(x-x_{0}\right)^{k}
$$


If the function being approximated is at least $(n+1)$-times differentiable on an interval that includes both the point $x=x_{0}$ and the point $x$, then Lagrange has shown that the remainder term that reconciles the above Taylor series approximation of $f(x)$ with the value taken by the function itself is exactly given by the expression

$$
R_{n+1}(x)=\left(\frac{1}{(n+1) !}\right) f^{(n+1)}(z)\left(x-x_{0}\right)^{n+1}
$$

for some $z$ between $x$ and $x_{0}$. (If $x<x_{0}$, then $z \in\left(x, x_{0}\right)$. If $x>x_{0}$, then $z \in\left(x_{0}, x\right)$.)


## Differential approximation to a change in a function's value

Consider a function $y=f(x)$ that is at least once differentiable on some non-empty interval $(a, b)$.  Suppose that the value of the independent variable changes from some initial value $x \in(a, b)$ to some final value $x+\Delta x \in(a, b)$.

The exact impact of this change on the value taken by the function is $\Delta y=f(x+\Delta x)-f(x)$.

We might think about calculating an approximation of this change by using a linear (first-order) Taylor series of the function $f(x+\Delta x)$ around the point $x$. This approximation takes the form

$$
f(x+\Delta x) \approx f(x)+f^{\prime}(x)((x+\Delta x)-x)=f(x)+f^{\prime}(x) \Delta x
$$

If we employ this approximation, then we obtain

$$
\Delta y \approx f(x)+f^{\prime}(x) \Delta x-f(x)=f^{\prime}(x) \Delta x
$$

Recall that in many cases, if $x+\Delta x$ is sufficiently close to $x$, then the linear Taylor series approximation for $f(x+\Delta x)$ around the point $x$ will be reasonably accurate. If this is the case, then the linear (or first-order) approximation to the change in the value of the function $f(x)$ when the independent variable moves from $x$ to $x+\Delta x$ that we derived above will also be reasonably accurate when $x+\Delta x$ is sufficiently close to $x$.

In other words, it will be reasonably accurate when $\Delta x$ is sufficiently small in absolute value terms (that is, close to zero). In such cases, we typically use $d x$ to denote $\Delta x$, and $d y$ to denote $\Delta y$. This means that if $f(x)$ is at least once differentiable and $d x$ bis sufficiently small, then

$$
d y \approx f^{\prime}(x) d x
$$

This expression is known as the linear (or first-order) **differential** of the function $f(x)$.


## An application of linear differential approximation

The change in the natural logarithm of a variable is approximately equal to the corresponding proprtionate change in that variable. As such, we can interpret the change in the natural logarithm of the price level in an economy as a good indicator of inflation in that economy (as long as the change in the price level is not too large). This can be seen by noting that if $p=\ln (P)$, where $P$ is the price level in an economy, then

$$
d p \approx\left(\frac{d \ln (P)}{d P}\right) d P \Longleftrightarrow d p \approx\left(\frac{1}{P}\right) d P \Longleftrightarrow d p \approx \frac{d P}{P}
$$


Ted Sieper places the natural log of the price level on the horizontal axis of a diagrammatic representation of a version of the "IS-LM" macroeconomic model, thereby enabling him to use the above result to interpret horizontal distances in that diagram as a measure of inflation (or expected inflation).  This is a very interesting and insightful paper that is well worth a read at some stage during your study of economics.

See Sieper, E (1987), "Policy irrelevance is not the rule", Unpublished working paper, ANU, Canberra, November. Available online at: https://files.brontecapital.com/ted_sieper_paper.pdf.

