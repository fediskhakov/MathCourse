# Quadratic forms

<small>‚è± <span class="eta"></span> | <span class="words"></span> words</small>

````{dropdown} Sources and reading guide

```{figure} _static/img/bibliography/shsc2016.png
:width: 100px
:align: left
```
{cite:ps}`sydsaeter2006`

Chapter 15 (pp. 549-590). ???

<div style="clear: both"></div>

- {cite:ps}`anton1987`: Chapter 6 and Chapter 7 (Section 3).
- {cite:ps}`chiang1984`: Chapter 11 (Section 3).
- {cite:ps}`debreu1952`
- {cite:ps}`hicks1939`: Mathematical Appendix (pp. 303-328).
- {cite:ps}`hicks1946`: Mathematical Appendix (pp. 303-328).
- {cite:ps}`mandy2013`
- {cite:ps}`mandy2018`
- {cite:ps}`mann1943`
- {cite:ps}`samuelson1947`: Mathematical Appendix A (pp. 357-379).
- {cite:ps}`silberberg2001`: Chapter 6.
- {cite:ps}`simon1994`: Chapter 13 (Section 3), Chapter 16, Chapter 17, Chapter 19, Chapter 21, and Chapter 23.
- {cite:ps}`sundaram1996`: Chapter 1 (Section 5).
- {cite:ps}`takayama1993`: Chapter 1 (Section 4).

````



## What is a quadratic form?

Suppose that

$$
A=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}
\end{array}\right)
$$

is an $(n \times n)$ square matrix whose elements are all fixed parameters (constants) and

$$
x=\left(\begin{array}{c}
x_{1} \\
x_{2} \\
\vdots \\
x_{n}
\end{array}\right)
$$

is an $(n \times 1)$ column vector whose elements are all variables.

Consider the function $f(x)=x^{T} A x$.

Note that

$$
\begin{aligned}
x^{T} A x & =\left(\begin{array}{llll}
x_{1} & x_{2} & \cdots & x_{n}
\end{array}\right)\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{21} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n 1} & a_{n 2} & \cdots & a_{n n}
\end{array}\right)\left(\begin{array}{c}
x_{1} \\
x_{2} \\
\vdots \\
x_{n}
\end{array}\right) \\[10pt]
& =\left(\begin{array}{llll}
x_{1} & x_{2} & \cdots & x_{n}
\end{array}\right)\left(\begin{array}{c}
\sum_{i=1}^{n} a_{1 i} x_{i} \\
\vdots \\
\sum_{i=1}^{n} a_{n i}^{n} x_{i} x_{i}
\end{array}\right) \\[10pt]
& =\sum_{j=1}^{n}\left(x_{j}\left(\sum_{i=1}^{n} a_{j i} x_{i}\right)\right) \\
& =\sum_{j=1}^{n}\left(\sum_{i=1}^{n} a_{j i} x_{i} x_{j}\right) \\
& =\sum_{j=1}^{n} \sum_{i=1}^{n} a_{j i} x_{i} x_{j} \\
& =\left(\sum_{j=1}^{n} a_{j j} x_{j}^{2}\right)+\left(\sum_{j \neq i} \sum_{i=1}^{n} a_{j i} x_{i} x_{j}\right) 
\end{aligned}
$$

Clearly $f(x)=x^{T} A x$ is a quadratic function of the variables in the $x$ vector. It is for this reason that $x^{T} A x$ is known as a **quadratic form**.


## Symmetric and non-symmetric matrices

Suppose that a square matrix $A$ is not symmetric, so that $a_{i j} \neq a_{j i}$ for at least one $(i, j)$ pair for which $i \neq j$. We have already shown that

$$
x^{T} A x=\left(\sum_{j=1}^{n} a_{j j} x_{j}^{2}\right)+\left(\sum_{j \neq i} \sum_{i=1}^{n} a_{j i} x_{i} x_{j}\right)
$$

Note that the second component of the right hand side of this expression includes only terms for which either $j<i$ or $j>i$. If we collect like terms, we can rewrite this component as

$$
\sum_{j \neq i} \sum_{i=1}^{n} a_{j i} x_{i} x_{j}=\sum_{j<i} \sum_{i=1}^{n}\left(a_{j i}+a_{i j}\right) x_{i} x_{j}
$$

Suppose that we let $b_{i i}=a_{i i}$ and $b_{i j}=\frac{\left(a_{j i}+a_{i j}\right)}{2}=b_{j i}$.  This yields

$$
\begin{aligned}
x^{T} A x & =\left(\sum_{j=1}^{n} a_{j j} x_{j}^{2}\right)+\left(\sum_{j \neq i} \sum_{i=1}^{n} a_{j i} x_{i} x_{j}\right) \\
& =\left(\sum_{j=1}^{n} a_{j j} x_{j}^{2}\right)+\left(\sum_{j<i} \sum_{i=1}^{n}\left(a_{j i}+a_{i j}\right) x_{i} x_{j}\right) \\
& =\left(\sum_{j=1}^{n} b_{j j} x_{j}^{2}\right)+\left(\sum_{j<i} \sum_{i=1}^{n}\left(\frac{\left(a_{j i}+a_{i j}\right)}{2}+\frac{\left(a_{j i}+a_{i j}\right)}{2}\right) x_{i} x_{j}\right) \\
& =\left(\sum_{j=1}^{n} b_{j j} x_{j}^{2}\right)+\left(\sum_{j<i} \sum_{i=1}^{n}\left(b_{j i}+b_{j i}\right) x_{i} x_{j}\right)\\
& =\left(\sum_{j=1}^{n} b_{j j} x_{j}^{2}\right)+\left(\sum_{j \neq i} \sum_{i=1}^{n} b_{j i} x_{i} x_{j}\right) \\
& =x^{T} B x
\end{aligned}
$$

where

$$
B=\left(\begin{array}{cccc}
b_{11} & b_{12} & \cdots & b_{1 n} \\
b_{12} & b_{22} & \cdots & b_{2 n} \\
\vdots & \vdots & \ddots & \vdots \\
b_{1 n} & b_{2 n} & \cdots & b_{n n}
\end{array}\right)
$$

is a symmetric matrix.

Thus any quadratic form $x^{T} A x$ in which the matrix $A$ is not symmetric can also be expressed as a quadratic form $x^{T} B x$ in which the matrix $B$ is symmetric.


## The definiteness of a matrix

The "definiteness" of a square matrix $A$ is related to the sign of the quadratic form $x^{T} A x$ when the $x$ vector is not a null vector.

(Trivially, when $x$ is a null vector (that is, a vector of zeros), the quadratic form $x^{T} A x$ must be equal to zero.)

- The matrix $A$ is said to be **positive definite** if $x^{T} A x>0$ for all $x \neq 0$.
- The matrix $A$ is said to be **positive semi-definite** if $x^{T} A x \geqslant 0$ for all $x \neq 0$.
- The matrix $A$ is said to be **negative semi-definite** if $x^{T} A x \leqslant 0$ for all $x \neq 0$.
- The matrix $A$ is said to be **negative definite** if $x^{T} A x<0$ for all $x \neq 0$.
- The matrix $A$ is said to be **indefinite** if $x^{T} A x>0$ for at least one $x \neq 0$ and $x^{T} A x<0$ for at least one $x \neq 0$.


Sometimes the definition of the various types of matrix definiteness can be used to establish the definiteness of a particular square matrix. But often this is not a particularly convenient method for doing this.

When a square matrix is symmetric, there are two indirect approaches to determining its definiteness that are often much more convenient than attempting to directly employ the definition itself.
- One of these indirect methods involves an examination of the "eigenvalues" of the matrix.
- The other of these indirect methods involves an examination of the "leading principal minors" of the matrix.

But what if a square matrix is not symmetric?
- We can always use the technique discussed above to construct a symmetric square matrix that will have an identical definiteness to the original non-symmetric square matrix.



## Eigenvalues and definiteness

Suppose that, in addition to being a square matrix, the matrix $A$ is a symmetric matrix, so that $A^{T}=A$.
- The matrix $A$ will be positive definite if and only if all of its eigenvalues are strictly positive $(>0)$.
- The matrix $A$ will be positive semi-definite if and only if all of its eigenvalues are non-negative $(\geqslant 0)$.
- The matrix $A$ will be negative semi-definite if and only if all of its eigenvalues are non-positive $(\leqslant 0)$.
- The matrix $A$ will be negative definite if and only if all of its eigenvalues are strictly negative $(<0)$.
- The matrix $A$ will be indefinite if and only if it has both at least one strictly positive eigenvalue and at least one strictly negative eigenvalue.

But what are the eigenvalues of a matrix and how do we find them?


The **characteristic matrix** associated with a square matrix $A$ is defined to be the square matrix $(\lambda I-A)$, where $\lambda$ is a scalar variable and $I$ is the identity matrix that has the same dimensions as $A$.
- Sometimes the characteristic matrix is defined to be $(A-\lambda I)$.
- The **characteristic polynomial** associated with the matrix $A$ is defined to be $\operatorname{det}(\lambda I-A)$.
    - Sometimes the characteristic polynomial associated with the matrix $A$ is defined to be $\operatorname{det}(A-\lambda I)$.
    - If $A$ is an $(n \times n)$ matrix for some $n \in \mathbb{N}$, then the characteristic polynomial will be an $n$th degree polynomial function of the scalar variable $\lambda$.
- The **characteristic equation** associated with the matrix $A$ is defined to be $\operatorname{det}(\lambda I-A)=0$.
    - Sometimes the characteristic equation associated with the matrix $A$ is defined to be $\operatorname{det}(A-\lambda I)=0$.



- The **eigenvalues** $(\lambda)$ of a square matrix $(A)$ are the solutions to the characteristic equation.
    - Both versions of the characteristic equation will yield the same set of solution values for $\lambda$.
- If $A$ is a symmetric matrix, then all of its eigenvalues will be real numbers.
    - This is Part (a) of Theorem 23.16 in {cite:ps}`simon1994` (p. 621).



## Principal minors and definiteness

Once again, suppose that $A$ is a symmetric square matrix. Symmetry requires that $a_{i j}=a_{j i}$ for all $i \neq j$. In other words, if $A$ is an an $(n \times n)$ square matrix, then it takes the form

$$
A=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{12} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{1 n} & a_{2 n} & \cdots & a_{n n}
\end{array}\right)
$$

The **leading principal sub-matrices** for $A$ are given by

$$
\begin{gathered}
A_{1}=\left(a_{11}\right) \\[10pt]
A_{2}=\left(\begin{array}{ll}
a_{11} & a_{12} \\
a_{12} & a_{22}
\end{array}\right)\\
A_{3}=\left(\begin{array}{lll}
a_{11} & a_{12} & a_{13} \\
a_{12} & a_{22} & a_{23} \\
a_{13} & a_{23} & a_{33}
\end{array}\right)
\end{gathered}
$$

and so on and so forth up until

$$
A_{n}=A=\left(\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1 n} \\
a_{12} & a_{22} & \cdots & a_{2 n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{1 n} & a_{2 n} & \cdots & a_{n n}
\end{array}\right)
$$

The **leading principal minors** for $A$ are given by $\operatorname{det}\left(A_{1}\right)$, $\operatorname{det}\left(A_{2}\right)$, $\operatorname{det}\left(A_{3}\right)$, and so on and so forth up until $\operatorname{det}\left(A_{n}\right)=\operatorname{det}(A)$.



- The matrix $A$ will be **positive definite** if and only if $\operatorname{det}\left(A_{i}\right)>0$ for all $i \in\{1,2, \cdots, n\}$.
- The matrix $A$ will be **negative definite** if and only if both $\operatorname{det}\left(A_{i}\right)<0$ for all odd $i$ and $\operatorname{det}\left(A_{i}\right)>0$ for all even $i$.
- Using the leading principal minors of a matrix to determine whether or not it is either positive semi-definite or negative semi-definite is slightly more complicated.
    - Unfortunately, we cannot just directly modify the strict inequalities in the positive definite and negative definite tests to incorporate weak inequalities.
    - Instead, we need the pattern implied by doing just that to hold for all possible permutations of the entries in the matrix.
    - This makes this approach to determining positive semi-definiteness or negative semi-definiteness somewhat cumbersome.
    - Further details can be found in {cite:ps}`sundaram1996` (pp. 50-55) and {cite:ps}`mandy2018` (pp. 1396-1398).
- In any other circumstance, the matrix $A$ is indefinite.


### Examples


```{admonition} Example
:class: tip


Consider the matrix

$$
H=\left(\begin{array}{ccc}
\frac{\alpha}{x} & 0 & 0 \\
0 & \frac{\beta}{y} & 0 \\
0 & 0 & \frac{\gamma}{z}
\end{array}\right)
$$

where $x>0, y>0, z>0, \alpha>0, \beta>0, \gamma>0$ and $(\alpha+\beta+\gamma)=1$. Note that $H$ is a symmetric matrix.

First, let us see if we can determine the definiteness of the matrix $H$ by using the leading principal minors approach. Note that the first leading principal minor of $H$ is

$$
\operatorname{det}\left(H_{1}\right)=\operatorname{det}\left(\left(\frac{\alpha}{x}\right)\right)=\frac{\alpha}{x}>0
$$

because $x>0$ and $\alpha>0$.

Note that the second leading principal minor of $H$ is

$$
\begin{aligned}
\operatorname{det}\left(H_{2}\right) & =\operatorname{det}\left(\left(\begin{array}{cc}
\frac{\alpha}{x} & 0 \\
0 & \frac{\beta}{y}
\end{array}\right)\right) \\
& =\left(\frac{\alpha}{x}\right)\left(\frac{\beta}{y}\right)-(0)(0) \\
& =\frac{\alpha \beta}{x y}-0 \\
& =\frac{\alpha \beta}{x y} \\
& >0 \quad \text { (because } x>0, y>0, \alpha>0 \text { and } \beta>0) .
\end{aligned}
$$

Note that the third (and final) leading principal minor of $H$ is simply the determinant of the matrix $H$ itself. Upon employing a cofactor expansion along the first row of matrix $H$, we obtain

$$
\begin{aligned}
\operatorname{det}\left(H_{3}\right) & =\operatorname{det}(H) \\
& =\left(\frac{\alpha}{x}\right)(-1)^{1+1} \operatorname{det}\left(\left(\begin{array}{cc}
\frac{\beta}{y} & 0 \\
0 & \frac{\gamma}{z}
\end{array}\right)\right)+0+0 \\
& =\left(\frac{\alpha}{x}\right)(-1)^{2}\left[\left(\frac{\beta}{y}\right)\left(\frac{\gamma}{z}\right)-(0)(0)\right] \\
& =\left(\frac{\alpha}{x}\right)(1)\left[\frac{\beta \gamma}{y z}-0\right] \\
& =\left(\frac{\alpha}{x}\right)\left(\frac{\beta \gamma}{y z}\right) \\
& =\frac{\alpha \beta \gamma}{x y z} \\
& >0
\end{aligned}
$$

because $x>0, y>0, z>0, \alpha>0, \beta>0$, and $\gamma>0$.

Since $\operatorname{det}\left(H_{1}\right)>0$, $\operatorname{det}\left(H_{2}\right)>0$ and $\operatorname{det}\left(H_{3}\right)>0$, we can conclude that the matrix $H$ is positive definite.

Now let us now establish that $H$ is positive definite by using the eigenvalue approach. The characteristic matrix associated with $H$ is

$$
\begin{aligned}
\lambda I-H & =\lambda\left(\begin{array}{ccc}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{array}\right)-\left(\begin{array}{ccc}
\frac{\alpha}{x} & 0 & 0 \\
0 & \frac{\beta}{y} & 0 \\
0 & 0 & \frac{\gamma}{z}
\end{array}\right) \\
& =\left(\begin{array}{ccc}
\lambda & 0 & 0 \\
0 & \lambda & 0 \\
0 & 0 & \lambda
\end{array}\right)-\left(\begin{array}{ccc}
\frac{\alpha}{x} & 0 & 0 \\
0 & \frac{\beta}{y} & 0 \\
0 & 0 & \frac{\gamma}{z}
\end{array}\right) \\
& =\left(\begin{array}{ccc}
\lambda-\frac{\alpha}{x} & 0 & 0 \\
0 & \lambda-\frac{\beta}{y} & 0 \\
0 & 0 & \lambda-\frac{\gamma}{z}
\end{array}\right)
\end{aligned}
$$


It is straight-forward to establish that the characteristic polynomial for $H$ is

$$
\operatorname{det}(\lambda I-H)=\left(\lambda-\frac{\alpha}{x}\right)\left(\lambda-\frac{\beta}{y}\right)\left(\lambda-\frac{\gamma}{z}\right)
$$

You should establish the validity of this claim as a form of revision of the calculation of determinants. Thus the characteristic equation associated with $H$ is

$$
\operatorname{det}(\lambda I-H)=\left(\lambda-\frac{\alpha}{x}\right)\left(\lambda-\frac{\beta}{y}\right)\left(\lambda-\frac{\gamma}{z}\right)=0
$$

Clearly the eigenvalues for $H$ are $\lambda_{1}=\frac{\alpha}{x}, \lambda_{2}=\frac{\beta}{y}$, and $\lambda_{3}=\frac{\gamma}{z}$.

Since $x>0, y>0, z>0, \alpha>0, \beta>0$, and $\gamma>0$, we know that $\lambda_{1}>0, \lambda_{2}>0$, and $\lambda_{3}>0$.

Thus we can conclude that $H$ is a positive definite matrix.
```

```{admonition} Example
:class: tip


Consider the matrix

$$
A=\left(\begin{array}{ll}
2 & 3 \\
3 & 7
\end{array}\right)
$$

Note that $A$ is a symmetric matrix.
The leading principal sub-matrices for this matrix are $A_{1}=(2)$ and $A_{2}=A$. As such, the leading principal minors for this matrix are

$$
\operatorname{det}\left(A_{1}\right)=2>0
$$

and

$$
\operatorname{det}\left(A_{2}\right)=\operatorname{det}(A)=(2)(7)-(3)(3)=14-9=5>0
$$

Thus we can conclude that $A$ is a positive definite matrix.

```



```{admonition} Example
:class: tip


Consider the matrix

$$
A=\left(\begin{array}{ll}
2 & 4 \\
4 & 7
\end{array}\right)
$$

Note that $A$ is a symmetric matrix. The leading principal sub-matrices for this matrix are $A_{1}=(2)$ and $A_{2}=A$. As such, the leading principal minors for this matrix are

$$
\operatorname{det}\left(A_{1}\right)=2>0
$$

and

$$
\operatorname{det}\left(A_{2}\right)=\operatorname{det}(A)=(2)(7)-(4)(4)=14-16=-2<0
$$

Since $\operatorname{det}\left(A_{1}\right)>0$ and $\operatorname{det}\left(A_{2}\right)=\operatorname{det}(A)<0$, we know that $A$ is neither negative definite nor positive definite. But is it negative semi-definite, positive semi-definite, or indefinite? Let us find the eigenvalues of $A$.

The characteristic matrix for $A$ is

$$
\begin{aligned}
\lambda I-A & =\lambda\left(\begin{array}{ll}
1 & 0 \\
0 & 1
\end{array}\right)-\left(\begin{array}{ll}
2 & 4 \\
4 & 7
\end{array}\right) \\
& =\left(\begin{array}{ll}
\lambda & 0 \\
0 & \lambda
\end{array}\right)-\left(\begin{array}{ll}
2 & 4 \\
4 & 7
\end{array}\right) \\
& =\left(\begin{array}{cc}
\lambda-2 & -4 \\
-4 & \lambda-7
\end{array}\right)
\end{aligned}
$$


This means that the characteristic polynomial for $A$ is

$$
\begin{aligned}
\operatorname{det}(\lambda I-A) & =(\lambda-2)(\lambda-7)-(-4)(-4) \\
& =\lambda^{2}-7 \lambda-2 \lambda+14-16 \\
& =\quad \lambda^{2}-9 \lambda-2
\end{aligned}
$$

Thus the characteristic equation for $A$ is

$$
\operatorname{det}(\lambda I-A)=\lambda^{2}-9 \lambda-2=0
$$

Note that the characteristic equation for $A$ is a quadratic equation in the variable $\lambda$.


Upon applying the quadratic formula to the characteristic equation for $A$, we find that the eigenvalues for the matrix $A$ are $\lambda_{1}=\frac{9+\sqrt{89}}{2}$ and $\lambda_{2}=\frac{9-\sqrt{89}}{2}$.

Since $9^{2}=81<89<100=10^{2}$, we know that $9<\sqrt{89}<10$.

This means that $\lambda_{1}=\frac{9+\sqrt{89}}{2}>0$ and $\lambda_{2}=\frac{9-\sqrt{89}}{2}<0$.

Thus we can conclude that the $A$ is an indefinite matrix.
```


```{admonition} Example
:class: tip


Consider the matrix

$$
A=\left(\begin{array}{ll}
0 & 0 \\
0 & 7
\end{array}\right)
$$

Note that $x^{T} A x=7 x_{2}^{2} \geqslant 0$ for all $\left(x_{1}, x_{2}\right)^{T} \neq(0,0)^{T}$. Thus this matrix is positive semi-definite.

This follows directly from the definition of positive semi-definiteness of a matrix. It is not positive definite because $x^{T} A x=7 x_{2}^{2}=0$ when $\left(x_{1}, x_{2}\right)^{T}=(1,0)$ and $(1,0) \neq(0,0)$.

```



```{admonition} Example
:class: tip


Consider the matrix

$$
A=\left(\begin{array}{cc}
0 & 0 \\
0 & -7
\end{array}\right)
$$

Note that $x^{T} A x=-7 x_{2}^{2} \leqslant 0$ for all $\left(x_{1}, x_{2}\right)^{T} \neq(0,0)^{T}$.  Thus this matrix is negative semi-definite.

This follows directly from the definition of negative semi-definiteness of a matrix. It is not negative definite because $x^{T} A x=7 x_{2}^{2}=0$ when $\left(x_{1}, x_{2}\right)^{T}=(1,0)$ and $(1,0) \neq(0,0)$.)

```


```{admonition} Example
:class: tip


Consider the matrix

$$
A=\left(\begin{array}{cc}
2 & 2 \\
2 & -1
\end{array}\right)
$$

Note that $A$ is a symmetric matrix. The leading principal sub-matrices for this matrix are $A_{1}=(2)$ and $A_{2}=A$. As such, the leading principal minors for this matrix are

$$
\operatorname{det}\left(A_{1}\right)=2>0
$$

and

$$
\operatorname{det}\left(A_{2}\right)=\operatorname{det}(A)=(2)(-1)-(2)(2)=-2-4=-6<0
$$

Since $\operatorname{det}\left(A_{1}\right)>0$ and $\operatorname{det}\left(A_{2}\right)=\operatorname{det}(A)<0$, we know that $A$ is neither negative definite nor positive definite. But is it negative semi-definite, positive semi-definite, or indefinite? Let us find the eigenvalues of $A$.

The characteristic matrix for $A$ is

$$
\begin{aligned}
\lambda I-A & =\lambda\left(\begin{array}{ll}
1 & 0 \\
0 & 1
\end{array}\right)-\left(\begin{array}{cc}
2 & 2 \\
2 & -1
\end{array}\right) \\
& =\left(\begin{array}{ll}
\lambda & 0 \\
0 & \lambda
\end{array}\right)-\left(\begin{array}{cc}
2 & 2 \\
2 & -1
\end{array}\right) \\
& =\left(\begin{array}{cc}
\lambda-2 & -2 \\
-2 & \lambda+1
\end{array}\right)
\end{aligned}
$$

This means that the characteristic polynomial for $A$ is

$$
\begin{array}{rlr}
\operatorname{det}(\lambda I-A) & = & (\lambda-2)(\lambda+1)-(-2)(-2) \\
& = & \lambda^{2}+\lambda-2 \lambda-2-4 \\
& = & \lambda^{2}-\lambda-6 \\
& = & (\lambda+2)(\lambda-3) .
\end{array}
$$

Thus the characteristic equation for $A$ is

$$
\operatorname{det}(\lambda I-A)=(\lambda+2)(\lambda-3)=0 \text {. }
$$

This means that the eigenvalues for the matrix $A$ are $\lambda_{1}=-2$ and $\lambda_{2}=3$. Since $\lambda_{1}<0$ and $\lambda_{2}>0$, we can conclude that $A$ is an indefinite matrix.
```


````{admonition} Example
:class: tip


Consider the matrix

$$
A=\left(\begin{array}{lll}
1 & 2 & 0 \\
2 & 4 & 5 \\
0 & 5 & 6
\end{array}\right)
$$

Note that $A$ is a symmetric matrix. The leading principal sub-matrices for this matrix are $A_{1}=(1)$,

$$
A_{2}=\left(\begin{array}{ll}
1 & 2 \\
2 & 4
\end{array}\right)
$$

and $A_{3}=A$.

As such, the leading principal minors for this matrix are $\operatorname{det}\left(A_{1}\right)=1$,

$$
\operatorname{det}\left(A_{2}\right)=(1)(4)-(2)(2)=4-4=0
$$

and

$$
\begin{aligned}
\operatorname{det}\left(A_{3}\right)= & \operatorname{det}(A) \\[5pt]
= & (1)(-1)^{1+1} \operatorname{det}\left(\left(\begin{array}{ll}
4 & 5 \\
5 & 6
\end{array}\right)\right) \\[5pt]
& +(2)(-1)^{1+2} \operatorname{det}\left(\left(\begin{array}{ll}
2 & 5 \\
0 & 6
\end{array}\right)\right) \\[5pt]
& +(0)(-1)^{1+3} \operatorname{det}\left(\left(\begin{array}{ll}
2 & 4 \\
0 & 5
\end{array}\right)\right) \\[5pt]
= & (1)(-1)^{2}\{(4)(6)-(5)(5)\} \\
& +(2)(-1)^{3}\{(2)(6)-(5)(0)\}+0 \\[5pt]
= & (1)(-1)^{2}\{(4)(6)-(5)(5)\} \\
& +(2)(-1)^{3}\{(2)(6)-(5)(0)\}+0 \\[5pt]
= & (1)(1)\{24-25\}+(2)(-1)\{12-0\} \\[5pt]
= & (1)(1)(-1)+(2)(-1)(12) \\[5pt]
= & -1+(-24) \\[5pt]
= & -1-24 \\[5pt]
= & -25
\end{aligned}
$$

Since $\operatorname{det}\left(A_{1}\right)>0$, $\operatorname{det}\left(A_{2}\right)=0$, and $\operatorname{det}\left(A_{3}\right)=\operatorname{det}(A)<0$, we know that $A$ is neither negative definite nor positive definite. But is it negative semi-definite, positive semi-definite, or indefinite?  Let us find the eigenvalues of $A$.


The characteristic matrix for $A$ is

$$
\begin{aligned}
\lambda I-A & =\lambda\left(\begin{array}{lll}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{array}\right)-\left(\begin{array}{lll}
1 & 2 & 0 \\
2 & 4 & 5 \\
0 & 5 & 6
\end{array}\right) \\
& =\left(\begin{array}{lll}
\lambda & 0 & 0 \\
0 & \lambda & 0 \\
0 & 0 & \lambda
\end{array}\right)-\left(\begin{array}{lll}
1 & 2 & 0 \\
2 & 4 & 5 \\
0 & 5 & 6
\end{array}\right) \\
& =\left(\begin{array}{ccc}
\lambda-1 & -2 & 0 \\
-2 & \lambda-4 & -5 \\
0 & -5 & \lambda-6
\end{array}\right)
\end{aligned}
$$

The characteristic polynomial for $A$ is

$$
\begin{aligned}
\operatorname{det}(\lambda I-A)= & (\lambda-1)(-1)^{1+1} \operatorname{det}\left(\left(\begin{array}{cc}
\lambda-4 & -5 \\
-5 & \lambda-6
\end{array}\right)\right) \\
& +(-2)(-1)^{1+2} \operatorname{det}\left(\left(\begin{array}{cc}
-2 & -5 \\
0 & \lambda-6
\end{array}\right)\right)+0 \\
= & (\lambda-1)(-1)^{2}[(\lambda-4)(\lambda-4)-25] \\
& +(-2)(-1)^{3}[-2(\lambda-6)-0] \\
= & (\lambda-1)(1)\left[\lambda^{2}-10 \lambda+24-25\right] \\
& -2(-1)[-2 \lambda+12] \\
= & (\lambda-1)\left[\lambda^{2}-10 \lambda-1\right]+2[-2 \lambda+12] \\
= & \lambda^{3}-10 \lambda^{2}-\lambda-\left[\lambda^{2}-10 \lambda-1\right]-4 \lambda+24 \\
= & \lambda^{3}-10 \lambda^{2}-\lambda-\lambda^{2}+10 \lambda+1-4 \lambda+24 \\
= & \lambda^{3}-11 \lambda^{2}+5 \lambda+25
\end{aligned}
$$


The characteristic equation for the matrix $A$ is

$$
\operatorname{det}(\lambda I-A)=\lambda^{3}-11 \lambda^{2}+5 \lambda+25=0
$$

Note that this is a cubic equation in the variable $\lambda$.
While there do not appear to be any "obvious" factorisations of this characteristic polynomial, it is possible to obtain numerical approximations to the eigenvalues of $A$ (that is, the solutions to the characteristic equation) by using Microsoft Excel.
Upon doing this we find that $\lambda_{1} \approx-1.2395, \lambda_{2} \approx 1.9627$, and $\lambda_{3} \approx 10.277$.
A graph of the characteristic polynomial can be found on the next slide.
Since the matrix $A$ has both positive and negative eigenvalues, we can conclude that it is indefinite.


```{figure} _static/img/lecture_07/example7.png
:width: 80%
:align: center

Graph of the characteristic polynomial
```
````


```{admonition} Example
:class: tip


Consider the matrix

$$
A=\left(\begin{array}{ccc}
-1 & 1 & 0 \\
1 & -1 & 0 \\
0 & 0 & -2
\end{array}\right)
$$

Note that $A$ is a symmetric matrix. The characteristic matrix for $A$ is

$$
(\lambda I-A)=\left(\begin{array}{ccc}
\lambda+1 & -1 & 0 \\
-1 & \lambda+1 & 0 \\
0 & 0 & \lambda+2
\end{array}\right)
$$

The characteristic polynomial for $A$ is

$$
\begin{aligned}
\operatorname{det}(\lambda I-A) & =0+0+(\lambda+2)(-1)^{3+3} \operatorname{det}\left(\left(\begin{array}{cc}
\lambda+1 & -1 \\
-1 & \lambda+1
\end{array}\right)\right) \\
& =0+0+(\lambda+2)(-1)^{6}\left[(\lambda+1)^{2}-1\right] \\
& =(\lambda+2)(1)((\lambda+1)+1)((\lambda+1)-1) \\
& =(\lambda+2)(1)(\lambda+2)(\lambda) \\
& =(\lambda+2)^{2} \lambda
\end{aligned}
$$

The characteristic equation for the matrix $A$ is

$$
\operatorname{det}(\lambda I-A)=(\lambda+2)^{2} \lambda=0
$$

Clearly the eigenvalues for the matrix $A$ are $\lambda_{1}=-2, \lambda_{2}=-2$, and $\lambda_{3}=0$.

Since the matrix $A$ has both negative eigenvalues and a zero eigenvalue, we can conclude that it is negative semi-definite.

```



```{admonition} Example
:class: tip


Consider the matrix

$$
A=\left(\begin{array}{cc}
-1 & -2 \\
4 & 3
\end{array}\right)
$$

Note that the matrix $A$ is _not_ symmetric.

Before proceeding, let us construct a symmetric matrix $B$ such that $x^{T} A x=x^{T} B x$ for all $x \in \mathbb{R}^{2}$.

We will do this by setting $b_{11}=a_{11}=-1, b_{22}=a_{22}=3$, and $b_{12}=b_{21}=\left(\frac{1}{2}\right)\left(a_{12}+a_{21}\right)=\frac{(-2+4)}{2}=\frac{2}{2}=1$.

The resulting matrix $B$ is

$$
B=\left(\begin{array}{cc}
-1 & 1 \\
1 & 3
\end{array}\right)
$$

Note that the matrix $B$ is symmetric.


The leading principal sub-matrices for this matrix are $B_{1}=(-1)$ and $B_{2}=B$. As such, the leading principal minors for this matrix are

$$
\operatorname{det}\left(B_{1}\right)=-1<0
$$

and

$$
\operatorname{det}\left(B_{2}\right)=\operatorname{det}(B)=(-1)(3)-(1)(1)=-3-1=-4<0
$$

Since $\operatorname{det}\left(B_{1}\right)<0$ and $\operatorname{det}\left(B_{2}\right)=\operatorname{det}(B)<0$, we know that $B$ (and hence $A$ ) is neither negative definite nor positive definite.  But is it negative semi-definite, positive semi-definite, or indefinite? Let us find the eigenvalues of $B$.

The characteristic matrix for $B$ is

$$
\begin{aligned}
\lambda I-B & =\lambda\left(\begin{array}{ll}
1 & 0 \\
0 & 1
\end{array}\right)-\left(\begin{array}{cc}
-1 & 1 \\
1 & 3
\end{array}\right) \\
& =\left(\begin{array}{ll}
\lambda & 0 \\
0 & \lambda
\end{array}\right)-\left(\begin{array}{cc}
-1 & 1 \\
1 & 3
\end{array}\right) \\
& =\left(\begin{array}{cc}
\lambda+1 & -1 \\
-1 & \lambda-3
\end{array}\right)
\end{aligned}
$$

This means that the characteristic polynomial for $B$ is

$$
\begin{array}{rlr}
\operatorname{det}(\lambda I-B) & = & (\lambda+1)(\lambda-3)-(-1)(-1) \\
& = & \lambda^{2}-3 \lambda+\lambda-3-1 \\
& = & \lambda^{2}-2 \lambda-4
\end{array}
$$


Thus the characteristic equation for $B$ is

$$
\operatorname{det}(\lambda /-B)=\lambda^{2}-2 \lambda-4=0
$$

Note that the characteristic equation for $B$ is a quadratic equation in the variable $\lambda$.

Upon applying the quadratic formula to the characteristic equation for $B$, we find that the eigenvalues for the matrix $B$ are $\lambda_{1}=\frac{2+\sqrt{20}}{2}$ and $\lambda_{2}=\frac{2-\sqrt{20}}{2}$.

Since $4^{2}=16<20<25=5^{2}$, we know that $4<\sqrt{20}<5$.

This means that $\lambda_{1}=\frac{2+\sqrt{20}}{2}>0$ and $\lambda_{2}=\frac{2-\sqrt{20}}{2}<0$.

Thus we can conclude that the $B$ (and hence $A$ ) is an indefinite matrix.
```


```{admonition} Example
:class: tip


Consider the matrix

$$
A=\left(\begin{array}{cc}
\frac{-\alpha}{x^{2}} & 0 \\
0 & \frac{-(1-\alpha)}{y^{2}}
\end{array}\right)
$$

where $x>0, y>0$, and $0<\alpha<1$.

The leading principal sub-matrices for this matrix are $A_{1}=\left(\frac{-\alpha}{x^{2}}\right)$ and $A_{2}=A$. As such, the leading principal minors for this matrix are

$$
\operatorname{det}\left(A_{1}\right)=\frac{-\alpha}{x^{2}}<0
$$

and

$$
\operatorname{det}\left(A_{2}\right)=\operatorname{det}(A)
$$


$$
\begin{aligned}
\operatorname{det}\left(A_{2}\right) & =\operatorname{det}(A) \\
& =\left(\frac{-\alpha}{x^{2}}\right)\left(\frac{-(1-\alpha)}{y^{2}}\right)-(0)(0) \\
& =\frac{\alpha(1-\alpha)}{x^{2} y^{2}}-0 \\
& =\frac{\alpha(1-\alpha)}{x^{2} y^{2}} \\
& >0 
\end{aligned}
$$

Since $\operatorname{det}\left(A_{1}\right)<0$ and $\operatorname{det}\left(A_{2}\right)=\operatorname{det}(A)>0$, we can conclude that $A$ is a negative definite matrix.
```



### Quadratic forms on sets of linear constraints

Up until now, we have been allowing the $x$ vector to vary over all of $\mathbb{R}^{n}$ (for some $n \in \mathbb{N}$ ) and examining the sign of the quadratic form $x^{T} A x$ for all such $x \neq 0$. In other words, we have been examining the sign of an "unconstrained" quadratic form in $x$.

In economics, however, we are often faced with situations in which the $x$ vector will be subject to one or more constraints. Is it possible to determine the sign of a quadratic form for all $x$ vectors that satisfy one or more constraints in addition to the standard constraint that $x \neq 0$? If so, how can this be done?

In the remainder of these notes, we (at least partially) address these questions for the case in which the $x$ vector is subject to one or more linear constraints (in addition to the standard constraint that $x \neq 0$ ).


Let $x \in \mathbb{R}^{n}$ be a vector of $n$ real-valued variables, $A$ be an $(n \times n)$ matrix of constant real-valued coefficients, $C$ be an $(m \times n)$ matrix of constant real-valued coefficients, $m \in \mathbb{N}, n \in \mathbb{N}$, and $m<n$.

Note that $x^{T} A x$ is a quadratic form in the $x$ vector and $C x$ is a linear form in the $x$ vector.

We have already seen that if $A$ is not a symmetric matrix, then there exists some other matrix $B$ such that $x^{T} A x=x^{T} B x$ for all $x \in \mathbb{R}^{n}$. As such, we can assume, without loss of generality, that $A$ is a symmetric $(n \times n)$ matrix. We will make this assumption for the remainder of these notes.


The linear form $C_{x}$ will represent the linear constraints that we are imposing on the $x$ vector in addition to the standard restriction that $x \neq 0$.

To be precise, the set of linear constraints that are being imposed are given by the matrix equation $C_{X}=0$, where 0 is an $(m \times 1)$ null vector (that is, a vector consisting entirely of entries that are zeros). It is important that $m<n$ because we do not want the $x$ vector to be completely determined by the additional constraints that are being imposed.

We can use the matrices $A$ and $C$ to form a "bordered matrix" $D$ that takes the partitioned form

$$
D=\left(\begin{array}{cc}
0 & C \\
C^{T} & A
\end{array}\right),
$$

where 0 is an $(m \times m)$ null matrix (that is, a matrix consisting entirely of entries that are zeros).

Note that $D$ is a symmetric square matrix.
- It is an $((m+n) \times(m+n))$ matrix.
- It is symmetric because we have assumed that $A$ is a symmetric matrix.

The theorem on the following two slides is contained within (that is, is part of) Theorem 16.4 in {cite:ps}`simon1994` (p. 389).

```{admonition} Theorem
:class: caution

**Theorem**: Consider the quadratic form $Q(x)=x^{T} A x$ subject to the set of linear constraints $C x=0_{(m \times 1)}$ and $x \neq 0_{(n \times 1)}$, where $x \in \mathbb{R}^{n}$ is an $(m \times 1)$ vector of real-valued variables, $A$ is an $(n \times n)$ symmetric matrix of constant real-valued coefficients, $C$ is an $(m \times n)$ matrix of constant real-valued coefficients, $m \in \mathbb{N}, n \in \mathbb{N}$, and $m<n$. Form the $((m+n) \times(m+n))$ symmetric "bordered matrix" (in partitioned form)

$$
D=\left(\begin{array}{cc}
0_{(m \times m)} & C \\
C^{T} & A
\end{array}\right)
$$


1. The quadratic form $Q(x)$ is negative definite on the constraint set if $\operatorname{det}(D)$ has the same sign as $(-1)^{n}$ **and** if the **last** $(n-m)$ leading principal minors alternate in sign.
2. The quadratic form $Q(x)$ is positive definite on the constraint set if the last $(n-m)$ leading principal minors all have the same sign as $(-1)^{m}$.
3. The quadratic form $Q(x)$ is indefinite on the constraint set if both condition (1) and condition (2) are violated by **non-zero** leading principal minors.
```


```{admonition} Example
:class: tip


This is Example 16.7 from {cite:ps}`simon1994` (pp. 389-390).

Consider the case where $A$ is the symmetric $(4 \times 4)$ matrix

$$
A=\left(\begin{array}{cccc}
1 & 0 & 0 & -1 \\
0 & -1 & 2 & 0 \\
0 & 2 & 1 & 0 \\
-1 & 0 & 0 & 1
\end{array}\right)
$$

and $C$ is the $(2 \times 4)$ matrix

$$
C=\left(\begin{array}{cccc}
0 & 1 & 1 & 1 \\
1 & -9 & 0 & 1
\end{array}\right)
$$

Note that in this case there are four variables (that is, $n=4$ ) and two linear constraints other than the constraint that $x \neq 0$ (that is, $m=2)$.

The symmetric bordered matrix for this example is the $(6 \times 6)$ matrix

$$
D=\left(\begin{array}{cc}
0_{(2 \times 2)} & \\
& \\
C^{T} & A
\end{array}\right)=\left(\begin{array}{cccccc}
0 & 0 & 0 & 1 & 1 & 1 \\
0 & 0 & 1 & -9 & 0 & 1 \\
0 & 1 & 1 & 0 & 0 & -1 \\
1 & -9 & 0 & -1 & 2 & 0 \\
1 & 0 & 0 & 2 & 1 & 0 \\
1 & 1 & -1 & 0 & 0 & 1
\end{array}\right)
$$

Since $n=4$ and $m=2$ in this example, we need to check the signs of the last $(n-m)=(4-2)=2$ leading principal minors.

- The last leading principal minor is $\operatorname{det}\left(D_{6}\right)=\operatorname{det}(D)$.
- The second-last leading principal minor is $\operatorname{det}\left(D_{5}\right)$.


According to {cite:ps}`simon1994` (p. 390), $\operatorname{det}\left(D_{6}\right)=\operatorname{det}(D)=24>0$ and $\operatorname{det}\left(D_{5}\right)=77>0$.

You should confirm these values for the last two leading principle minors of $D$ for yourself.

Note that $(-1)^{m}=(-1)^{2}=1>0$. Thus we have

$$
\operatorname{sign}\left(\operatorname{det}\left(D_{6}\right)\right)=\operatorname{sign}\left(\operatorname{det}\left(D_{5}\right)\right)=\operatorname{sign}\left((-1)^{m}\right)=\operatorname{sign}\left((-1)^{2}\right) .
$$

This means that the matrix $A$ is positive definite on the set of constraints given by both $C_{x}=0$ and $x \neq 0$.

```
